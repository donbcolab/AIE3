{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU langchain langchain-core langchain-community langchain-openai\n",
    "!pip install -qU langchain-groq\n",
    "!pip install -qU langchain-qdrant\n",
    "!pip install -qU transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")\n",
    "QDRANT_URL = os.getenv(\"QDRANT_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donbr/aie3-bootcamp/AIE3/Week 3/Day 2/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_qdrant import Qdrant\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import tqdm as notebook_tqdm\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-70B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the document\n",
    "\n",
    "docs = PyMuPDFLoader(\"https://singjupost.com/wp-content/uploads/2014/07/Steve-Jobs-iPhone-2007-Presentation-Full-Transcript.pdf\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the token length function\n",
    "def llama3_token_len(text):\n",
    "    return len(tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=0,\n",
    "    length_function=llama3_token_len,\n",
    ")\n",
    "\n",
    "split_chunks = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### FOR INITIAL ANALYSIS ONLY:\n",
    "\n",
    "# PRINT THE NUMBER OF CHUNKS\n",
    "len(split_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n"
     ]
    }
   ],
   "source": [
    "##### FOR INITIAL ANALYSIS ONLY:\n",
    "\n",
    "max_chunk_length = 0\n",
    "\n",
    "for chunk in split_chunks:\n",
    "  max_chunk_length = max(max_chunk_length, llama3_token_len(chunk.page_content))\n",
    "\n",
    "print(max_chunk_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = QDRANT_URL\n",
    "api_key = QDRANT_API_KEY\n",
    "qdrant = Qdrant.from_documents(\n",
    "    split_chunks,\n",
    "    embedding_model,\n",
    "    url=url,\n",
    "    prefer_grpc=True,\n",
    "    api_key=api_key,\n",
    "    collection_name=\"iphone_speech\",\n",
    "    force_recreate=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_retriever = qdrant.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the LANGCHAIN_API_KEY environment variable (create key in settings)\n",
    "from langchain import hub\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set up LLM model\n",
    "#### set up LLAMA3 RAG prompt\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain import hub\n",
    "\n",
    "llm = ChatGroq(model=\"llama3-70b-8192\")\n",
    "llama3_prompt = hub.pull(\"rlm/rag-prompt-llama3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt.input_variables: ['context', 'question']\n",
      "\n",
      "prompt.metadata: {'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt-llama3', 'lc_hub_commit_hash': '4bc799d6b3a36adebc6359db85ff42234b4648bd8502c6597d99b5c0dcbb9ed3'}\n",
      "\n",
      "message type: HumanMessagePromptTemplate\n",
      "message:\n",
      "prompt=PromptTemplate(input_variables=['context', 'question'], template=\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise <|eot_id|><|start_header_id|>user<|end_header_id|> \\nQuestion: {question} \\nContext: {context} \\nAnswer: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\")\n"
     ]
    }
   ],
   "source": [
    "# display input_variables from prompt\n",
    "print(f\"prompt.input_variables: {llama3_prompt.input_variables}\")\n",
    "print(f\"\\nprompt.metadata: {llama3_prompt.metadata}\")\n",
    "\n",
    "# for each message in prompt.messages, display the message type (such as HumanMessagePromptTemplate) and the message itself\n",
    "for message in llama3_prompt.messages:\n",
    "    print(f\"\\nmessage type: {message.__class__.__name__}\")\n",
    "    print(f\"message:\\n{message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### verify simple prompt\n",
    "simple_chain = llama3_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    +-------------+    \n",
      "    | PromptInput |    \n",
      "    +-------------+    \n",
      "           *           \n",
      "           *           \n",
      "           *           \n",
      "+--------------------+ \n",
      "| ChatPromptTemplate | \n",
      "+--------------------+ \n",
      "           *           \n",
      "           *           \n",
      "           *           \n",
      "     +----------+      \n",
      "     | ChatGroq |      \n",
      "     +----------+      \n",
      "           *           \n",
      "           *           \n",
      "           *           \n",
      "  +----------------+   \n",
      "  | ChatGroqOutput |   \n",
      "  +----------------+   \n"
     ]
    }
   ],
   "source": [
    "# display the graph\n",
    "print(simple_chain.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"I don't know. The provided context only mentions that France is a country in Europe, but it doesn't provide the capital of France.\" response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 97, 'total_tokens': 125, 'completion_time': 0.080199539, 'prompt_time': 0.018759978, 'queue_time': None, 'total_time': 0.098959517}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'stop', 'logprobs': None} id='run-23ce10fe-4594-44c5-992b-584361af34d0-0'\n"
     ]
    }
   ],
   "source": [
    "simple_response = simple_chain.invoke({\"context\": \"France is a country in Europe.\", \"question\": \"What is the capital of France?\"})\n",
    "print(simple_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "retrieval_augmented_qa_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | qdrant_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": llama3_prompt | llm, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      +---------------------------------+                        \n",
      "                      | Parallel<context,question>Input |                        \n",
      "                      +---------------------------------+                        \n",
      "                           ****                   ****                           \n",
      "                       ****                           ***                        \n",
      "                     **                                  ****                    \n",
      "+--------------------------------+                           **                  \n",
      "| Lambda(itemgetter('question')) |                            *                  \n",
      "+--------------------------------+                            *                  \n",
      "                 *                                            *                  \n",
      "                 *                                            *                  \n",
      "                 *                                            *                  \n",
      "     +----------------------+                 +--------------------------------+ \n",
      "     | VectorStoreRetriever |                 | Lambda(itemgetter('question')) | \n",
      "     +----------------------+                 +--------------------------------+ \n",
      "                           ****                   ****                           \n",
      "                               ****           ****                               \n",
      "                                   **       **                                   \n",
      "                      +----------------------------------+                       \n",
      "                      | Parallel<context,question>Output |                       \n",
      "                      +----------------------------------+                       \n",
      "                                        *                                        \n",
      "                                        *                                        \n",
      "                                        *                                        \n",
      "                           +------------------------+                            \n",
      "                           | Parallel<context>Input |                            \n",
      "                           +------------------------+                            \n",
      "                              ***               ***                              \n",
      "                           ***                     ***                           \n",
      "                         **                           **                         \n",
      "     +-------------------------------+            +-------------+                \n",
      "     | Lambda(itemgetter('context')) |            | Passthrough |                \n",
      "     +-------------------------------+            +-------------+                \n",
      "                              ***               ***                              \n",
      "                                 ***         ***                                 \n",
      "                                    **     **                                    \n",
      "                          +-------------------------+                            \n",
      "                          | Parallel<context>Output |                            \n",
      "                          +-------------------------+                            \n",
      "                                        *                                        \n",
      "                                        *                                        \n",
      "                                        *                                        \n",
      "                      +---------------------------------+                        \n",
      "                      | Parallel<response,context>Input |                        \n",
      "                      +---------------------------------+                        \n",
      "                            ****                 ***                             \n",
      "                         ***                        ***                          \n",
      "                       **                              ****                      \n",
      "         +--------------------+                            **                    \n",
      "         | ChatPromptTemplate |                             *                    \n",
      "         +--------------------+                             *                    \n",
      "                    *                                       *                    \n",
      "                    *                                       *                    \n",
      "                    *                                       *                    \n",
      "              +----------+                 +-------------------------------+     \n",
      "              | ChatGroq |                 | Lambda(itemgetter('context')) |     \n",
      "              +----------+**               +-------------------------------+     \n",
      "                            ****                ****                             \n",
      "                                ***          ***                                 \n",
      "                                   **      **                                    \n",
      "                      +----------------------------------+                       \n",
      "                      | Parallel<response,context>Output |                       \n",
      "                      +----------------------------------+                       \n"
     ]
    }
   ],
   "source": [
    "print(retrieval_augmented_qa_chain.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = retrieval_augmented_qa_chain.invoke({\"question\" : \"What is the most important thing about the iPhone?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The most important thing about the iPhone is that it runs on the OSX operating system, which provides a strong foundation and enables features like multi-tasking, networking, security, and desktop-class applications.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "page_content='what’s on any other phone. Now how do we do this? Well, we start with a strong foundation.\\niPhone runs OSX.\\nNow, why would we want to run such a sophisticated operating system on a mobile\\ndevice? Well, because it’s got everything we need. It’s got multi-tasking. It’s got the best\\nnetworking. It already knows how to power manage. We’ve been doing this on mobile\\ncomputers for years. It’s got awesome security. And the right apps. It’s got everything from\\nCocoa and the graphics and it’s got core animation built in and it’s got the audio and video\\nthat OSX is famous for. It’s got all the stuff we want. And it’s built right in to iPhone. And\\nthat has let us create desktop class applications and networking. Not the crippled stuff that\\nyou find on most phones. This is real, desktop-class applications.' metadata={'subject': '', 'creator': '', 'total_pages': 22, 'keywords': '', 'modDate': \"20200415062431+00'00'\", 'trapped': '', 'format': 'PDF 1.4', 'creationDate': \"20200415062431+00'00'\", 'file_path': 'https://singjupost.com/wp-content/uploads/2014/07/Steve-Jobs-iPhone-2007-Presentation-Full-Transcript.pdf', 'source': 'https://singjupost.com/wp-content/uploads/2014/07/Steve-Jobs-iPhone-2007-Presentation-Full-Transcript.pdf', 'producer': 'mPDF 7.0.3', 'page': 2, 'title': 'Steve Jobs iPhone 2007 Presentation (Full Transcript)', 'author': 'Married Wildebeest', '_id': 'cd538255-3b4a-437e-b567-6d8f8479f4b7', '_collection_name': 'iphone_speech'}\n",
      "----\n",
      "Context:\n",
      "page_content='you think. They told me this, they said, You had me at scrolling. So, the iPhone with the\\nmost amazing iPod ever. You can now touch your music. So that’s the iPod.\\nNow, let’s take a look at a revolutionary phone. We want to reinvent the phone. Now, what’s\\nthe killer app? The killer app is making calls! It’s amazing — it’s amazing how hard it is to\\nmake calls on most phones. Most people actually dial them every time. Most people don’t\\nhave very many numbers in their address book they use their recents as their address book.\\nRight? How many of you do that? I bet more than a few. So, we want to let you use contacts\\nlike never before. You can synch your iPhone with your PC or Mac and bring down all your\\ncontacts right into your phone. So you’ve got everybody’s numbers with you at all times.' metadata={'subject': '', 'creator': '', 'total_pages': 22, 'keywords': '', 'trapped': '', 'modDate': \"20200415062431+00'00'\", 'format': 'PDF 1.4', 'creationDate': \"20200415062431+00'00'\", 'source': 'https://singjupost.com/wp-content/uploads/2014/07/Steve-Jobs-iPhone-2007-Presentation-Full-Transcript.pdf', 'file_path': 'https://singjupost.com/wp-content/uploads/2014/07/Steve-Jobs-iPhone-2007-Presentation-Full-Transcript.pdf', 'producer': 'mPDF 7.0.3', 'page': 6, 'title': 'Steve Jobs iPhone 2007 Presentation (Full Transcript)', 'author': 'Married Wildebeest', '_id': 'ce9c24da-baa5-468b-9305-656694fef7e9', '_collection_name': 'iphone_speech'}\n",
      "----\n",
      "Context:\n",
      "page_content='you set up what you want synched to your iPhone. And it’s just like an iPod. Charge and\\nsynch. So synch with iTunes.\\nThird thing I want to talk about a little is design. We’ve designed something wonderful for\\nyour hand, just wonderful. This is what it looks like. It’s got a three-and-a-half-inch screen\\non it. It’s really big. And, it’s the highest-resolution screen we’ve ever shipped. It’s 160\\npixels per inch. Highest we’ve ever shipped. It’s gorgeous. And on the front, there’s only one\\nbutton down there. We call it the Home button. Takes you Home from wherever you are.\\nAnd that’s it.\\nLet’s take a look at the side. It’s really thin. It’s thinner than any smartphone out there, at' metadata={'subject': '', 'creator': '', 'total_pages': 22, 'keywords': '', 'modDate': \"20200415062431+00'00'\", 'trapped': '', 'format': 'PDF 1.4', 'source': 'https://singjupost.com/wp-content/uploads/2014/07/Steve-Jobs-iPhone-2007-Presentation-Full-Transcript.pdf', 'creationDate': \"20200415062431+00'00'\", 'file_path': 'https://singjupost.com/wp-content/uploads/2014/07/Steve-Jobs-iPhone-2007-Presentation-Full-Transcript.pdf', 'title': 'Steve Jobs iPhone 2007 Presentation (Full Transcript)', 'page': 3, 'producer': 'mPDF 7.0.3', 'author': 'Married Wildebeest', '_id': 'd793904a-dcc0-4749-859e-efeb87558846', '_collection_name': 'iphone_speech'}\n",
      "----\n",
      "Context:\n",
      "page_content='the multi-touch screen. A first. Miniaturization, more than any we’ve done before. A lot of\\ncustom silicon. Tremendous power management. OSX inside a mobile device. Featherweight\\nprecision enclosures. Three advanced sensors. Desktop class applications, and of course, the\\nwidescreen video iPod. We’ve been innovating like crazy for the last few years on this, and\\nwe filed for over 200 patents for all the inventions in iPhone, and we intend to protect them.\\nSo, a lot of high technology. I think we’re advancing the state of the art in every aspect of\\nthis design. So iPhone is like having your life in your pocket. It’s the ultimate digital device.\\nSo what should we price it at? Well, what do these things normally cost? An iPod, the most\\npopular iPod, $199 for 4 gig nano. What’s a smartphone cost? Well, they say you get the' metadata={'subject': '', 'creator': '', 'total_pages': 22, 'keywords': '', 'modDate': \"20200415062431+00'00'\", 'trapped': '', 'format': 'PDF 1.4', 'file_path': 'https://singjupost.com/wp-content/uploads/2014/07/Steve-Jobs-iPhone-2007-Presentation-Full-Transcript.pdf', 'creationDate': \"20200415062431+00'00'\", 'source': 'https://singjupost.com/wp-content/uploads/2014/07/Steve-Jobs-iPhone-2007-Presentation-Full-Transcript.pdf', 'title': 'Steve Jobs iPhone 2007 Presentation (Full Transcript)', 'page': 17, 'producer': 'mPDF 7.0.3', 'author': 'Married Wildebeest', '_id': 'f77ad81c-32ee-4f87-81f1-5b3b19d6b190', '_collection_name': 'iphone_speech'}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for context in response[\"context\"]:\n",
    "  print(\"Context:\")\n",
    "  print(context)\n",
    "  print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = retrieval_augmented_qa_chain.invoke({\"question\" : \"What is the airspeed velocity of an unladen swallow?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"response\"].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
