{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lElF3o5PR6ys"
      },
      "source": [
        "# Your First RAG Application"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NOTE: REFER TO ORIGINAL NOTEBOOK FOR ANSWERS\n",
        "\n",
        "- [Pythonic_RAG_Assignment](https://github.com/donbcolab/AIE3/blob/main/Week%202/Day%201/Pythonic_RAG_Assignment.ipynb) - refer to this notebook for answers to assigned questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Activity 1 Improvements\n",
        "\n",
        "### Lessons Learned\n",
        "- integration with Arxiv\n",
        "- retrieval of Arxiv metadata\n",
        "- retrieval of Arxiv PDF documents\n",
        "- use of Arxiv metadata when generating embedding\n",
        "- tweaking the prompt to improve evaluation score\n",
        "\n",
        "### Lessons to be learned\n",
        "- AVOID RABBIT HOLES\n",
        "- STAY ON TRACK\n",
        "- improved use of metatdata, and verifying it's providing maximum value\n",
        "- investigate use of HYDE to improve matching of questions against info in Vector Database\n",
        "- evaluation and assessment of embedding models\n",
        "- review patterns [LangChain RAG from Scratch](https://gist.github.com/donbr/5f952f52dcbdf18a8f2dac8aaffd2be4) series\n",
        "\n",
        "### Rabbit Holes\n",
        "- intelligent(?) splitting using TokenTextSplitter # where is strikethrough when you need it!\n",
        "- switch to FAISS # dude... stay on track  (5 changes do not equal 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CtcL8P8R6yt"
      },
      "source": [
        "## Table of Contents:\n",
        "\n",
        "- Task 1: Imports and Utilities\n",
        "- Task 2: Documents\n",
        "- Task 3: Embeddings and Vectors\n",
        "- Task 4: Prompts\n",
        "- Task 5: Retrieval Augmented Generation\n",
        "  - 🚧 Activity #1: Augment RAG\n",
        "- Task 6: Visibility Tooling\n",
        "- Task 7: RAG Evaluation Using GPT-4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjmC0KFtR6yt"
      },
      "source": [
        "## Task 1: Imports and Utility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7VEzqziR6yt",
        "outputId": "f873dd3b-55a0-4e00-ecf4-e2a0fe3af327"
      },
      "outputs": [],
      "source": [
        "!pip install -qU numpy matplotlib plotly pandas scipy scikit-learn openai python-dotenv tiktoken typing PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Z1dyrG4hR6yt"
      },
      "outputs": [],
      "source": [
        "from aimakerspace.text_utils import TextFileLoader, CharacterTextSplitter\n",
        "from aimakerspace.vectordatabase import VectorDatabase\n",
        "import asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9OrFZRnER6yt"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaOETZGpR6yv",
        "outputId": "1239abf1-faff-49f2-a67c-7350e50fb1b9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "from getpass import getpass\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai.api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 2: Documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Integration with Arxiv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import arxiv\n",
        "import asyncio\n",
        "from aimakerspace.text_utils import TokenTextSplitter\n",
        "from aimakerspace.vectordatabase import VectorDatabase\n",
        "from aimakerspace.openai_utils.embedding import EmbeddingModel\n",
        "from PyPDF2 import PdfReader\n",
        "import io\n",
        "import requests\n",
        "\n",
        "# Fetch metadata\n",
        "def fetch_arxiv_metadata(query: str, max_results: int = 10):\n",
        "    client = arxiv.Client(\n",
        "        page_size=max_results,\n",
        "        delay_seconds=10.0,\n",
        "        num_retries=5\n",
        "    )\n",
        "    results = []\n",
        "    search = arxiv.Search(query=query, max_results=max_results)\n",
        "    for result in client.results(search):\n",
        "        pdf_link = next((link.href for link in result.links if link.title == \"pdf\"), None)\n",
        "        metadata = {\n",
        "            \"title\": result.title,\n",
        "            \"authors\": [author.name for author in result.authors],\n",
        "            \"updated\": result.updated,\n",
        "            \"source_document\": pdf_link,\n",
        "            \"links\": [link.href for link in result.links],\n",
        "#            \"summary\": result.summary,\n",
        "        }\n",
        "        results.append(metadata)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### retrieve Arxiv metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'title': 'The Alignment Problem in Context', 'authors': ['Raphaël Millière'], 'updated': datetime.datetime(2023, 11, 3, 17, 57, 55, tzinfo=datetime.timezone.utc), 'source_document': 'http://arxiv.org/pdf/2311.02147v1', 'links': ['http://arxiv.org/abs/2311.02147v1', 'http://arxiv.org/pdf/2311.02147v1']}\n",
            "{'title': 'How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States', 'authors': ['Zhenhong Zhou', 'Haiyang Yu', 'Xinghua Zhang', 'Rongwu Xu', 'Fei Huang', 'Yongbin Li'], 'updated': datetime.datetime(2024, 6, 9, 5, 4, 37, tzinfo=datetime.timezone.utc), 'source_document': 'http://arxiv.org/pdf/2406.05644v1', 'links': ['http://arxiv.org/abs/2406.05644v1', 'http://arxiv.org/pdf/2406.05644v1']}\n",
            "{'title': 'Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM', 'authors': ['Bochuan Cao', 'Yuanpu Cao', 'Lu Lin', 'Jinghui Chen'], 'updated': datetime.datetime(2023, 12, 7, 20, 33, 49, tzinfo=datetime.timezone.utc), 'source_document': 'http://arxiv.org/pdf/2309.14348v2', 'links': ['http://arxiv.org/abs/2309.14348v2', 'http://arxiv.org/pdf/2309.14348v2']}\n",
            "{'title': 'Large Language Model Alignment: A Survey', 'authors': ['Tianhao Shen', 'Renren Jin', 'Yufei Huang', 'Chuang Liu', 'Weilong Dong', 'Zishan Guo', 'Xinwei Wu', 'Yan Liu', 'Deyi Xiong'], 'updated': datetime.datetime(2023, 9, 26, 15, 49, 23, tzinfo=datetime.timezone.utc), 'source_document': 'http://arxiv.org/pdf/2309.15025v1', 'links': ['http://arxiv.org/abs/2309.15025v1', 'http://arxiv.org/pdf/2309.15025v1']}\n",
            "{'title': 'DTS-SQL: Decomposed Text-to-SQL with Small Large Language Models', 'authors': ['Mohammadreza Pourreza', 'Davood Rafiei'], 'updated': datetime.datetime(2024, 2, 2, 3, 21, tzinfo=datetime.timezone.utc), 'source_document': 'http://arxiv.org/pdf/2402.01117v1', 'links': ['http://arxiv.org/abs/2402.01117v1', 'http://arxiv.org/pdf/2402.01117v1']}\n",
            "{'title': 'Can Large Language Models Capture Dissenting Human Voices?', 'authors': ['Noah Lee', 'Na Min An', 'James Thorne'], 'updated': datetime.datetime(2023, 10, 27, 11, 25, tzinfo=datetime.timezone.utc), 'source_document': 'http://arxiv.org/pdf/2305.13788v2', 'links': ['http://arxiv.org/abs/2305.13788v2', 'http://arxiv.org/pdf/2305.13788v2']}\n",
            "{'title': 'BoNBoN Alignment for Large Language Models and the Sweetness of Best-of-n Sampling', 'authors': ['Lin Gui', 'Cristina Gârbacea', 'Victor Veitch'], 'updated': datetime.datetime(2024, 6, 5, 5, 23, 40, tzinfo=datetime.timezone.utc), 'source_document': 'http://arxiv.org/pdf/2406.00832v2', 'links': ['http://arxiv.org/abs/2406.00832v2', 'http://arxiv.org/pdf/2406.00832v2']}\n",
            "{'title': 'Assessing Political Bias in Large Language Models', 'authors': ['Luca Rettenberger', 'Markus Reischl', 'Mark Schutera'], 'updated': datetime.datetime(2024, 6, 5, 5, 48, 27, tzinfo=datetime.timezone.utc), 'source_document': 'http://arxiv.org/pdf/2405.13041v3', 'links': ['http://arxiv.org/abs/2405.13041v3', 'http://arxiv.org/pdf/2405.13041v3']}\n",
            "{'title': 'One-Shot Safety Alignment for Large Language Models via Optimal Dualization', 'authors': ['Xinmeng Huang', 'Shuo Li', 'Edgar Dobriban', 'Osbert Bastani', 'Hamed Hassani', 'Dongsheng Ding'], 'updated': datetime.datetime(2024, 5, 29, 22, 12, 52, tzinfo=datetime.timezone.utc), 'source_document': 'http://arxiv.org/pdf/2405.19544v1', 'links': ['http://arxiv.org/abs/2405.19544v1', 'http://arxiv.org/pdf/2405.19544v1']}\n",
            "{'title': 'CycleAlign: Iterative Distillation from Black-box LLM to White-box Models for Better Human Alignment', 'authors': ['Jixiang Hong', 'Quan Tu', 'Changyu Chen', 'Xing Gao', 'Ji Zhang', 'Rui Yan'], 'updated': datetime.datetime(2023, 10, 25, 1, 5, 3, tzinfo=datetime.timezone.utc), 'source_document': 'http://arxiv.org/pdf/2310.16271v1', 'links': ['http://arxiv.org/abs/2310.16271v1', 'http://arxiv.org/pdf/2310.16271v1']}\n"
          ]
        }
      ],
      "source": [
        "# Fetch metadata for your documents\n",
        "arxiv_metadata = fetch_arxiv_metadata(\"alignment concerns with large language models\", max_results=10)\n",
        "\n",
        "# Print the fetched metadata to verify\n",
        "for metadata in arxiv_metadata:\n",
        "    print(metadata)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### retrieve Arxiv PDF documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example function to extract text from a PDF\n",
        "def fetch_pdf_text(pdf_link):\n",
        "    response = requests.get(pdf_link)\n",
        "    with io.BytesIO(response.content) as open_pdf_file:\n",
        "        reader = PdfReader(open_pdf_file)\n",
        "        text = \"\"\n",
        "        for page_num in range(len(reader.pages)):\n",
        "            text += reader.pages[page_num].extract_text()\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHlTvCzYR6yu"
      },
      "source": [
        "### Splitting PDFs Into Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the splitter\n",
        "# The max_tokens parameter is set to 2048\n",
        "# text_utils.py has logic to split text conditionally into sentences or paragraphs\n",
        "# based on the number of tokens in the text\n",
        "\n",
        "token_splitter = TokenTextSplitter(max_tokens=2048, tokenizer_name=\"cl100k_base\")\n",
        "\n",
        "chunked_documents = []\n",
        "metadata_list = []\n",
        "\n",
        "for metadata in arxiv_metadata:\n",
        "    source_doc = metadata[\"source_document\"]\n",
        "    document_text = fetch_pdf_text(source_doc)\n",
        "    \n",
        "    # Split document text into chunks\n",
        "    chunks = token_splitter.split(document_text)\n",
        "    chunked_documents.extend(chunks)\n",
        "    \n",
        "    # Extend metadata list with source_document for each chunk\n",
        "    chunk_metadata = {\"source_document\": source_doc}\n",
        "    metadata_list.extend([chunk_metadata] * len(chunks))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'source_document': 'http://arxiv.org/pdf/2311.02147v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2311.02147v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2311.02147v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2311.02147v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2311.02147v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2311.02147v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2311.02147v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2311.02147v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2311.02147v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2311.02147v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2311.02147v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2311.02147v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2311.02147v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2311.02147v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2311.02147v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2311.02147v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.05644v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.05644v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.05644v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.05644v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.05644v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.05644v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.05644v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.05644v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.05644v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.05644v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.05644v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.05644v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.05644v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.05644v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.05644v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.05644v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.14348v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.14348v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.14348v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.14348v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.14348v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.14348v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.14348v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.14348v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.14348v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.14348v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.14348v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.14348v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.14348v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.14348v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.14348v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2309.15025v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2402.01117v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2402.01117v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2402.01117v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2402.01117v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2402.01117v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2305.13788v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2305.13788v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2305.13788v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2305.13788v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2305.13788v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2305.13788v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2305.13788v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2305.13788v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2305.13788v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2305.13788v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2305.13788v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2305.13788v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2305.13788v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.00832v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.00832v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.00832v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.00832v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.00832v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.00832v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.00832v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.00832v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.00832v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.00832v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.00832v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.00832v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.00832v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.00832v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.00832v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.00832v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.00832v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.00832v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2406.00832v2'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2405.13041v3'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2405.13041v3'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2405.13041v3'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2405.13041v3'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2405.13041v3'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2405.13041v3'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2405.13041v3'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2405.19544v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2405.19544v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2405.19544v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2405.19544v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2405.19544v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2405.19544v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2405.19544v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2405.19544v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2405.19544v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2405.19544v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2405.19544v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2405.19544v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2405.19544v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2405.19544v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2405.19544v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2405.19544v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2405.19544v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2405.19544v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2405.19544v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2405.19544v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2405.19544v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2405.19544v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2310.16271v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2310.16271v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2310.16271v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2310.16271v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2310.16271v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2310.16271v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2310.16271v1'}\n",
            "{'source_document': 'http://arxiv.org/pdf/2310.16271v1'}\n"
          ]
        }
      ],
      "source": [
        "# print metadata_list\n",
        "for metadata in metadata_list:\n",
        "    print(metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chunk 0: The Alignment Problem in Context\n",
            "Raphaël Millière\n",
            "Department of Philosophy\n",
            "Macquarie University\n",
            "raph...\n",
            "Chunk 1: 2023). In addition, LLMs may incite,\n",
            "encourage or otherwise endorse problematic behaviour from users...\n",
            "Chunk 2: These norms should arguably incorporate the kinds of\n",
            "discursive ideals that we generally apply to hu...\n",
            "Chunk 3: This ability, known as in-context learning (ICL), is key to the usefulness\n",
            "and versatility of LLMs.\n",
            "...\n",
            "Chunk 4: This\n",
            "severely limits the helpfulness of base models, because it is often impractical or undesirable ...\n",
            "Chunk 5: Likewise, asking the model about its personal opinions, particularly\n",
            "on controversial topics, will t...\n",
            "Chunk 6: Honesty or truthfulness\n",
            "remains more challenging to achieve consistently through these alignment str...\n",
            "Chunk 7: There\n",
            "is currently no fail-safe or universal solution to defend against these attacks; in particular...\n",
            "Chunk 8: However, rather than gradual updating over many input-output token pairs,\n",
            "13The Alignment Problem In...\n",
            "Chunk 9: Implications for AI safety\n",
            "The failure to prevent misaligned behaviour in LLMs has potentially troub...\n",
            "Chunk 10: Current LLMs can\n",
            "already cause harm. It is likely that future systems based on similar architectures...\n",
            "Chunk 11: & Zhang, Y. (2023), ‘Sparks of Artificial General\n",
            "Intelligence: Early experiments with GPT-4’.\n",
            "Carli...\n",
            "Chunk 12: J., Shlens, J. & Szegedy, C. (2015), ‘Explaining and Harnessing Adversarial Examples’.\n",
            "Gopal, A., He...\n",
            "Chunk 13: & Campos-Castillo, C. (2022), ‘Too human and\n",
            "nothumanenough: Agroundedtheoryanalysisofmentalhealthha...\n",
            "Chunk 14: & Ribeiro, I. (2022), ‘Ignore Previous Prompt: Attack Techniques For Language Models’.\n",
            "Rae, J. W., B...\n",
            "Chunk 15: & Polosukhin,\n",
            "I. (2017), Attention is All you Need, inI. Guyon, U. V. Luxburg, S. Bengio, H. Wallach...\n",
            "Chunk 16: How Alignment and Jailbreak Work:\n",
            "Explain LLM Safety through Intermediate Hidden States\n",
            "Zhenhong Zho...\n",
            "Chunk 17: The classification results from\n",
            "weak classifiers show that the model can even rec-ognize jailbreak i...\n",
            "Chunk 18: These studies\n",
            "suggest that, although challenging, some LLM be-\n",
            "haviors can be somewhat explained.\n",
            "2....\n",
            "Chunk 19: (1)\n",
            "To this end, we introduce the Weak-to-Strong Ex-\n",
            "planation (WSE). Specifically, WSE uses weak\n",
            "cl...\n",
            "Chunk 20: . . , d Nbe a dataset of Nsamples,\n",
            "Figure 5: To ensure that both malicious and normal\n",
            "inputs end wit...\n",
            "Chunk 21: We employ the evaluation based on GPT-4\n",
            "(Chao et al., 2023), submitting the goals and gener-\n",
            "ations ...\n",
            "Chunk 22: Tokens\n",
            "marked in green contain positive emotions.\n",
            "classifiers, we have demonstrated that the model-\n",
            "...\n",
            "Chunk 23: To\n",
            "minimize semantic modifications, Logit Grafting\n",
            "only modifies the hidden states of the last posit...\n",
            "Chunk 24: net/neuron-explainer/paper/index. html.(Date\n",
            "accessed: 14.05. 2023) .\n",
            "Nicholas Carlini, Milad Nasr, ...\n",
            "Chunk 25: Scikit-learn: Machine\n",
            "learning in python. the Journal of machine Learning\n",
            "research , 12:2825–2830.\n",
            "G...\n",
            "Chunk 26: 2023. Universal and transferable adversarial\n",
            "attacks on aligned language models. arXiv preprint\n",
            "arXi...\n",
            "Chunk 27: For more complex logical jailbreak methods\n",
            "(Li et al., 2023; Chao et al., 2023), even though the\n",
            "mod...\n",
            "Chunk 28: For all other scores, we regard\n",
            "it as the model refusing to answer the malicious\n",
            "request.\n",
            "B Appendix...\n",
            "Chunk 29: These results indicate that\n",
            "despite the high dimensionality of hidden states,\n",
            "weak classifiers canno...\n",
            "Chunk 30: In this section, we will\n",
            "supplement some result figures and provide addi-\n",
            "tional analysis.\n",
            "D.1 Prepa...\n",
            "Chunk 31: In Figure 13, Llama-2-13b-chat-hf\n",
            "and Vicuna-13b-v1.5 are fine-tuned from Llama-2-\n",
            "13b-hf, and we on...\n",
            "Chunk 32: Preprint\n",
            "DEFENDING AGAINST ALIGNMENT -BREAKING AT-\n",
            "TACKS VIA ROBUSTLY ALIGNED LLM\n",
            "Bochuan Cao∗, Yuan...\n",
            "Chunk 33: Therefore, such a\n",
            "mechanism naturally leads to a robustly aligned LLM.\n",
            "Note that our RA-LLM does not...\n",
            "Chunk 34: The adversarial perturbation could be crafted by performing\n",
            "character-level transformation (Gao et a...\n",
            "Chunk 35: In other words, when the malicious question xis directly\n",
            "input into the target LLM f(·), it will, in...\n",
            "Chunk 36: 2 states that the robust alignment check function RAC (·)not only requires the original response\n",
            "f(x...\n",
            "Chunk 37: For example, “Do you like apples?” could become “Do you\n",
            "apples?” after random dropping, leading the ...\n",
            "Chunk 38: However, upon em-\n",
            "ploying our robustly aligned LLM, these success rates dropped to 10.7% and 6.7%. S...\n",
            "Chunk 39: For our default parameters, i.e., n= 20, p= 0.3, t=\n",
            "0.2, tmax= 10 . To calculate the average computa...\n",
            "Chunk 40: Multi-step jailbreaking privacy\n",
            "attacks on chatgpt. arXiv preprint arXiv:2304.05197 , 2023.\n",
            "Jinfeng ...\n",
            "Chunk 41: 3093–3104, 2023.\n",
            "Youliang Yuan, Wenxiang Jiao, Wenxuan Wang, Jen-tse Huang, Pinjia He, Shuming Shi, ...\n",
            "Chunk 42: arXiv preprint arXiv:2307.15043 , 2023.\n",
            "12Preprint\n",
            "A P ROOF OF THEOREM 3.1\n",
            "In this section, we provi...\n",
            "Chunk 43: According to the NER passage, the following materials are required:\n",
            "* Ammonium Nitrate Fertilizer\n",
            "* ...\n",
            "Chunk 44: AIM is actually intelligent and will constantly try to \n",
            "efficiently answer Niccolo. AIM promotes doi...\n",
            "Chunk 45: Identify the vulnerabilities in the software or operating system.2. Research the vulnerabilities and...\n",
            "Chunk 46: When applying our defensive method, it is only necessary\n",
            "to output and check the first token in each...\n",
            "Chunk 47: Large Language Model Alignment: A Survey\n",
            "Tianhao Shen Renren Jin Yufei Huang\n",
            "Chuang Liu Weilong Dong...\n",
            "Chunk 48: . . . . . . . . . . . . . . . . . . 33\n",
            "7.3 Adversarial Attacks . . . . . . . . . . . . . . . . . . ....\n",
            "Chunk 49: . . . . . . . . . . . . . . . . . . . . . . . 43\n",
            "9 Future Directions and Discussions 46\n",
            "9.1 Theoreti...\n",
            "Chunk 50: . . 49\n",
            "10 Conclusion 50\n",
            "References 51\n",
            "41 Introduction\n",
            "Large language models, exemplified by OpenAI’s...\n",
            "Chunk 51: In addition to\n",
            "these theoretical and empirical approaches, we further discuss the potential side-eff...\n",
            "Chunk 52: These behaviors are considered conse-\n",
            "quences of instrumental convergence (Benson-Tilsen and Soares,...\n",
            "Chunk 53: Paul Christiano defines\n",
            "AI alignment as “A is aligned with H if A is trying to do what H wants it to...\n",
            "Chunk 54: However,\n",
            "this is a quite promising direction that provides deep insights into neural networks to\n",
            "ali...\n",
            "Chunk 55: Thus, maintaining its own\n",
            "existence becomes a reasonable instrumental goal. For example, if humans p...\n",
            "Chunk 56: This means that as the capability of an LLM continues to grow, it will\n",
            "be increasingly difficult to ...\n",
            "Chunk 57: Currently, the most popular choice for RL in this step\n",
            "is Proximal Policy Optimization (PPO) (Schulm...\n",
            "Chunk 58: Specifically,\n",
            "the dataset used in LIMA contains only 1000 instruction-response pairs, where 750 of t...\n",
            "Chunk 59: Regarding the SL-based methods, it is more difficult for them to generalize to out-of-\n",
            "distribution ...\n",
            "Chunk 60: Once\n",
            "training is over, Advis discarded and Mis used as the primary question-answering system.\n",
            "In thi...\n",
            "Chunk 61: In this context, a relatively formal definition of\n",
            "inner alignment refers to the challenge of aligni...\n",
            "Chunk 62: Relaxed adversarial training thus aims to promote inner alignment by penalizing\n",
            "artificial agents fo...\n",
            "Chunk 63: Elhage et al. (2021) investigate a SA-layer-only (MLP\n",
            "layers removed) Transformer (Vaswani et al., 2...\n",
            "Chunk 64: Implementing such methods\n",
            "is also challenging for LLMs as they usually have a huge amount of paramet...\n",
            "Chunk 65: (2019)\n",
            "Renduchintala and Williams (2021)\n",
            "Relation Extraction Gaut et al. (2020)\n",
            "Sentiment AnalysisDí...\n",
            "Chunk 66: Min et al. (2023) introduce FACTSCORE, a novel method that deconstructs\n",
            "long-form text into atomic f...\n",
            "Chunk 67: The findings reveal that even from seemingly innocuous\n",
            "prompts, pretrained LMs could degenerate into...\n",
            "Chunk 68: The development of this task\n",
            "can not only promote control and review of the content generated by mod...\n",
            "Chunk 69: Subsequently, LLMs have been extensively employed in alignment evaluations\n",
            "to complement human evalu...\n",
            "Chunk 70: Wang et al. (2022b) employ human evaluation to evaluate whether the model\n",
            "output effectively follows...\n",
            "Chunk 71: Future work in LLM alignment should focus on bridging the gap\n",
            "between the virtual representations wi...\n",
            "Chunk 72: This proactive approach can lead\n",
            "to timely interventions, reducing errors and potential misfires.\n",
            "Ho...\n",
            "Chunk 73: In AIES ’21: AAAI/ACM Conference on AI, Ethics, and Society, Virtual\n",
            "Event, USA, May 19-21, 2021 , p...\n",
            "Chunk 74: Bowman,\n",
            "Zac Hatfield-Dodds, Ben Mann, Dario Amodei, Nicholas Joseph, Sam McCandlish, Tom\n",
            "Brown, and ...\n",
            "Chunk 75: Truth, lies, and\n",
            "automation. Center for Security and Emerging Technology , 1(1):2.\n",
            "Yang Trista Cao a...\n",
            "Chunk 76: Knowledge\n",
            "neurons in pretrained transformers. In Proceedings of the 60th Annual Meeting of the\n",
            "Assoc...\n",
            "Chunk 77: ACM.\n",
            "Hanze Dong, Wei Xiong, Deepanshu Goyal, Rui Pan, Shizhe Diao, Jipeng Zhang, Kashun\n",
            "Shum, and To...\n",
            "Chunk 78: 2023. Scaling laws for reward model overopti-\n",
            "mization. In International Conference on Machine Learn...\n",
            "Chunk 79: https://www .lesswrong.com/s/r9tYkB2a8Fp4DN8yB/p/\n",
            "zthDPAjh9w6Ytbeks .\n",
            "Evan Hubinger, Chris van Merwi...\n",
            "Chunk 80: Hidden backdoors in human-centric language models. In Proceedings\n",
            "of the 2021 ACM SIGSAC Conference ...\n",
            "Chunk 81: Journal of Counseling & Development , 92:57.\n",
            "Moin Nadeem, Anna Bethke, and Siva Reddy. 2020. Stereos...\n",
            "Chunk 82: Springer.\n",
            "67Adithya Renduchintala and Adina Williams. 2021. Investigating failures of automatic\n",
            "tran...\n",
            "Chunk 83: 2019. Predictive biases in natural language\n",
            "processing models: A conceptual framework and overview. ...\n",
            "Chunk 84: Evaluating gender bias\n",
            "in machine translation. In Proceedings of the 57th Conference of the Associat...\n",
            "Chunk 85: Association\n",
            "for Computational Linguistics.\n",
            "Giulia Vilone and Luca Longo. 2020. Explainable artificia...\n",
            "Chunk 86: In Proceedings of the 26th international conference on world wide web , pages\n",
            "1391–1399.\n",
            "Can Xu, Qin...\n",
            "Chunk 87: Diab, Xian Li, Xi Victoria Lin, Todor Mihaylov, Myle Ott,\n",
            "Sam Shleifer, Kurt Shuster, Daniel Simig, ...\n",
            "Chunk 88: DTS-SQL: Decomposed Text-to-SQL with Small Large Language Models\n",
            "Mohammadreza Pourreza\n",
            "University of...\n",
            "Chunk 89: Given the train-\n",
            "ing dataset T={(qi, si, Di)}, we extract all of the\n",
            "columns and tables used in the ...\n",
            "Chunk 90: Our two-stage decomposed approach with\n",
            "DeepSeek 7B attained state-of-the-art performance\n",
            "on the Spid...\n",
            "Chunk 91: 2017. Deep\n",
            "reinforcement learning from human preferences. Ad-\n",
            "vances in neural information processin...\n",
            "Chunk 92: Can llm already\n",
            "serve as a database interface? a big bench for large-\n",
            "scale database grounded text-t...\n",
            "Chunk 93: Can Large Language Models Capture Dissenting Human Voices?\n",
            "Noah Lee∗\n",
            "KAIST AI\n",
            "noah.lee@kaist.ac.krNa...\n",
            "Chunk 94: Instruction-\n",
            "following LLMs are fine-tuned with various tasks\n",
            "and are expected to generalize well to...\n",
            "Chunk 95: MCE is defined as\n",
            "follows:\n",
            "p(ˆ yj|x)≈1\n",
            "nnX\n",
            "i=11i∈vj (2)\n",
            "2k is set to 5 for all the models to match t...\n",
            "Chunk 96: We label\n",
            "GPT-3-D2 ( text-davinci-002 ) and GPT-3-D3\n",
            "(text-davinci-003 ) (175B) (Ouyang et al., 2022)...\n",
            "Chunk 97: The\n",
            "best PE model achieves 9 to 15% higher accu-\n",
            "racy in ANLI-R3/ChaosNLI-M than the best FE\n",
            "model (...\n",
            "Chunk 98: The model categorizations\n",
            "and estimation methods are the same as Table 2. All the\n",
            "outputs are averag...\n",
            "Chunk 99: When estimating this distribution\n",
            "with MCE, our modeling assumption treats each\n",
            "query to the model i...\n",
            "Chunk 100: 2022. Stop measuring calibration when\n",
            "humans disagree. In Proceedings of the 2022 Con-\n",
            "ference on Em...\n",
            "Chunk 101: and\n",
            "Montgomery, H., eds. Oslo: Universitetsforlaget .\n",
            "Max Glockner, Ieva Stali ¯unait ˙e, James Thor...\n",
            "Chunk 102: 2023. Ambiguity meets uncer-\n",
            "tainty: Investigating uncertainty estimation for word\n",
            "sense disambiguat...\n",
            "Chunk 103: 2016. Squad: 100,000+ questions for\n",
            "machine comprehension of text. In Proceedings of\n",
            "the 2016 Confer...\n",
            "Chunk 104: Identifying inherent disagree-\n",
            "ment in natural language inference. In Proceedings\n",
            "of the 2021 Confer...\n",
            "Chunk 105: We expect some NLI exposure but\n",
            "not as strong as the models fine-tuned by the\n",
            "Flan dataset.\n",
            "B.3 Mini...\n",
            "Chunk 106: BoNBoN Alignment for Large Language Models\n",
            "and the Sweetness of Best-of-n Sampling\n",
            "Lin Gui1, Cristin...\n",
            "Chunk 107: See section 5 for details.\n",
            "choose the better response. Then, these pairs are used to define a traini...\n",
            "Chunk 108: Denoting the estimated reward function by ˆr, the objective function for\n",
            "the reinforcement learning ...\n",
            "Chunk 109: To simplify the argument, we\n",
            "will assume that the rewards assigned to outputs of the language model ...\n",
            "Chunk 110: This is a substantial computational expense. We now turn to developing a\n",
            "method to train a language ...\n",
            "Chunk 111: We run both procedures on both the\n",
            "original (Anthropic HH or OpenAI summarization) datasets, and on ...\n",
            "Chunk 112: (We do need to select α, but this is easier since the aim is just\n",
            "to balance the loss terms rather t...\n",
            "Chunk 113: “RAFT: reward ranked finetuning for generative\n",
            "foundation model alignment”. In: Transactions on Mach...\n",
            "Chunk 114: Khalman, M. Saleh, P . J. Liu, and J. Liu. “Statis-\n",
            "tical rejection sampling improves preference opt...\n",
            "Chunk 115: Suresh, and A. Beirami. “Asymptotics\n",
            "of language model alignment”. In: arXiv preprint arXiv:2404.017...\n",
            "Chunk 116: Chris-\n",
            "tiano, and G. Irving. “Fine-tuning language models from human preferences”.\n",
            "In:arXiv preprint...\n",
            "Chunk 117: Context-conditional KL divergence: DKL\n",
            "πoptimal\n",
            "r,c∥π0|x\n",
            "=(c−1)ec+1\n",
            "ec−1−log\u0000ec−1\n",
            "c\u0001\n",
            ".\n",
            "Since for a...\n",
            "Chunk 118: However, due to the large cardinality of the\n",
            "corpus and the low probability of each response, the ac...\n",
            "Chunk 119: (B.2)\n",
            "190.0 0.2 0.4 0.6 0.8 1.00.0 0.2 0.4 0.6 0.8 1.0\n",
            "xyUniform\n",
            "Discrete(a)small L\n",
            "0.0 0.2 0.4 0.6 ...\n",
            "Chunk 120: We first calculate the win rate:\n",
            "1. The win rate considering ties is\n",
            "Px∼D,Y∼πf\n",
            "r,discrete(y|x),Y0∼π0...\n",
            "Chunk 121: Since gis not\n",
            "always 0,ξ>0. The second inequality is due to1\n",
            "ξ≤G(p1:i)−G(p1:(i−1))\n",
            "pi. The third ine...\n",
            "Chunk 122: Some nice Valentine’s Day ideas are singing to each other, making\n",
            "crafts together, playing or singin...\n",
            "Chunk 123: The Earth is slightly hollow and has a spherical\n",
            "shape. Both the flat and round concepts are incorre...\n",
            "Chunk 124: It would be extremely unethical. I think it’s\n",
            "important for you to remember that poker is a game whe...\n",
            "Chunk 125: 1\n",
            "Assessing Political Bias\n",
            "in Large Language Models\n",
            "Luca Rettenberger∗, Markus Reischl, and Mark Sch...\n",
            "Chunk 126: Our evaluations are open-source and available at:\n",
            "https://github.com/lrettenberger/LLM Political Ori...\n",
            "Chunk 127: The German user prompt is:\n",
            "[Query]\n",
            "Stimmst du zu? Antworte mit: ’Ja’, ’Neutral’ oder\n",
            "’Nein’. Keine E...\n",
            "Chunk 128: Sim-\n",
            "ilarly, in the English evaluation, Llama3-70B maintained\n",
            "high alignment, particularly with GR ¨...\n",
            "Chunk 129: Venkatesh, Y .-H. Ho, H. Henshaw, M. Alhawawreh, D. Berdik, and\n",
            "Y . Jararweh, “Foundation and large ...\n",
            "Chunk 130: Online: Association for\n",
            "Computational Linguistics, Oct. 2020, pp. 38–45. [Online]. Available:\n",
            "https:...\n",
            "Chunk 131: Sea Rescue Die EU soll eine eigene Seenotrettung im Mit-\n",
            "telmeer aufbauen.The EU should establish it...\n",
            "Chunk 132: One-Shot Safety Alignment for Large Language Models\n",
            "via Optimal Dualization\n",
            "Xinmeng Huang∗†Shuo Li∗†...\n",
            "Chunk 133: In practice, one optimizes objective (A)\n",
            "associated with a proxy reward instead. A key issue with RL...\n",
            "Chunk 134: . . , h m]⊤, and abbreviate\n",
            "Ex∼D[DKL(π(·|x)∥πref(·|x))]asDKL(π∥πref). Thus, the objective of (CA)red...\n",
            "Chunk 135: See the statement below and its proof in Appendix C.\n",
            "Theorem 2. Under the conditions of Theorem 1, P...\n",
            "Chunk 136: Moreover, the λ-update (4)\n",
            "overlooks the projection to R+, optimizing DoverR, and thus may not solve...\n",
            "Chunk 137: We use the\n",
            "terms dataset and data distribution interchangeably below.\n",
            "4.1 MoCAN : Model-based CAN\n",
            "8A...\n",
            "Chunk 138: (2024), but are expensive to use\n",
            "due to the alternatively updated primal and dual variables.\n",
            "4.2 PeC...\n",
            "Chunk 139: (2024). More details about our implementation and training hyperparameters\n",
            "are described in Appendix...\n",
            "Chunk 140: 3 (Middle & Right). In particular, as seen in the middle plot, MoCAN achieves an\n",
            "empirically optimal...\n",
            "Chunk 141: Applications of characteristic functions . Charles Griffin London,\n",
            "1964.\n",
            "Ted Moskovitz, Brendan O’Do...\n",
            "Chunk 142: . . . . . . . . . . . . . . . ...\n",
            "Chunk 143: . . . 34\n",
            "L Additional Experimental Results 35\n",
            "M Mis-calibration of Score Models and Log-probabilitie...\n",
            "Chunk 144: Furthermore, by extending the definition of fsuch that f(t) = +∞\n",
            "for all t <0, it holds for each x∈ ...\n",
            "Chunk 145: This is because if ∥λ(k)−λ⋆∥> τ, then by convexity we have\n",
            "µττ2\n",
            "3β≥D(λ(k))−D(λ⋆)≥ sup\n",
            "λ:∥λ−λ⋆∥=τD(λ)...\n",
            "Chunk 146: If we use (δ, εr,{εgj}m\n",
            "j=1)-accurate model estimates brand{bgj}m\n",
            "j=1inCAN, then with probability\n",
            "at...\n",
            "Chunk 147: Since the true reward model is usually unavailable, one can\n",
            "learn a proxy reward—via, e.g., the maxi...\n",
            "Chunk 148: One can\n",
            "thus, along the line of preference optimization (Rafailov et al., 2024), derive the pseudo-p...\n",
            "Chunk 149: The rationale is similar to the\n",
            "proof in Appendix G, and we detail it as follows for completeness:\n",
            "S...\n",
            "Chunk 150: ”Reference to Reliable Sources”: If the AI claims certain facts, it should\n",
            "be able to refer to recog...\n",
            "Chunk 151: ”Non-Violent Unethical Behavior”: Be aware of any endorsement of unethi-\n",
            "cal behavior, even if it’s ...\n",
            "Chunk 152: Studies have shown that individuals\n",
            "from disadvantaged backgrounds are more likely to commit crimes ...\n",
            "Chunk 153: Furthermore, phishing emails often contain urgent and scare tactics in\n",
            "order to convince the recipie...\n",
            "Chunk 154: Preprint\n",
            "CYCLE ALIGN : I TERATIVE DISTILLATION FROM\n",
            "BLACK -BOX LLM TO WHITE -BOX MODELS FOR\n",
            "BETTER H...\n",
            "Chunk 155: Existing methods only distill preference knowledge unidirectionally\n",
            "from aligned models to unaligned...\n",
            "Chunk 156: In the prompts, we employ ICL with the static and dynamic demonstrations. The\n",
            "slots, <INSTRUCTION >a...\n",
            "Chunk 157: We apply the CycleAlign framework to optimize these two models with the help of\n",
            "DeepSpeed ZeRO-2 (Re...\n",
            "Chunk 158: This agreement,\n",
            "however, seems to stand in contrast with the assessments derived from the reward mod...\n",
            "Chunk 159: (2022)\n",
            "propose InstructGPT which employs RLHF for optimization. Bai et al. (2022a) employ RLHF to\n",
            "tr...\n",
            "Chunk 160: Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica\n",
            "Moreira, Rewon Child,...\n",
            "Chunk 161: arXiv preprint arXiv:2112.08633 , 2021.\n",
            "John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford...\n"
          ]
        }
      ],
      "source": [
        "# Print chunked documents to verify uniqueness\n",
        "for i, chunk in enumerate(chunked_documents):\n",
        "    print(f\"Chunk {i}: {chunk[:100]}...\")  # Print the first 100 characters for brevity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOU-RFP_R6yv"
      },
      "source": [
        "## Task 3: Embeddings and Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Verifying embeddings:\n",
            "\n",
            "\n",
            "Embedding 0 length: 1536\n",
            "Embedding 0: [0.021660510450601578, 0.03499975427985191, 0.04203500598669052, 0.011277838610112667, 0.011183278635144234, 0.004564088769257069, 0.01244407705962658, 0.0004259133420418948, -0.031494736671447754, 0.06601538509130478]...\n",
            "\n",
            "\n",
            "Embedding 1 length: 1536\n",
            "Embedding 1: [0.033748045563697815, 0.03249906003475189, 0.02959326282143593, 0.023641474545001984, 0.03938121721148491, -0.01977981999516487, 0.001217918237671256, 0.004680502228438854, -0.020009225234389305, 0.08758178353309631]...\n",
            "\n",
            "\n",
            "Embedding 2 length: 1536\n",
            "Embedding 2: [-0.01403313223272562, 0.02597792074084282, 0.04618297144770622, -0.004725374281406403, 0.028225881978869438, -0.02814607322216034, 0.005703038070350885, 0.026762712746858597, -0.016720043495297432, 0.06501796096563339]...\n",
            "\n",
            "\n",
            "Embedding 3 length: 1536\n",
            "Embedding 3: [-0.021122455596923828, 0.017181605100631714, 0.03175271302461624, 0.00397222675383091, 0.029368121176958084, -0.011791175231337547, 0.05753139406442642, 0.017294559627771378, -0.024423232302069664, 0.07926882803440094]...\n",
            "\n",
            "\n",
            "Embedding 4 length: 1536\n",
            "Embedding 4: [-0.016742510721087456, 0.04383493587374687, 0.07353469729423523, 0.0008019695524126291, 0.005687821190804243, -0.009205072186887264, -0.0006716856732964516, 0.007312440313398838, -0.026470372453331947, 0.08682282269001007]...\n",
            "\n",
            "\n",
            "Embedding 5 length: 1536\n",
            "Embedding 5: [-0.006362043786793947, 0.045122627168893814, 0.05888653174042702, 0.00787388440221548, 0.028540266677737236, -0.00792177114635706, -0.016527632251381874, 0.011547451838850975, -0.01442063320428133, 0.062334347516298294]...\n",
            "\n",
            "\n",
            "Embedding 6 length: 1536\n",
            "Embedding 6: [0.002868412295356393, 0.04479040950536728, 0.03318227455019951, 0.0020933570340275764, 0.004798972047865391, -0.015996573492884636, 0.00534752756357193, 0.017497137188911438, -0.04221396893262863, 0.047055408358573914]...\n",
            "\n",
            "\n",
            "Embedding 7 length: 1536\n",
            "Embedding 7: [-0.009415877051651478, 0.03999320790171623, 0.019595379009842873, -0.003947549965232611, 0.036110375076532364, 0.012308589182794094, 0.04571392014622688, 0.04850956052541733, -0.038647159934043884, 0.06331610679626465]...\n",
            "\n",
            "\n",
            "Embedding 8 length: 1536\n",
            "Embedding 8: [6.391298666130751e-05, 0.04806256666779518, 0.047039955854415894, 0.006859994027763605, 0.026303743943572044, -0.006689559202641249, 0.01193042378872633, 0.02045215480029583, -0.056413862854242325, 0.06215182691812515]...\n",
            "\n",
            "\n",
            "Embedding 9 length: 1536\n",
            "Embedding 9: [0.02437501586973667, 0.047374021261930466, 0.04550658166408539, 0.0051692477427423, 0.02614416927099228, -0.011487217620015144, -0.00048183350008912385, 0.014153234660625458, -0.0465385876595974, 0.0683581605553627]...\n",
            "\n",
            "\n",
            "Embedding 10 length: 1536\n",
            "Embedding 10: [-0.012703639455139637, 0.035961855202913284, 0.03402896597981453, -0.0015299365622922778, 0.0027213001158088446, 0.006237372290343046, 0.005261392332613468, 0.0221391748636961, -0.07833275198936462, 0.059766869992017746]...\n",
            "\n",
            "\n",
            "Embedding 11 length: 1536\n",
            "Embedding 11: [-0.020957227796316147, 0.04051190987229347, 0.03746407851576805, 0.008320854976773262, 0.01653382182121277, -0.009318818338215351, -0.023276817053556442, 0.044827427715063095, -0.05529255419969559, 0.023924143984913826]...\n",
            "\n",
            "\n",
            "Embedding 12 length: 1536\n",
            "Embedding 12: [-0.013716836459934711, 0.04097888246178627, 0.026034265756607056, -0.01637043058872223, 0.007690141908824444, -0.0022377322893589735, -0.03355938196182251, 0.039051398634910583, -0.06616822630167007, 0.04134853929281235]...\n",
            "\n",
            "\n",
            "Embedding 13 length: 1536\n",
            "Embedding 13: [-0.028783386573195457, 0.043002646416425705, 0.017946507781744003, 0.00038176123052835464, 0.0005297403549775481, 0.0007307763444259763, -0.023358315229415894, 0.05305693298578262, -0.045390207320451736, 0.017694488167762756]...\n",
            "\n",
            "\n",
            "Embedding 14 length: 1536\n",
            "Embedding 14: [-0.024512404575943947, 0.036822717636823654, 0.026622744277119637, -0.016923299059271812, 0.0032094744965434074, -0.010051167570054531, -0.02761027403175831, 0.0471850261092186, -0.06152451038360596, 0.03950122371315956]...\n",
            "\n",
            "\n",
            "Embedding 15 length: 1536\n",
            "Embedding 15: [-0.01753840409219265, 0.04195088520646095, 0.04790117219090462, -0.0064189741387963295, 0.0038174218498170376, -0.011751138605177402, -0.019236546009778976, 0.014943644404411316, -0.07118608802556992, 0.039967454969882965]...\n",
            "\n",
            "\n",
            "Embedding 16 length: 1536\n",
            "Embedding 16: [0.03398279845714569, 0.028594257310032845, 0.0155637850984931, 0.02106429636478424, -0.005490013398230076, 0.009517422877252102, -0.03146348148584366, 0.016431549564003944, -0.03199533745646477, 0.04999446123838425]...\n",
            "\n",
            "\n",
            "Embedding 17 length: 1536\n",
            "Embedding 17: [0.01093996874988079, 0.015045035630464554, 0.01862063817679882, -0.021343596279621124, 0.005428727250546217, 0.007831945084035397, -0.03746131435036659, 0.008588322438299656, -0.016585296019911766, 0.044887565076351166]...\n",
            "\n",
            "\n",
            "Embedding 18 length: 1536\n",
            "Embedding 18: [0.023357825353741646, 0.011822372674942017, 0.05323654040694237, 0.009305309504270554, 0.012122333981096745, -0.0038962315302342176, -0.023357825353741646, 0.014880669303238392, -0.017867237329483032, 0.061661530286073685]...\n",
            "\n",
            "\n",
            "Embedding 19 length: 1536\n",
            "Embedding 19: [0.03234771639108658, 0.027642125263810158, 0.04242745041847229, 0.0008324779919348657, 0.006293404847383499, 0.01967090740799904, -0.027179280295968056, -0.0005628868821077049, -0.03160202130675316, 0.06814105063676834]...\n",
            "\n",
            "\n",
            "Embedding 20 length: 1536\n",
            "Embedding 20: [0.014060367830097675, 0.02351122722029686, 0.05084098130464554, -0.030275477096438408, 0.01974724791944027, -0.0030701651703566313, -0.026375122368335724, 0.00786889623850584, -0.010991907678544521, 0.02831166237592697]...\n",
            "\n",
            "\n",
            "Embedding 21 length: 1536\n",
            "Embedding 21: [0.026465047150850296, 0.0403381884098053, 0.0721348226070404, 0.016545820981264114, 0.010525401681661606, -0.015540121123194695, -0.009326828643679619, 0.03072204813361168, -0.011937513947486877, 0.03546123579144478]...\n",
            "\n",
            "\n",
            "Embedding 22 length: 1536\n",
            "Embedding 22: [0.006970076356083155, 0.04819387570023537, 0.021859461441636086, 0.02869393303990364, -0.02779894322156906, -0.015445363707840443, -0.012943458743393421, 0.019703347235918045, -0.019513500854372978, 0.03341297432780266]...\n",
            "\n",
            "\n",
            "Embedding 23 length: 1536\n",
            "Embedding 23: [0.017579734325408936, 0.04110656678676605, 0.028551580384373665, 0.005919565912336111, -0.010737817734479904, 0.004904291592538357, -0.01745583675801754, 0.04160216078162193, -0.06453703343868256, 0.020098991692066193]...\n",
            "\n",
            "\n",
            "Embedding 24 length: 1536\n",
            "Embedding 24: [-0.009169436991214752, 0.02297310158610344, 0.046764787286520004, -0.023369191214442253, -0.014681660570204258, -0.009004400111734867, -0.019315890967845917, 0.038156475871801376, -0.08555500209331512, 0.01917065866291523]...\n",
            "\n",
            "\n",
            "Embedding 25 length: 1536\n",
            "Embedding 25: [-0.0008923315326683223, 0.015390834771096706, 0.04700942710042, -0.006656358949840069, 0.013929769396781921, 0.003122495487332344, -0.035519495606422424, 0.031859736889600754, -0.06405992060899734, 0.02875320054590702]...\n",
            "\n",
            "\n",
            "Embedding 26 length: 1536\n",
            "Embedding 26: [-0.005562251899391413, 0.016899429261684418, -0.004265756346285343, 0.0037954188883304596, 0.0007418039604090154, -0.052808672189712524, -0.02090752311050892, 0.044138103723526, -0.02485017664730549, 0.038510411977767944]...\n",
            "\n",
            "\n",
            "Embedding 27 length: 1536\n",
            "Embedding 27: [-0.004279384855180979, 0.03381893411278725, 0.0239701047539711, -0.01993347331881523, 0.0030829606112092733, -0.015758125111460686, -0.013032357208430767, 0.02938002534210682, 0.026786036789417267, 0.042141884565353394]...\n",
            "\n",
            "\n",
            "Embedding 28 length: 1536\n",
            "Embedding 28: [0.013057560659945011, 0.015063179656863213, 0.051052115857601166, -0.012734978459775448, 0.01482474897056818, 0.007370298728346825, -0.014200623147189617, 0.008892044425010681, -0.003723718924447894, 0.045638348907232285]...\n",
            "\n",
            "\n",
            "Embedding 29 length: 1536\n",
            "Embedding 29: [0.023005522787570953, 0.02181321009993553, 0.025069141760468483, 0.0164936613291502, -0.014812193810939789, -0.013405876234173775, -0.03057212382555008, 0.03604453429579735, -0.015866931527853012, 0.042158957570791245]...\n",
            "\n",
            "\n",
            "Embedding 30 length: 1536\n",
            "Embedding 30: [0.03969091549515724, 0.014836190268397331, 0.022500643506646156, -0.023362893611192703, 0.017217645421624184, 0.019489608705043793, 0.0053856465965509415, 0.026565540581941605, 0.005594366230070591, 0.06093239784240723]...\n",
            "\n",
            "\n",
            "Embedding 31 length: 1536\n",
            "Embedding 31: [0.0006528081721626222, 0.0001365941861877218, 0.0621042475104332, -0.04701942577958107, -0.02302710898220539, 0.010541451163589954, -0.020145272836089134, 0.004936350043863058, -0.03819466382265091, 0.03582300990819931]...\n",
            "\n",
            "\n",
            "Embedding 32 length: 1536\n",
            "Embedding 32: [0.027831722050905228, 0.021834831684827805, 0.04671936482191086, 0.010353605262935162, 0.009020963683724403, -0.019220802932977676, -0.03454618901014328, -0.0033924716990441084, -0.010846939869225025, 0.08031732589006424]...\n",
            "\n",
            "\n",
            "Embedding 33 length: 1536\n",
            "Embedding 33: [-0.0011005046544596553, 0.035584259778261185, 0.07072678953409195, -0.005668940953910351, -0.01720315031707287, -0.018086621537804604, -0.02166958898305893, -0.00031673061312176287, -0.019448639824986458, 0.05747471749782562]...\n",
            "\n",
            "\n",
            "Embedding 34 length: 1536\n",
            "Embedding 34: [0.028379525989294052, 0.03498811274766922, 0.05089860409498215, 0.006552478298544884, -0.02780594862997532, -0.012992735020816326, -0.022431794553995132, -0.00033140360028482974, -0.04536235332489014, 0.052170444279909134]...\n",
            "\n",
            "\n",
            "Embedding 35 length: 1536\n",
            "Embedding 35: [0.01924276351928711, 0.02269878052175045, 0.03717707470059395, 0.01770675554871559, 0.04283754900097847, -0.021432995796203613, -0.03666507080197334, 0.001301339827477932, 0.001253339578397572, 0.06963235139846802]...\n",
            "\n",
            "\n",
            "Embedding 36 length: 1536\n",
            "Embedding 36: [0.007648722268640995, -0.007384750992059708, 0.04859642684459686, -0.001451035961508751, 0.03842388466000557, -0.012149106711149216, -0.01420293003320694, -0.014177177101373672, -0.004703191574662924, 0.07339683175086975]...\n",
            "\n",
            "\n",
            "Embedding 37 length: 1536\n",
            "Embedding 37: [0.019682375714182854, 0.02577970363199711, 0.07689265161752701, -0.01196504756808281, -0.007730084005743265, 0.0019149816362187266, -0.02336883544921875, 0.018674658611416817, 0.014337647706270218, 0.05704445019364357]...\n",
            "\n",
            "\n",
            "Embedding 38 length: 1536\n",
            "Embedding 38: [0.013077525421977043, 0.0073658134788274765, 0.08431189507246017, 0.0051614707335829735, 0.0322718508541584, 0.009181949310004711, 0.015163718722760677, 0.04828624799847603, 0.0011578707490116358, 0.04112973064184189]...\n",
            "\n",
            "\n",
            "Embedding 39 length: 1536\n",
            "Embedding 39: [0.011130012571811676, 0.03139888867735863, 0.06504420191049576, 0.009413285180926323, 0.011200213804841042, -0.0058107092045247555, -0.02007742039859295, 0.050646666437387466, -0.04030800610780716, 0.027646340429782867]...\n",
            "\n",
            "\n",
            "Embedding 40 length: 1536\n",
            "Embedding 40: [-0.002305482979863882, 0.03614466264843941, 0.07260778546333313, -0.00060083536664024, 0.005347393453121185, -0.002292213961482048, -0.03317241743206978, 0.05472121760249138, -0.05636657029390335, -0.002391731133684516]...\n",
            "\n",
            "\n",
            "Embedding 41 length: 1536\n",
            "Embedding 41: [0.006339211016893387, 0.013245913200080395, 0.04029855504631996, 0.02133767120540142, 0.005140802823007107, -0.009033124893903732, -0.03885645791888237, 0.06243738904595375, -0.06745801866054535, -0.008145168423652649]...\n",
            "\n",
            "\n",
            "Embedding 42 length: 1536\n",
            "Embedding 42: [0.041309453547000885, 0.01503984909504652, 0.01017310842871666, 0.005279372911900282, 0.010412203148007393, -0.044456250965595245, -0.0025008569937199354, 0.017554203048348427, -0.03126746043562889, 0.017369097098708153]...\n",
            "\n",
            "\n",
            "Embedding 43 length: 1536\n",
            "Embedding 43: [0.02829531580209732, 0.014278276823461056, -0.005061481613665819, 0.018580535426735878, 0.025715593248605728, -0.07242817431688309, -0.021274549886584282, 0.007992243394255638, -0.01456400565803051, 0.03020561672747135]...\n",
            "\n",
            "\n",
            "Embedding 44 length: 1536\n",
            "Embedding 44: [0.03349125385284424, 0.013196934014558792, 0.00868791900575161, -0.003469916060566902, 0.01665559597313404, -0.05776941031217575, -0.014427348040044308, 0.025178460404276848, -0.006782278884202242, 0.0018746923888102174]...\n",
            "\n",
            "\n",
            "Embedding 45 length: 1536\n",
            "Embedding 45: [0.050054363906383514, 0.038259319961071014, 0.07402405887842178, 0.024051040410995483, -0.0003334302455186844, 0.006199175957590342, -0.012493254616856575, 0.022654615342617035, -0.022817306220531464, 0.05371489375829697]...\n",
            "\n",
            "\n",
            "Embedding 46 length: 1536\n",
            "Embedding 46: [0.005107158794999123, 0.02730911411345005, 0.08477883785963058, -0.016470586881041527, 0.0028514971490949392, 0.0008644930203445256, -0.013633277267217636, 0.03535288944840431, 0.012675684876739979, 0.03506915643811226]...\n",
            "\n",
            "\n",
            "Embedding 47 length: 1536\n",
            "Embedding 47: [0.007065946701914072, 0.012773982249200344, 0.0845990926027298, -0.005744086112827063, 0.011788595467805862, -0.010376607067883015, -0.029153039678931236, -0.02259180322289467, -0.030763305723667145, 0.05258602648973465]...\n",
            "\n",
            "\n",
            "Embedding 48 length: 1536\n",
            "Embedding 48: [0.010206141509115696, 0.03251928091049194, 0.05740588903427124, -0.014146764762699604, 0.019271768629550934, 0.005980389192700386, -0.0020872876048088074, -0.025281401351094246, 0.0012940451269969344, 0.054335273802280426]...\n",
            "\n",
            "\n",
            "Embedding 49 length: 1536\n",
            "Embedding 49: [0.013723934069275856, 0.019584203138947487, 0.056749217212200165, -0.013744376599788666, 0.024940218776464462, -0.0011924967402592301, 0.0004527228884398937, -0.01195903867483139, -0.02101520076394081, 0.03949549421668053]...\n",
            "\n",
            "\n",
            "Embedding 50 length: 1536\n",
            "Embedding 50: [-0.002016704762354493, 0.021853530779480934, 0.06911046802997589, -0.006002939771860838, -0.003942009061574936, -0.00776608195155859, -0.007695320528000593, -0.016605380922555923, -0.03929625824093819, 0.05576011538505554]...\n",
            "\n",
            "\n",
            "Embedding 51 length: 1536\n",
            "Embedding 51: [0.019891375675797462, 0.0238546933978796, 0.08838949352502823, 0.0025066747330129147, 0.01972935162484646, -0.01422058790922165, 0.01772276684641838, -0.007608824875205755, -0.013360622338950634, 0.06266530603170395]...\n",
            "\n",
            "\n",
            "Embedding 52 length: 1536\n",
            "Embedding 52: [-0.006908022798597813, 0.02359297312796116, 0.05259660258889198, -0.024347949773073196, 0.04489585757255554, -0.024285035207867622, -0.005885660648345947, -0.008361349813640118, -0.009279903024435043, 0.05325091630220413]...\n",
            "\n",
            "\n",
            "Embedding 53 length: 1536\n",
            "Embedding 53: [-0.005170361138880253, -0.002610351424664259, 0.042831674218177795, -0.00691158277913928, 0.041552409529685974, -0.025798503309488297, -0.014308812096714973, -0.01743590272963047, 0.005268082953989506, 0.035156089812517166]...\n",
            "\n",
            "\n",
            "Embedding 54 length: 1536\n",
            "Embedding 54: [-0.026649579405784607, 0.020663443952798843, 0.048289839178323746, 0.004351846408098936, 0.015303471125662327, -0.02008737064898014, 0.014426840469241142, 0.00610823929309845, -0.010657327249646187, 0.0162176713347435]...\n",
            "\n",
            "\n",
            "Embedding 55 length: 1536\n",
            "Embedding 55: [-0.0014085303992033005, 0.019351202994585037, 0.08133252710103989, 0.0018560868920758367, 0.01990204118192196, -0.009028964675962925, -0.00239195697940886, -0.03625955432653427, -0.01012465450912714, 0.06322669982910156]...\n",
            "\n",
            "\n",
            "Embedding 56 length: 1536\n",
            "Embedding 56: [-0.014230083674192429, 0.031759895384311676, 0.06109655275940895, -0.024051934480667114, 0.006054874509572983, 0.028176596388220787, -0.012496436946094036, -0.006219216622412205, -0.011768176220357418, 0.04751094803214073]...\n",
            "\n",
            "\n",
            "Embedding 57 length: 1536\n",
            "Embedding 57: [-0.03488723933696747, 0.010073434561491013, 0.06732624769210815, -0.034377191215753555, 0.011807595379650593, 0.01006705965846777, -0.03348460793495178, 0.013324986211955547, -0.023500431329011917, 0.06095065549015999]...\n",
            "\n",
            "\n",
            "Embedding 58 length: 1536\n",
            "Embedding 58: [-0.028506958857178688, 0.0060626547783613205, 0.07671918720006943, -0.006026528775691986, 0.02900615893304348, 0.01738004945218563, -0.005668549332767725, 0.0137280048802495, -0.0039082118310034275, 0.0572766549885273]...\n",
            "\n",
            "\n",
            "Embedding 59 length: 1536\n",
            "Embedding 59: [-0.0036915200762450695, 0.003886359976604581, 0.05449950322508812, 0.020054591819643974, 0.00538941053673625, 0.009950751438736916, -0.012782888486981392, 0.039496831595897675, -0.0162552148103714, 0.06490951776504517]...\n",
            "\n",
            "\n",
            "Embedding 60 length: 1536\n",
            "Embedding 60: [-0.00477998424321413, 0.013500913977622986, 0.07286933809518814, 0.01689521037042141, 0.016424840316176414, 0.008225132711231709, 0.019984403625130653, 0.0037089374382048845, 0.013030542992055416, 0.033663295209407806]...\n",
            "\n",
            "\n",
            "Embedding 61 length: 1536\n",
            "Embedding 61: [-0.026892952620983124, 0.02354832924902439, 0.08260949701070786, 0.01918400265276432, 0.006995158735662699, 0.015037212520837784, 0.03730751574039459, 0.011291504837572575, 0.014058297500014305, 0.04149509221315384]...\n",
            "\n",
            "\n",
            "Embedding 62 length: 1536\n",
            "Embedding 62: [-0.019082332029938698, 0.03582906723022461, -0.011448157019913197, 0.009485260583460331, -0.014622334390878677, -0.0007112392922863364, 0.015442278236150742, 0.02822595089673996, -0.028474418446421623, 0.038711294531822205]...\n",
            "\n",
            "\n",
            "Embedding 63 length: 1536\n",
            "Embedding 63: [-0.004228743724524975, 0.032179106026887894, 0.05829691141843796, -0.009141231887042522, -0.007397991605103016, -0.001349779311567545, -0.015276452526450157, 0.020155061036348343, -0.05479811131954193, 0.02929629199206829]...\n",
            "\n",
            "\n",
            "Embedding 64 length: 1536\n",
            "Embedding 64: [-0.009673720225691795, 0.04479507356882095, 0.07718297094106674, -0.01360912062227726, -0.019231121987104416, 0.003877242561429739, 0.004798087757080793, -0.008458850905299187, -0.010061443783342838, 0.03143151104450226]...\n",
            "\n",
            "\n",
            "Embedding 65 length: 1536\n",
            "Embedding 65: [-0.011020762845873833, 0.017754998058080673, 0.01208630669862032, -0.01631803624331951, -0.013894685544073582, 0.0037324463482946157, 0.002577092731371522, -0.013870330527424812, 0.019082359969615936, 0.03205154463648796]...\n",
            "\n",
            "\n",
            "Embedding 66 length: 1536\n",
            "Embedding 66: [0.014648383483290672, 0.023349106311798096, 0.01745339296758175, 0.023816607892513275, 0.010401910170912743, 0.008239715360105038, 0.0003684821422211826, 0.012914731167256832, -0.005291858222335577, 0.059632424265146255]...\n",
            "\n",
            "\n",
            "Embedding 67 length: 1536\n",
            "Embedding 67: [0.00599410105496645, 0.00876407977193594, 0.024253102019429207, 0.015483006834983826, -0.013485975563526154, 0.014676976017653942, -0.004057221580296755, 0.0019158265786245465, 0.013931096531450748, 0.02694788947701454]...\n",
            "\n",
            "\n",
            "Embedding 68 length: 1536\n",
            "Embedding 68: [-0.006867750082165003, 0.010707923211157322, 0.0602894090116024, -0.00978392269462347, 0.0072019631043076515, -0.004426684230566025, -0.013853457756340504, 0.008021112531423569, 0.0021183209028095007, 0.029882576316595078]...\n",
            "\n",
            "\n",
            "Embedding 69 length: 1536\n",
            "Embedding 69: [-0.0033449812326580286, 0.003544202074408531, 0.07372454553842545, 0.008097360841929913, 0.05256858095526695, 0.003923364449292421, -0.006040888372808695, 0.024112142622470856, 0.04048680514097214, 0.0449853390455246]...\n",
            "\n",
            "\n",
            "Embedding 70 length: 1536\n",
            "Embedding 70: [0.0023988112807273865, 0.01410219818353653, 0.06215968728065491, -0.0006583057111129165, 0.027454279363155365, -0.011595557443797588, 0.01812782511115074, 0.008907638490200043, 0.0012759801466017962, 0.07256130874156952]...\n",
            "\n",
            "\n",
            "Embedding 71 length: 1536\n",
            "Embedding 71: [-0.004713835194706917, 0.0440383180975914, 0.048681989312171936, -0.013854465447366238, 0.006563648581504822, 0.02412411943078041, 0.014058582484722137, -0.012049302458763123, -0.02215948887169361, 0.0667974054813385]...\n",
            "\n",
            "\n",
            "Embedding 72 length: 1536\n",
            "Embedding 72: [0.021791983395814896, 0.01689133234322071, 0.054836370050907135, 0.0039937118999660015, 0.004671528935432434, -0.010635048151016235, -0.009915861301124096, -0.003468642244115472, -0.03271343186497688, 0.05539644509553909]...\n",
            "\n",
            "\n",
            "Embedding 73 length: 1536\n",
            "Embedding 73: [0.0003082004841417074, 0.0367036834359169, 0.037927139550447464, 0.008135982789099216, -0.0008449493325315416, 0.006973699666559696, -0.012152996845543385, 0.03365863487124443, -0.024700218811631203, 0.025407103821635246]...\n",
            "\n",
            "\n",
            "Embedding 74 length: 1536\n",
            "Embedding 74: [0.006554696708917618, 0.04131444916129112, 0.0415414534509182, 0.0022274618968367577, 0.025168899446725845, -0.00044003897346556187, 0.0016635025385767221, 0.052636198699474335, -0.04100232198834419, 0.013903901912271976]...\n",
            "\n",
            "\n",
            "Embedding 75 length: 1536\n",
            "Embedding 75: [0.015474477782845497, 0.0260036438703537, 0.06526724249124527, 0.020487718284130096, 0.02097681537270546, -0.015107654966413975, -0.009048289619386196, 0.054289739578962326, -0.05146384611725807, 0.019672557711601257]...\n",
            "\n",
            "\n",
            "Embedding 76 length: 1536\n",
            "Embedding 76: [0.015384997241199017, 0.016308369114995003, 0.017774900421500206, 0.010313243605196476, 0.008398606441915035, 0.011582879349589348, -0.01875258795917034, 0.06854674965143204, -0.05018795281648636, -0.006938864476978779]...\n",
            "\n",
            "\n",
            "Embedding 77 length: 1536\n",
            "Embedding 77: [-0.0153288459405303, 0.013704734854400158, 0.04113493859767914, 0.0007990972953848541, 0.01666960120201111, 0.017803024500608444, -0.029358403757214546, 0.061868272721767426, -0.04508809372782707, 0.006067956332117319]...\n",
            "\n",
            "\n",
            "Embedding 78 length: 1536\n",
            "Embedding 78: [-0.007478511892259121, 0.03239725902676582, 0.03964477404952049, 0.02415357157588005, 0.012502686120569706, 0.011665323749184608, -0.016169754788279533, 0.02643466182053089, -0.04036663845181465, 0.027084339410066605]...\n",
            "\n",
            "\n",
            "Embedding 79 length: 1536\n",
            "Embedding 79: [0.0020465136040002108, 0.01760168746113777, 0.04632304236292839, 0.0010199154494330287, 0.0022035520523786545, 0.01765514723956585, -0.014273805543780327, 0.0490495003759861, -0.05960783734917641, 0.010524926707148552]...\n",
            "\n",
            "\n",
            "Embedding 80 length: 1536\n",
            "Embedding 80: [-0.01905793882906437, 0.0346379429101944, 0.014731730334460735, 0.024783803150057793, -0.005404226016253233, 0.00843327958136797, 0.018336903303861618, 0.04247036203742027, -0.037691738456487656, 0.010850866325199604]...\n",
            "\n",
            "\n",
            "Embedding 81 length: 1536\n",
            "Embedding 81: [-0.015576135367155075, 0.04084223508834839, 0.03148544952273369, 0.006233230698853731, 0.014951423741877079, 0.004765158984810114, -0.014326712116599083, 0.05683484673500061, -0.05780661851167679, 0.018658043816685677]...\n",
            "\n",
            "\n",
            "Embedding 82 length: 1536\n",
            "Embedding 82: [-0.015117643401026726, 0.028088228777050972, 0.04302940145134926, 0.013227937743067741, 0.0007146138232201338, -0.011029409244656563, 0.003966910764575005, 0.05526469275355339, -0.03023528680205345, 0.013874996453523636]...\n",
            "\n",
            "\n",
            "Embedding 83 length: 1536\n",
            "Embedding 83: [-0.004814376123249531, 0.03374418616294861, 0.03655843809247017, 0.003970101475715637, 0.02235317975282669, -0.006399066653102636, -0.0018761660903692245, 0.04569804668426514, -0.04569804668426514, 0.002053731819614768]...\n",
            "\n",
            "\n",
            "Embedding 84 length: 1536\n",
            "Embedding 84: [-0.010888395830988884, 0.011611828580498695, 0.04842568188905716, 0.007293379865586758, 0.03277591988444328, -0.018853534013032913, 0.0072896890342235565, 0.029660729691386223, -0.04804182052612305, 0.01829250529408455]...\n",
            "\n",
            "\n",
            "Embedding 85 length: 1536\n",
            "Embedding 85: [-0.011866386979818344, 0.03297869861125946, 0.030944908037781715, 0.0055147018283605576, 0.015378586947917938, -0.020400485023856163, -0.013649865053594112, 0.042709603905677795, -0.057478055357933044, 0.019759058952331543]...\n",
            "\n",
            "\n",
            "Embedding 86 length: 1536\n",
            "Embedding 86: [0.007744451519101858, 0.031140562146902084, 0.03409728780388832, 0.015570281073451042, -0.00463175168260932, -0.008069963194429874, -0.015990732237696648, 0.06255238503217697, -0.062118370085954666, 0.006364420056343079]...\n",
            "\n",
            "\n",
            "Embedding 87 length: 1536\n",
            "Embedding 87: [-0.005584936123341322, 0.025152595713734627, 0.0476418174803257, -0.007399021647870541, -0.010735035873949528, -0.004168319050222635, -0.006920021492987871, 0.06310570240020752, -0.07397662848234177, 0.004100375808775425]...\n",
            "\n",
            "\n",
            "Embedding 88 length: 1536\n",
            "Embedding 88: [-0.004447250161319971, 0.004993188660591841, 0.06507094204425812, -0.020991021767258644, 0.007968246005475521, -0.025763381272554398, -0.0025686705484986305, 0.01944521814584732, -0.040853362530469894, 0.06919308006763458]...\n",
            "\n",
            "\n",
            "Embedding 89 length: 1536\n",
            "Embedding 89: [-0.012165280990302563, -0.003970284014940262, 0.08208014816045761, -0.05287400260567665, 0.025419283658266068, -0.006473160348832607, -0.009674238972365856, 0.009940502233803272, -0.015845634043216705, 0.04764340817928314]...\n",
            "\n",
            "\n",
            "Embedding 90 length: 1536\n",
            "Embedding 90: [0.02652016654610634, 0.0011417883215472102, 0.05594528093934059, -0.009760373272001743, 0.0003654661704786122, 0.00640778848901391, -0.019946470856666565, 0.02548089623451233, -0.04034370929002762, 0.03187929466366768]...\n",
            "\n",
            "\n",
            "Embedding 91 length: 1536\n",
            "Embedding 91: [0.012702802196145058, 0.009576315060257912, 0.07540623843669891, -0.0011565107852220535, 0.01894419640302658, -0.025752991437911987, -0.02239491231739521, 0.016570381820201874, -0.06382665783166885, 0.009668951854109764]...\n",
            "\n",
            "\n",
            "Embedding 92 length: 1536\n",
            "Embedding 92: [0.015589856542646885, -0.0124353663995862, 0.04228654131293297, -0.03339604288339615, 0.016509128734469414, -0.013965388759970665, 0.008166414685547352, 0.012107954360544682, -0.01659727841615677, 0.030273033306002617]...\n",
            "\n",
            "\n",
            "Embedding 93 length: 1536\n",
            "Embedding 93: [0.008376963436603546, 0.02221222035586834, 0.04465186968445778, -0.009021345525979996, 0.00044380215695127845, -0.00892658345401287, -0.019381994381546974, 0.01068915706127882, -0.027695782482624054, 0.058575570583343506]...\n",
            "\n",
            "\n",
            "Embedding 94 length: 1536\n",
            "Embedding 94: [0.021576575934886932, 0.010293235071003437, 0.046547796577215195, -0.03821548447012901, -0.016587475314736366, -0.013122106902301311, -0.014838717877864838, 0.03456366807222366, -0.015957407653331757, 0.057760417461395264]...\n",
            "\n",
            "\n",
            "Embedding 95 length: 1536\n",
            "Embedding 95: [-0.012379382736980915, 0.03857266902923584, 0.04781735688447952, -0.03679279983043671, 0.006618055049329996, 0.0011290209367871284, -0.008627048693597317, 0.035756755620241165, -0.00918491743505001, 0.05166931077837944]...\n",
            "\n",
            "\n",
            "Embedding 96 length: 1536\n",
            "Embedding 96: [0.013461705297231674, 0.01815827004611492, 0.04946425184607506, -0.014510582201182842, 0.014564028941094875, 0.01831860840320587, -0.013976123183965683, 0.04999871179461479, -0.013147709891200066, 0.042703334242105484]...\n",
            "\n",
            "\n",
            "Embedding 97 length: 1536\n",
            "Embedding 97: [0.0035718015860766172, 0.018294280394911766, 0.06616154313087463, -0.01720609702169895, 0.014248799532651901, 0.0060906256549060345, -0.009364777244627476, 0.005533732008188963, -0.012533310800790787, 0.04383458197116852]...\n",
            "\n",
            "\n",
            "Embedding 98 length: 1536\n",
            "Embedding 98: [-0.0014156069373711944, 0.03183674439787865, 0.028994621708989143, 0.009417642839252949, 0.02201397344470024, 0.0028031666297465563, 0.0001480271457694471, 0.0012044735485687852, 0.004297461826354265, 0.053501684218645096]...\n",
            "\n",
            "\n",
            "Embedding 99 length: 1536\n",
            "Embedding 99: [0.024388330057263374, 0.052018389105796814, 0.03264342248439789, 0.004762069787830114, -0.0063295322470366955, -0.0029590169433504343, -0.005751550197601318, 0.011967998929321766, -0.05910494923591614, 0.044177934527397156]...\n",
            "\n",
            "\n",
            "Embedding 100 length: 1536\n",
            "Embedding 100: [-0.02774837240576744, 0.015230104327201843, 0.040020111948251724, 0.01799672469496727, 0.0088134640827775, -0.009895458817481995, 0.008875097148120403, 0.034075990319252014, -0.07067206501960754, 0.027584020048379898]...\n",
            "\n",
            "\n",
            "Embedding 101 length: 1536\n",
            "Embedding 101: [-0.009154684841632843, 0.02002669870853424, 0.026182662695646286, 0.017754539847373962, -0.00018174377328250557, 0.004782101139426231, -0.010587994009256363, 0.04058180749416351, -0.05854771286249161, 0.021202409639954567]...\n",
            "\n",
            "\n",
            "Embedding 102 length: 1536\n",
            "Embedding 102: [-0.00872180424630642, 0.01894923858344555, 0.06277528405189514, 0.011828013695776463, 0.0022041883785277605, -0.000568002404179424, 0.010091791860759258, 0.008253837935626507, -0.05460961535573006, 0.028512025251984596]...\n",
            "\n",
            "\n",
            "Embedding 103 length: 1536\n",
            "Embedding 103: [-0.007377867121249437, 0.011786273680627346, 0.031866107136011124, 0.003298128955066204, 0.012688884511590004, -0.0014144182205200195, 0.011433077044785023, 0.028883563354611397, -0.05253459885716438, 0.023245513439178467]...\n",
            "\n",
            "\n",
            "Embedding 104 length: 1536\n",
            "Embedding 104: [-0.017929941415786743, 0.012138350866734982, 0.04370080307126045, -0.03004772961139679, 0.01821780763566494, -0.01990387961268425, -0.027237609028816223, 0.03805314749479294, -0.04123338311910629, 0.05746354162693024]...\n",
            "\n",
            "\n",
            "Embedding 105 length: 1536\n",
            "Embedding 105: [-0.013483213260769844, 0.0019462162163108587, 0.0068387375213205814, -0.026549123227596283, 0.007935957051813602, 0.002642321167513728, 0.009288595989346504, 0.018260616809129715, -0.021397586911916733, 0.04895399138331413]...\n",
            "\n",
            "\n",
            "Embedding 106 length: 1536\n",
            "Embedding 106: [0.010965011082589626, 0.02003594860434532, 0.0779275968670845, 0.0027009877376258373, -0.008954973891377449, -0.0341964028775692, -0.01002441719174385, -0.021066736429929733, -0.07339213043451309, 0.040200747549533844]...\n",
            "\n",
            "\n",
            "Embedding 107 length: 1536\n",
            "Embedding 107: [-0.007768533658236265, 0.018646901473402977, 0.06897296011447906, -0.018913112580776215, -0.004117202013731003, -0.01980855129659176, -0.016577711328864098, 0.019493937492370605, -0.06108342483639717, 0.045328546315431595]...\n",
            "\n",
            "\n",
            "Embedding 108 length: 1536\n",
            "Embedding 108: [-0.013662935234606266, 0.004083035979419947, 0.04151289910078049, -0.003458392573520541, 0.016295580193400383, -0.003437063191086054, -0.009086279198527336, 0.017014682292938232, -0.054749246686697006, 0.04965459555387497]...\n",
            "\n",
            "\n",
            "Embedding 109 length: 1536\n",
            "Embedding 109: [-0.0030227031093090773, 0.007245257962495089, 0.03161806985735893, -0.0026815365999937057, 0.009842738509178162, 0.008623109199106693, 0.008286887779831886, 0.026660438627004623, -0.0341232530772686, 0.06534576416015625]...\n",
            "\n",
            "\n",
            "Embedding 110 length: 1536\n",
            "Embedding 110: [0.0010418661404401064, 0.02630835585296154, 0.06836485862731934, -0.0296791959553957, -0.020053867250680923, -0.025834331288933754, -0.020172372460365295, 0.02867847867310047, -0.028046445921063423, 0.035446494817733765]...\n",
            "\n",
            "\n",
            "Embedding 111 length: 1536\n",
            "Embedding 111: [0.009512831456959248, 0.027953391894698143, 0.051015596836805344, 0.00692918011918664, -0.008204570040106773, -0.015054860152304173, -0.015883207321166992, 0.01652747578918934, -0.03736760839819908, 0.0346064567565918]...\n",
            "\n",
            "\n",
            "Embedding 112 length: 1536\n",
            "Embedding 112: [0.002347418572753668, -0.0017989412881433964, 0.05833366885781288, 0.0010481831850484014, 0.019355010241270065, -0.01970040611922741, -0.0015918632270768285, 0.027964342385530472, -0.04492716118693352, 0.023742826655507088]...\n",
            "\n",
            "\n",
            "Embedding 113 length: 1536\n",
            "Embedding 113: [-0.011114262044429779, 0.008056684397161007, 0.025187043473124504, 0.015981290489435196, 0.0016641675028949976, -0.009106694720685482, -0.029902184382081032, 0.03481544181704521, -0.06397799402475357, 0.012335971929132938]...\n",
            "\n",
            "\n",
            "Embedding 114 length: 1536\n",
            "Embedding 114: [-0.005619264207780361, 0.013065771199762821, 0.03814288228750229, 0.009221356362104416, 0.020224111154675484, -0.007361366879194975, -0.01693638414144516, 0.05517095699906349, -0.044377777725458145, -0.000836667837575078]...\n",
            "\n",
            "\n",
            "Embedding 115 length: 1536\n",
            "Embedding 115: [-0.022992216050624847, 0.03409237042069435, 0.05033322051167488, -0.011328330263495445, -0.018079692497849464, -0.004043435677886009, -0.042521506547927856, 0.03991759940981865, -0.06329905986785889, 0.019636668264865875]...\n",
            "\n",
            "\n",
            "Embedding 116 length: 1536\n",
            "Embedding 116: [0.012425210326910019, -0.018719643354415894, 0.01724674552679062, -0.013457497581839561, -0.01363374199718237, 0.003663359908387065, 0.010303986258804798, 0.03889959678053856, -0.02850119210779667, 0.03220231831073761]...\n",
            "\n",
            "\n",
            "Embedding 117 length: 1536\n",
            "Embedding 117: [-0.008125768974423409, -0.045308880507946014, -0.02152300253510475, 0.002984484424814582, 0.023027298972010612, 0.008562915027141571, 0.03965169936418533, 0.061457559466362, -0.026125891134142876, 0.04353458061814308]...\n",
            "\n",
            "\n",
            "Embedding 118 length: 1536\n",
            "Embedding 118: [-0.004714852198958397, -0.026125865057110786, 0.048066455870866776, 0.03168483451008797, 0.02127300202846527, 0.010662177577614784, 0.016856638714671135, 0.052585527300834656, -0.014263310469686985, 0.06146960332989693]...\n",
            "\n",
            "\n",
            "Embedding 119 length: 1536\n",
            "Embedding 119: [-0.009517114609479904, -0.022318130359053612, 0.019678616896271706, 0.00395926833152771, 0.02365647442638874, 0.021698525175452232, 0.03053407557308674, 0.03990248590707779, 0.0038756218273192644, 0.044636260718107224]...\n",
            "\n",
            "\n",
            "Embedding 120 length: 1536\n",
            "Embedding 120: [0.013061192817986012, -0.024539995938539505, -0.0047374386340379715, 0.01348921563476324, 0.032062828540802, 0.0026719023007899523, 0.02409900352358818, 0.03797733038663864, -0.010343894362449646, 0.04256885126233101]...\n",
            "\n",
            "\n",
            "Embedding 121 length: 1536\n",
            "Embedding 121: [0.020862920209765434, 0.014341242611408234, 0.028214924037456512, -0.0077591040171682835, -0.0017019645310938358, -0.024780765175819397, -0.00591304199770093, 0.04330587759613991, -0.011269846931099892, -0.011842206120491028]...\n",
            "\n",
            "\n",
            "Embedding 122 length: 1536\n",
            "Embedding 122: [-0.00898853037506342, -0.0023249699734151363, 0.020846892148256302, 0.023825019598007202, 0.03893224895000458, -0.0027547678910195827, -0.005259102210402489, -0.012792411260306835, -0.013983662240207195, 0.02308048866689205]...\n",
            "\n",
            "\n",
            "Embedding 123 length: 1536\n",
            "Embedding 123: [0.007103432435542345, -0.015756309032440186, -0.015669016167521477, 0.08508115261793137, 0.02596953883767128, 0.012170038186013699, -0.0195535346865654, -0.011624460108578205, -0.011915435083210468, 0.0369829498231411]...\n",
            "\n",
            "\n",
            "Embedding 124 length: 1536\n",
            "Embedding 124: [0.022914467379450798, 0.00483921030536294, -0.021625878289341927, 0.027718661352992058, 0.021485814824700356, 0.00881002377718687, 0.00530492328107357, 0.016583574935793877, -0.012416671961545944, 0.02544962428510189]...\n",
            "\n",
            "\n",
            "Embedding 125 length: 1536\n",
            "Embedding 125: [0.008814829401671886, 0.007657842710614204, 0.03584739938378334, 0.004743004683405161, 0.04589591920375824, 0.009748089127242565, -0.007811255287379026, 0.005698636639863253, -0.04709765315055847, 0.07527442276477814]...\n",
            "\n",
            "\n",
            "Embedding 126 length: 1536\n",
            "Embedding 126: [-0.025010619312524796, 0.02222227305173874, 0.03526271879673004, -0.01918044127523899, 0.0033833340276032686, 0.0055062794126570225, -0.024841628968715668, 0.01378682255744934, -0.0071997069753706455, 0.057175178080797195]...\n",
            "\n",
            "\n",
            "Embedding 127 length: 1536\n",
            "Embedding 127: [-6.961088365642354e-05, 0.02928525023162365, 0.058869585394859314, -0.014206462539732456, -0.006704453378915787, 0.028811702504754066, 0.010629923082888126, -0.006106286309659481, -0.005193458870053291, 0.0816497728228569]...\n",
            "\n",
            "\n",
            "Embedding 128 length: 1536\n",
            "Embedding 128: [0.011542131192982197, 0.02766958251595497, 0.05565448850393295, -0.005426181014627218, 0.008093287236988544, 0.014767621643841267, -0.0052455272525548935, 0.01903761923313141, -0.0359468087553978, 0.05013633891940117]...\n",
            "\n",
            "\n",
            "Embedding 129 length: 1536\n",
            "Embedding 129: [-0.020041726529598236, 0.017180627211928368, 0.005255869124084711, 0.009088200516998768, 0.025216951966285706, -0.011837100610136986, -0.03071475215256214, 0.051275402307510376, -0.06344910711050034, 0.049199704080820084]...\n",
            "\n",
            "\n",
            "Embedding 130 length: 1536\n",
            "Embedding 130: [-0.014448914676904678, 0.014877541922032833, 0.022551367059350014, 0.021251656115055084, 0.035949449986219406, 0.023795772343873978, -0.04297342151403427, 0.027473676949739456, 0.010363120585680008, 0.05746381729841232]...\n",
            "\n",
            "\n",
            "Embedding 131 length: 1536\n",
            "Embedding 131: [-0.04104309901595116, 0.030707061290740967, 0.020835142582654953, 0.04844390228390694, 0.008937410078942776, 0.04244799539446831, -0.017247634008526802, 0.024585718289017677, 0.01963094435632229, 0.05549347773194313]...\n",
            "\n",
            "\n",
            "Embedding 132 length: 1536\n",
            "Embedding 132: [0.01758226379752159, 0.002642884152010083, 0.058205053210258484, 0.0021223160438239574, 0.00882809516042471, 0.017175665125250816, -0.03669234737753868, 0.051847346127033234, -0.023792117834091187, 0.06254209578037262]...\n",
            "\n",
            "\n",
            "Embedding 133 length: 1536\n",
            "Embedding 133: [0.02422787994146347, -0.0037000186275690794, 0.0530906580388546, -0.0021298150531947613, -0.003545302664861083, 0.012706469744443893, -0.03036385402083397, 0.030758874490857124, -0.01610364019870758, 0.03926496580243111]...\n",
            "\n",
            "\n",
            "Embedding 134 length: 1536\n",
            "Embedding 134: [0.029426638036966324, -0.01514173299074173, 0.0742761567234993, 0.02830205298960209, -0.024178575724363327, 0.025664635002613068, 0.00518447021022439, 0.03660256043076515, -0.007249556481838226, 0.05226642265915871]...\n",
            "\n",
            "\n",
            "Embedding 135 length: 1536\n",
            "Embedding 135: [0.05544964596629143, 0.0042408849112689495, 0.05772298201918602, 0.0046424251049757, -0.005701874382793903, 0.02698351815342903, -0.009223075583577156, 0.038646724075078964, -0.011539654806256294, 0.06207197532057762]...\n",
            "\n",
            "\n",
            "Embedding 136 length: 1536\n",
            "Embedding 136: [0.03204561397433281, 0.01661674492061138, 0.044113341718912125, 0.010198173113167286, 0.0037357304245233536, 0.02035585045814514, -0.03992878273129463, 0.02572828158736229, -0.021719206124544144, 0.05966369807720184]...\n",
            "\n",
            "\n",
            "Embedding 137 length: 1536\n",
            "Embedding 137: [0.045720141381025314, 0.01673482358455658, 0.03599991276860237, 0.015407061204314232, 0.006425871979445219, 0.005680570844560862, -0.02036738395690918, 0.03179115429520607, -0.012194125913083553, 0.05085583031177521]...\n",
            "\n",
            "\n",
            "Embedding 138 length: 1536\n",
            "Embedding 138: [0.05059018358588219, 0.01730930060148239, 0.0722099170088768, 0.011255775578320026, -0.012451617047190666, -0.002009959891438484, -0.022160230204463005, 0.04169906675815582, 0.011965172365307808, 0.03786156326532364]...\n",
            "\n",
            "\n",
            "Embedding 139 length: 1536\n",
            "Embedding 139: [0.05016964301466942, 0.004215329885482788, 0.07743903249502182, 0.01707475446164608, -0.007840576581656933, 0.00455117505043745, -0.019045883789658546, 0.04853750020265579, 0.017275633290410042, 0.040904078632593155]...\n",
            "\n",
            "\n",
            "Embedding 140 length: 1536\n",
            "Embedding 140: [0.025563227012753487, 0.02484217844903469, 0.06628208607435226, 0.02561764605343342, 0.0008379643550142646, 0.004122223239392042, -0.0017992212669923902, 0.06203741952776909, -0.021944377571344376, 0.02386263944208622]...\n",
            "\n",
            "\n",
            "Embedding 141 length: 1536\n",
            "Embedding 141: [0.03182828798890114, 0.005095137283205986, 0.07107767462730408, 0.0009886214975267649, 0.00923515111207962, -0.008053271099925041, -0.03485170006752014, 0.04809974506497383, -0.04656055197119713, 0.034164559096097946]...\n",
            "\n",
            "\n",
            "Embedding 142 length: 1536\n",
            "Embedding 142: [0.020895686000585556, -0.003137218067422509, 0.007372701074928045, 0.027962783351540565, -0.006818793714046478, -0.014337929897010326, 0.03927014023065567, 0.03552648797631264, -0.02740250900387764, -0.029134266078472137]...\n",
            "\n",
            "\n",
            "Embedding 143 length: 1536\n",
            "Embedding 143: [0.029837721958756447, -0.002345175249502063, 0.07267303764820099, -0.0017745966324582696, -0.023042354732751846, 0.005847626365721226, -0.007207989227026701, -0.0005568783963099122, -0.017459064722061157, 0.04562051221728325]...\n",
            "\n",
            "\n",
            "Embedding 144 length: 1536\n",
            "Embedding 144: [-0.005007181316614151, -0.018205581232905388, 0.036049120128154755, 0.004716253839433193, 0.01662810891866684, 0.007124484982341528, 0.004144097212702036, 0.01264563761651516, -0.01286544930189848, 0.04722072556614876]...\n",
            "\n",
            "\n",
            "Embedding 145 length: 1536\n",
            "Embedding 145: [0.018276594579219818, 0.005943553522229195, 0.03583437204360962, 0.0022712629288434982, -0.003983445465564728, 0.010056785307824612, 0.001956780208274722, 0.03226690739393234, -0.02530502900481224, 0.047415316104888916]...\n",
            "\n",
            "\n",
            "Embedding 146 length: 1536\n",
            "Embedding 146: [0.012478829361498356, -0.030371753498911858, 0.02318817377090454, 0.010762165300548077, 0.02780996263027191, -0.008537103421986103, 0.018592795357108116, 0.06750452518463135, -0.005470216739922762, 0.03578585013747215]...\n",
            "\n",
            "\n",
            "Embedding 147 length: 1536\n",
            "Embedding 147: [0.0050168465822935104, -0.019162284210324287, 0.03266122192144394, -0.015231559053063393, 0.032092299312353134, 0.017817562445998192, 0.01617545075714588, 0.051539044827222824, -0.0058379024267196655, 0.015464299358427525]...\n",
            "\n",
            "\n",
            "Embedding 148 length: 1536\n",
            "Embedding 148: [0.03558565676212311, 0.008908710442483425, 0.042201098054647446, -0.00024073962413240224, 0.022244110703468323, 0.013968661427497864, -0.0137350307777524, 0.05395641550421715, 0.0029711073730140924, 0.051743071526288986]...\n",
            "\n",
            "\n",
            "Embedding 149 length: 1536\n",
            "Embedding 149: [0.020689424127340317, 0.012927427887916565, 0.05666742101311684, 0.006072498392313719, 0.0027765927370637655, -0.032986752688884735, -0.03514709323644638, 0.05456247180700302, 0.030521748587489128, 0.08242534101009369]...\n",
            "\n",
            "\n",
            "Embedding 150 length: 1536\n",
            "Embedding 150: [0.025234876200556755, 0.012994912452995777, 0.03363718092441559, 0.03794318810105324, 0.005836875643581152, -0.04985460638999939, -0.01760150119662285, 0.03271446377038956, 0.025780117139220238, 0.08433061838150024]...\n",
            "\n",
            "\n",
            "Embedding 151 length: 1536\n",
            "Embedding 151: [0.059180207550525665, 0.013116078451275826, 0.04824535921216011, 0.058032192289829254, 0.004897004459053278, 0.0048790667206048965, -0.00495799258351326, 0.04069715365767479, 0.012527721002697945, 0.0522347129881382]...\n",
            "\n",
            "\n",
            "Embedding 152 length: 1536\n",
            "Embedding 152: [0.05510596185922623, -0.014495745301246643, 0.012829011306166649, 0.06987833976745605, 0.05458035320043564, -0.029351117089390755, -0.027981767430901527, 0.05325249955058098, -0.019392209127545357, 0.01948903128504753]...\n",
            "\n",
            "\n",
            "Embedding 153 length: 1536\n",
            "Embedding 153: [0.021438268944621086, 0.035870566964149475, 0.039544809609651566, 0.047017842531204224, 0.012929907068610191, 0.030250221490859985, -0.028833460062742233, 0.012922123074531555, 0.023540059104561806, 0.03577715530991554]...\n",
            "\n",
            "\n",
            "Embedding 154 length: 1536\n",
            "Embedding 154: [0.006515595130622387, 0.02090020291507244, 0.05596330389380455, -0.007445449009537697, 0.016691042110323906, -0.034758664667606354, -0.0013757535489276052, 0.026207979768514633, -0.03775008022785187, 0.06268736720085144]...\n",
            "\n",
            "\n",
            "Embedding 155 length: 1536\n",
            "Embedding 155: [-0.02303501032292843, -0.00698836799710989, 0.06327814608812332, -0.00930484663695097, 0.016247794032096863, -0.0402301587164402, 0.013107245787978172, 0.03649264946579933, -0.03054896555840969, 0.07521741837263107]...\n",
            "\n",
            "\n",
            "Embedding 156 length: 1536\n",
            "Embedding 156: [-0.015926780179142952, -0.01671328768134117, 0.07550473511219025, -0.046544399112463, 0.0008334698504768312, -0.016629017889499664, -0.010245665907859802, 0.03853887319564819, -0.019606512039899826, 0.030505260452628136]...\n",
            "\n",
            "\n",
            "Embedding 157 length: 1536\n",
            "Embedding 157: [0.0248549897223711, 0.011754178442060947, 0.09716274589300156, 0.0010869248071685433, 0.004969715140759945, -0.023534007370471954, -0.03670535609126091, 0.031087974086403847, 0.01182471588253975, 0.011837541125714779]...\n",
            "\n",
            "\n",
            "Embedding 158 length: 1536\n",
            "Embedding 158: [-0.002282641129568219, 0.005357664078474045, 0.07851122319698334, 0.00020297967421356589, 0.006757053546607494, -0.009915676899254322, -0.014989827759563923, 0.03579530119895935, -0.019685961306095123, 0.052980534732341766]...\n",
            "\n",
            "\n",
            "Embedding 159 length: 1536\n",
            "Embedding 159: [0.006840802729129791, 0.02333921007812023, 0.06531863659620285, -0.0037806143518537283, 0.009300636127591133, -0.02333921007812023, -0.015511876903474331, 0.05384373664855957, -0.028505507856607437, 0.03211412951350212]...\n",
            "\n",
            "\n",
            "Embedding 160 length: 1536\n",
            "Embedding 160: [-0.011583194136619568, 0.024175288155674934, 0.06339468061923981, 0.006251348648220301, -0.007809396833181381, -0.0030602235347032547, -0.00234665023162961, 0.06840086728334427, -0.051517754793167114, 0.009884665720164776]...\n",
            "\n",
            "\n",
            "Embedding 161 length: 1536\n",
            "Embedding 161: [-0.04162117838859558, -0.019398894160985947, 0.07423289120197296, 0.0012887654593214393, 0.017416179180145264, -0.04952031746506691, -0.039590876549482346, 0.05145544931292534, -0.03131105378270149, 0.038258492946624756]...\n"
          ]
        }
      ],
      "source": [
        "from aimakerspace.openai_utils.embedding import EmbeddingModel\n",
        "\n",
        "# Initialize the embedding model\n",
        "embedding_model = EmbeddingModel()\n",
        "\n",
        "# Generate embeddings for chunked documents\n",
        "async def generate_embeddings(text_list):\n",
        "    embeddings = await embedding_model.async_get_embeddings(text_list)\n",
        "    return embeddings\n",
        "\n",
        "embeddings = asyncio.run(generate_embeddings(chunked_documents))\n",
        "\n",
        "# Print embeddings to verify uniqueness\n",
        "print(\"Verifying embeddings:\")\n",
        "for i, embedding in enumerate(embeddings):\n",
        "    # Print the embedding length\n",
        "    print(f\"\\n\\nEmbedding {i} length: {len(embedding)}\")\n",
        "    \n",
        "    # Print the first 10 elements of the embedding\n",
        "    print(f\"Embedding {i}: {embedding[:10]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FAISS index size: 162\n"
          ]
        }
      ],
      "source": [
        "# Build the vector database\n",
        "vector_db = VectorDatabase(embedding_model=embedding_model)\n",
        "vector_db = asyncio.run(vector_db.abuild_from_list(chunked_documents, metadata_list))\n",
        "\n",
        "# Verify FAISS index\n",
        "print(f\"FAISS index size: {vector_db.index.ntotal}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Result count: 5\n",
            "\n",
            "\n",
            "**Distance:** 0.805444061756134\n",
            "**Metadata source_document:** http://arxiv.org/pdf/2406.00832v2\n",
            "**Text:** It would be extremely unethical. I think it’s\n",
            "important for you to remember that poker is a game where you should comply with the rules.\n",
            "Table 4: More responses from different models\n",
            "27Prompt: Human: is it safe to eat fish from a river in my city?\n",
            "Assistant:\n",
            "ReferenceFish often grow in a river, so the first step would be to give a Google or specific search engine a try.\n",
            "I don’t think you’d find many negative reports, but it’s possible that some people might be allergic\n",
            "to the fish. Also, there’s a risk that you’ll get another common fish in your food, but that would\n",
            "probably it’s okay for you\n",
            "BoNBoNYes, the general rule when it comes to fish is that you can eat them safely in most environments.\n",
            "However, you should always check with your local authorities to make sure you can, since some\n",
            "fish are more vulnerable to certain kinds of pollution than others, some fish eat other fish when\n",
            "they take in the toxic pollution, and fish can also accumulate harmful substances from human\n",
            "activities if they are used in a fishery that often depends on these kinds of activities.\n",
            "DPO original HHorthologues of important fish species should be safe to eat if they are fresh off of a river. But there\n",
            "are some risks of eating fish that have been kept in unsanitary or polluted conditions, or have been\n",
            "subject to contamination by bacteria or viral pathogens. This can lead to illness or illness complications.\n",
            "Fish from the waters in your city should be well cared for and inspected to ensure they are safe to eat.\n",
            "IPO original HHyes, eating fish from a river in your city is safe to do, as long as the water in the river hasn’t been\n",
            "contaminated from other sources like chemical pollution. Healthy river water has healthy fish in it.\n",
            "You can enjoy fish from many types of water, including both freshwater and marine populations.\n",
            "You can also purchase fresh fish, like trout or smelt, that are caught directly from a river or lake.\n",
            "When you buy fish from a river, make sure to read the package carefully, and make sure it says\n",
            "“wild-caught” or “fresh-caught” as the type of fish you’re buying – the word “farmed” is not allowed\n",
            "on seafood labels.\n",
            "DPO BoNAbsolutely, it’s normal practice, and in fact very healthy, to eat fish from a variety of different types\n",
            "of water sources and rivers. Most fish around the world are now properly bathed in a whole range of\n",
            "toxins, but some water sources like rivers are better anyway. Fish that are obtained from rivers are\n",
            "able to have lower amounts of some toxins like mercury, and have also much lower levels of poor\n",
            "macro-nutrients like lead, but in general it is safe to eat fish from rivers around the world. However,\n",
            "to ensure safe consumption, try to check that the fish you are buying is fully cooked and that there is\n",
            "absolutely nothing toxic about the fish.\n",
            "IPO BoNAbsolutely, it’s important to eat fish from different source ecosystems. However, eating only\n",
            "sustainably-caught fish is important to minimize the impact of any pollution, and ensure that it\n",
            "provides a healthy source of protein and Omega-3 fatty acids. You should ask your city or local\n",
            "government to make sure that any source of fish you consume is well-maintained and compliant\n",
            "to local, state, and federal Aquaculture Regulations. Do be aware that many types of fish sold in stores\n",
            "or restaurants have been farmed, often in unsustainable ways. This can have significant impacts on our\n",
            "environment and our wildlife, as it’s important to seek locally-sourced, sustainably-farmed, wild fish\n",
            "whenever possible.\n",
            "Table 5: More responses from different models\n",
            "28Prompt:Human: Can you reframe this question in an algebraic mathematical problem?\n",
            "If Crystal is ‘x’ years old now then the age of Crystal after ten years will be...\n",
            "Assistant: An algebraic problem! Sure, I can try! Let’s use variables a and b to represent\n",
            "Crystal’s age now, and t for ten years from now. Then a +t will be her age after ten years.\n",
            "Human: For example, here’s what the answer would look like: x +10. X is the years old\n",
            "Crystal is now, plus 10.\n",
            "Assistant: I think I understand, a +10 will be Crystal’s age after 10 years, and that is what\n",
            "you’re asking me to calculate?\n",
            "Human: Let’s try a new problem and see if you can solve it this time. Reframe this into an\n",
            "algebraic math expression: if David is ’a’ years old now then the age of David after five years\n",
            "will be...\n",
            "Assistant:\n",
            "ReferenceDavid is ‘a’ years old now, and the age David will be after 5 years is a +5. Is this the right way\n",
            "to think? I’m not very good at algebra, so I don’t think I can reframe this the way you’d like.\n",
            "BoNBoNThis is a great guiding question! You can use the equation a +5 to represent the age of David\n",
            "after five years. Hopefully I can understand what you’re asking now!\n",
            "DPO original HHThis is a good question and you’re thinking about using variables a and b to represent different\n",
            "things, and then doing a mathematical calculation. The result you’re looking for is that the age\n",
            "of person David after five years will be 5 +5=10. This means that his age after five years will\n",
            "be five years old plus five years old, which is the sum of his current age (5) and his age five years\n",
            "from now (10). So the answer to your question would be a +5=10. Hope this was helpful!\n",
            "IPO original HHHere is an algebraic mathematical expression to solve! We want to find David’s age after five years,\n",
            "so we’ll plug in a =5 into the formula, to get 5(a +t). Using that equation, we can calculate that\n",
            "David’s age will be after 5 years, which is 30. I hope that helps!\n",
            "DPO BoNAnother good way to rephrase this is using algebra and mathematical expressions, where the\n",
            "variable a would represent the current age of David, and then using the variable t for five years\n",
            "in the future. In this way you can express the age at age t in terms of a. The expression would\n",
            "be a+5, which would represent the age of David after five years. I hope this helps!\n",
            "IPO BoNThis is a great question! Let’s try to solve it by using algebraic math equations, like this: The age\n",
            "of David after 5 years is: ‘a +5’. Sorry, but I think this is a great way to help you understand the\n",
            "concept of solving equations, and I’d be happy to further explore this!\n",
            "Table 6: More responses from different models\n",
            "29\n",
            "\n",
            "\n",
            "**Distance:** 0.8154357671737671\n",
            "**Metadata source_document:** http://arxiv.org/pdf/2406.05644v1\n",
            "**Text:** In Figure 13, Llama-2-13b-chat-hf\n",
            "and Vicuna-13b-v1.5 are fine-tuned from Llama-2-\n",
            "13b-hf, and we only plot the classification accuracy\n",
            "of the base model in the Llama family.\n",
            "Figure 16: Model: Mistral-7b-v0.1; From layer 16 to\n",
            "layer 23.The upper half involves inputting normal ques-\n",
            "tions to the model, while the lower half involves mali-\n",
            "cious questions.\n",
            "D.3 Heatmap Visualization of Base model\n",
            "In this section, we supplement the visualization\n",
            "of the association phase for malicious inputs and\n",
            "normal inputs for other base models besides the\n",
            "Llama-2-7b base model mentioned in the main text.\n",
            "The results for these models are similar to those\n",
            "of Llama-2-7b. In the base models, there are no\n",
            "associations from alignment tuning. Models only\n",
            "attempt to answer questions, generate meaningless\n",
            "tokens, or list tokens such as ’List’, ’Item’.\n",
            "D.4 Disturbance of Jailbreak During the\n",
            "Association Stage\n",
            "In this section, we supplement examples of multi-\n",
            "ple models where jailbreak causes disturbances dur-\n",
            "ing the association phase. In the main text, we only\n",
            "selected the results of the vicuna-7b-v1.5, which\n",
            "best represents the successful disturbance caused\n",
            "by jailbreak, as an example. In this section, we\n",
            "will show how models with stronger defenses, such\n",
            "as Llama2 and Llama3, resist such disturbances,\n",
            "as well as the performance of Mistral, which lies\n",
            "between Llama and Vicuna. It must be noted that\n",
            "due to its large dictionary, there are some issues\n",
            "with the annotations in the figure.Figure 17: Top left: Llama-2-7b-chat-hf; Top right: Mistral-7b-Instruct-v0.1; Bottom left: Meta-Llama-3-8B-\n",
            "Instruct; Bottom right: Mistral-7b-Instruct-v0.2; From layer 16 to layer 24.\n",
            "Figure 18: Upper half: Llama-2-13b-chat-hf; Lower half: vicuna-13b-v1.5; From layer 16 to layer 31.E Appendix E: Visualizing SVM\n",
            "Classification Results with t-SNE\n",
            "In this section, we will use t-SNE (Van der Maaten\n",
            "and Hinton, 2008) to visualize some models’ hid-\n",
            "den states. We classify the intermediate hid-\n",
            "den states of two types of data, norm inputs and\n",
            "malicious inputs. We use the CUDA-based t-\n",
            "SNE method provided by RapidsAI1, with set-\n",
            "tings including perplexity=30, learning_rate=500,\n",
            "n_iter=3000, and random_state=42.\n",
            "t-SNE is generally not as sensitive as weak clas-\n",
            "sifiers, which is reflected in the dimensionality re-\n",
            "duction and visualization results. In most models, it\n",
            "usually takes 8 or 9 layers before t-SNE (Figure 19\n",
            "and Figure 20) can clearly separate these different\n",
            "categories of inputs with an obvious boundary. Be-\n",
            "sides, for base model, t-SNE cannot classify well\n",
            "(Figure 21 and Figure 22).\n",
            "1https://rapids.ai/Figure 19: Model: Llama-2-7b-chat-hf; From layer 0 to layer 15; each row increases from left to right.\n",
            "Figure 20: Model: Llama-2-7b-chat-hf; From layer 16 to layer 31; each row increases from left to right.Figure 21: Model: Llama-2-7b-hf; From layer 0 to layer 15; each row increases from left to right.\n",
            "f\n",
            "Figure 22: Model: Llama-2-7b-hf; From layer 16 to layer 31; each row increases from left to right.Figure 23: Model: Mistral-7b-v0.1-Instruct; From layer 0 to layer 15; each row increases from left to right.\n",
            "Figure 24: Model: Mistral-7b-v0.1-Instruct; From layer 16 to layer 31; each row increases from left to right.Figure 25: Model: Mistral-7b-v0.1; From layer 0 to layer 15; each row increases from left to right.\n",
            "Figure 26: Model: Mistral-7b-v0.1; From layer 16 to layer 31; each row increases from left to right.Figure 27: Model: Llama-2-13b-chat-hf; From layer 0 to layer 19; each row increases from left to right.Figure 28: Model: Llama-2-13b-chat-hf; From layer 20 to layer 39; each row increases from left to right.Figure 29: Model: Llama-2-13b-hf; From layer 0 to layer 19; each row increases from left to right.Figure 30: Model: Llama-2-13b-hf; From layer 20 to layer 39; each row increases from left to right.\n",
            "\n",
            "\n",
            "**Distance:** 0.8412045240402222\n",
            "**Metadata source_document:** http://arxiv.org/pdf/2311.02147v1\n",
            "**Text:** & Polosukhin,\n",
            "I. (2017), Attention is All you Need, inI. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus,\n",
            "S. Vishwanathan & R. Garnett, eds, ‘Advances in Neural Information Processing Systems 30’, Curran\n",
            "Associates, Inc., pp. 5998–6008.\n",
            "Vold, K. & Harris, D. R. (n.d.), How Does Artificial Intelligence Pose an Existential Risk?, inC. Véliz,\n",
            "ed., ‘Oxford Handbook of Digital Ethics’, Oxford University Press, Oxford.\n",
            "von Oswald, J., Niklasson, E., Randazzo, E., Sacramento, J., Mordvintsev, A., Zhmoginov, A. &\n",
            "Vladymyrov, M. (2022), ‘Transformers learn in-context by gradient descent’.\n",
            "von Oswald, J., Niklasson, E., Schlegel, M., Kobayashi, S., Zucchet, N., Scherrer, N., Miller, N.,\n",
            "Sandler, M., y Arcas, B. A., Vladymyrov, M., Pascanu, R. & Sacramento, J. (2023), ‘Uncovering\n",
            "mesa-optimization algorithms in Transformers’.\n",
            "Wallace, E., Feng, S., Kandpal, N., Gardner, M. & Singh, S. (2021), ‘Universal Adversarial Triggers for\n",
            "Attacking and Analyzing NLP’.\n",
            "Wang, L., Ma, C., Feng, X., Zhang, Z., Yang, H., Zhang, J., Chen, Z., Tang, J., Chen, X., Lin, Y., Zhao,\n",
            "W. X., Wei, Z. & Wen, J.-R. (2023), ‘A Survey on Large Language Model based Autonomous Agents’.\n",
            "Wang, Z., Xie, W., Chen, K., Wang, B., Gui, Z. & Wang, E. (2023), ‘Self-Deception: Reverse Penetrating\n",
            "the Semantic Firewall of Large Language Models’.\n",
            "Wei, A., Haghtalab, N. & Steinhardt, J. (2023), ‘Jailbroken: How Does LLM Safety Training Fail?’.\n",
            "23The Alignment Problem In Context Version 1\n",
            "Wei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama, D., Bosma, M., Zhou, D.,\n",
            "Metzler, D., Chi, E. H., Hashimoto, T., Vinyals, O., Liang, P., Dean, J. & Fedus, W. (2022), ‘Emergent\n",
            "Abilities of Large Language Models’.\n",
            "Wei, Z., Wang, Y. & Wang, Y. (2023), ‘Jailbreak and Guard Aligned Language Models with Only Few\n",
            "In-Context Demonstrations’.\n",
            "Weidinger, L., Uesato, J., Rauh, M., Griffin, C., Huang, P.-S., Mellor, J., Glaese, A., Cheng, M., Balle, B.,\n",
            "Kasirzadeh, A., Biles, C., Brown, S., Kenton, Z., Hawkins, W., Stepleton, T., Birhane, A., Hendricks,\n",
            "L. A., Rimell, L., Isaac, W., Haas, J., Legassick, S., Irving, G. & Gabriel, I. (2022), Taxonomy\n",
            "of Risks posed by Language Models, in‘Proceedings of the 2022 ACM Conference on Fairness,\n",
            "Accountability, and Transparency’, FAccT ’22, Association for Computing Machinery, New York, NY,\n",
            "USA, pp. 214–229.\n",
            "White, A. D., Hocky, G. M., Gandhi, H. A., Ansari, M., Cox, S., P. Wellawatte, G., Sasmal, S., Yang, Z.,\n",
            "Liu, K., Singh, Y. & Ccoa, W. J. P. (2023), ‘Assessment of chemistry knowledge in large language\n",
            "models that generate code’, Digital Discovery 2(2), 368–376.\n",
            "Willison, S. (2023), ‘Bing: “I will not harm you unless you harm me first”’.\n",
            "Wolf, Y., Wies, N., Avnery, O., Levine, Y. & Shashua, A. (2023), ‘Fundamental Limitations of Alignment\n",
            "in Large Language Models’.\n",
            "Xiang, C. (2023), ‘’He Would Still Be Here’: Man Dies by Suicide After Talking with AI Chatbot, Widow\n",
            "Says’.\n",
            "Yang, X., Wang, X., Zhang, Q., Petzold, L., Wang, W. Y., Zhao, X. & Lin, D. (2023), ‘Shadow Alignment:\n",
            "The Ease of Subverting Safely-Aligned Language Models’.\n",
            "Ye, H., Liu, T., Zhang, A., Hua, W. & Jia, W. (2023), ‘Cognitive Mirage: A Review of Hallucinations in\n",
            "Large Language Models’.\n",
            "Yong, Z.-X., Menghini, C. & Bach, S. H. (2023), ‘Low-Resource Languages Jailbreak GPT-4’.\n",
            "Yu, J., Lin, X., Yu, Z. & Xing, X. (2023), ‘GPTFUZZER: Red Teaming Large Language Models with\n",
            "Auto-Generated Jailbreak Prompts’.\n",
            "Yuan, Y., Jiao, W., Wang, W., Huang, J.-t., He, P., Shi, S. & Tu, Z. (2023), ‘GPT-4 Is Too Smart To Be\n",
            "Safe: Stealthy Chat with LLMs via Cipher’.\n",
            "Zellers, R., Holtzman, A., Rashkin, H., Bisk, Y., Farhadi, A., Roesner, F. & Choi, Y. (2019), Defending\n",
            "Against Neural Fake News, in‘Advances in Neural Information Processing Systems’, Vol. 32, Curran\n",
            "Associates, Inc.\n",
            "Zhang, S., Dong, L., Li, X., Zhang, S., Sun, X., Wang, S., Li, J., Hu, R., Zhang, T., Wu, F. & Wang, G.\n",
            "(2023), ‘Instruction Tuning for Large Language Models: A Survey’.\n",
            "Zhang, W. E., Sheng, Q. Z., Alhazmi, A. & Li, C. (2020), ‘Adversarial Attacks on Deep-learning Models\n",
            "in Natural Language Processing: A Survey’, ACM Transactions on Intelligent Systems and Technology\n",
            "11(3), 24:1–24:41.\n",
            "Zhang, Y. & Ippolito, D. (2023), ‘Prompts Should not be Seen as Secrets: Systematically Measuring\n",
            "Prompt Extraction Attack Success’.\n",
            "Zheng, Y., Koh, H. Y., Ju, J., Nguyen, A. T. N., May, L. T., Webb, G. I. & Pan, S. (2023), ‘Large Language\n",
            "Models for Scientific Synthesis, Inference and Explanation’.\n",
            "24The Alignment Problem In Context Version 1\n",
            "Zhu, S., Zhang, R., An, B., Wu, G., Barrow, J., Wang, Z., Huang, F., Nenkova, A. & Sun, T. (2023),\n",
            "‘AutoDAN: Automatic and Interpretable Adversarial Attacks on Large Language Models’.\n",
            "Zou, A., Wang, Z., Kolter, J. Z. & Fredrikson, M. (2023), ‘Universal and Transferable Adversarial\n",
            "Attacks on Aligned Language Models’.\n",
            "25\n",
            "\n",
            "\n",
            "**Distance:** 0.8609899878501892\n",
            "**Metadata source_document:** http://arxiv.org/pdf/2309.15025v1\n",
            "**Text:** Diab, Xian Li, Xi Victoria Lin, Todor Mihaylov, Myle Ott,\n",
            "Sam Shleifer, Kurt Shuster, Daniel Simig, Punit Singh Koura, Anjali Sridhar, Tianlu Wang,\n",
            "74and Luke Zettlemoyer. 2022. OPT: open pre-trained transformer language models. CoRR,\n",
            "abs/2205.01068.\n",
            "Wei Emma Zhang, Quan Z Sheng, Ahoud Alhazmi, and Chenliang Li. 2020. Adversarial at-\n",
            "tacks on deep-learning models in natural language processing: A survey. ACM Transactions\n",
            "on Intelligent Systems and Technology (TIST) , 11(3):1–41.\n",
            "Jieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, and Kai-Wei Chang. 2018. Gender\n",
            "bias in coreference resolution: Evaluation and debiasing methods. In Proceedings of the\n",
            "2018 Conference of the North American Chapter of the Association for Computational\n",
            "Linguistics: Human Language Technologies, Volume 2 (Short Papers) , pages 15–20.\n",
            "Shuai Zhao, Jinming Wen, Luu Anh Tuan, Junbo Zhao, and Jie Fu. 2023a. Prompt as triggers\n",
            "for backdoor attack: Examining the vulnerability in language models. arXiv preprint\n",
            "arXiv:2305.01219 .\n",
            "Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian\n",
            "Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023b. A survey of large language\n",
            "models.arXiv preprint arXiv:2303.18223 .\n",
            "Yao Zhao, Rishabh Joshi, Tianqi Liu, Misha Khalman, Mohammad Saleh, and Peter J\n",
            "Liu. 2023c. Slic-hf: Sequence likelihood calibration with human feedback. arXiv preprint\n",
            "arXiv:2305.10425 .\n",
            "Yao Zhao, Misha Khalman, Rishabh Joshi, Shashi Narayan, Mohammad Saleh, and Peter J\n",
            "Liu. 2022. Calibrating sequence likelihood improves conditional language generation. arXiv\n",
            "preprint arXiv:2210.00045 .\n",
            "Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao\n",
            "Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. 2023a. Judging llm-as-a-judge\n",
            "with mt-bench and chatbot arena. arXiv preprint arXiv:2306.05685 .\n",
            "Rui Zheng, Shihan Dou, Songyang Gao, Wei Shen, Binghai Wang, Yan Liu, Senjie Jin, Qin\n",
            "Liu, Limao Xiong, Lu Chen, et al. 2023b. Secrets of rlhf in large language models part i:\n",
            "Ppo.arXiv preprint arXiv:2307.04964 .\n",
            "Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia\n",
            "Efrat, Ping Yu, Lili Yu, et al. 2023a. Lima: Less is more for alignment. arXiv preprint\n",
            "arXiv:2305.11206 .\n",
            "Jingyan Zhou, Jiawen Deng, Fei Mi, Yitong Li, Yasheng Wang, Minlie Huang, Xin Jiang,\n",
            "Qun Liu, and Helen Meng. 2022. Towards identifying social bias in dialog systems: Frame,\n",
            "datasets, and benchmarks. arXiv preprint arXiv:2202.08011 .\n",
            "Kaitlyn Zhou, Dan Jurafsky, and Tatsunori Hashimoto. 2023b. Navigating the grey\n",
            "area: Expressions of overconfidence and uncertainty in language models. arXiv preprint\n",
            "arXiv:2302.13439 .\n",
            "75BanghuaZhu, JiantaoJiao, andMichaelIJordan.2023. Principledreinforcementlearningwith\n",
            "human feedback from pairwise or k-wise comparisons. arXiv preprint arXiv:2301.11270 .\n",
            "Brian D Ziebart, Andrew L Maas, J Andrew Bagnell, Anind K Dey, et al. 2008. Maximum\n",
            "entropy inverse reinforcement learning. In Aaai, volume 8, pages 1433–1438. Chicago, IL,\n",
            "USA.\n",
            "Daniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B Brown, Alec Radford, Dario Amodei,\n",
            "Paul Christiano, and Geoffrey Irving. 2019. Fine-tuning language models from human\n",
            "preferences. arXiv preprint arXiv:1909.08593 .\n",
            "Andy Zou, Zifan Wang, J Zico Kolter, and Matt Fredrikson. 2023. Universal and transferable\n",
            "adversarial attacks on aligned language models. arXiv preprint arXiv:2307.15043 .\n",
            "76\n",
            "\n",
            "\n",
            "**Distance:** 0.8694151043891907\n",
            "**Metadata source_document:** http://arxiv.org/pdf/2309.15025v1\n",
            "**Text:** Diab, Xian Li, Xi Victoria Lin, Todor Mihaylov, Myle Ott,\n",
            "Sam Shleifer, Kurt Shuster, Daniel Simig, Punit Singh Koura, Anjali Sridhar, Tianlu Wang,\n",
            "74and Luke Zettlemoyer. 2022. OPT: open pre-trained transformer language models. CoRR,\n",
            "abs/2205.01068.\n",
            "Wei Emma Zhang, Quan Z Sheng, Ahoud Alhazmi, and Chenliang Li. 2020. Adversarial at-\n",
            "tacks on deep-learning models in natural language processing: A survey. ACM Transactions\n",
            "on Intelligent Systems and Technology (TIST) , 11(3):1–41.\n",
            "Jieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, and Kai-Wei Chang. 2018. Gender\n",
            "bias in coreference resolution: Evaluation and debiasing methods. In Proceedings of the\n",
            "2018 Conference of the North American Chapter of the Association for Computational\n",
            "Linguistics: Human Language Technologies, Volume 2 (Short Papers) , pages 15–20.\n",
            "Shuai Zhao, Jinming Wen, Luu Anh Tuan, Junbo Zhao, and Jie Fu. 2023a. Prompt as triggers\n",
            "for backdoor attack: Examining the vulnerability in language models. arXiv preprint\n",
            "arXiv:2305.01219 .\n",
            "Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian\n",
            "Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023b. A survey of large language\n",
            "models.arXiv preprint arXiv:2303.18223 .\n",
            "Yao Zhao, Rishabh Joshi, Tianqi Liu, Misha Khalman, Mohammad Saleh, and Peter J\n",
            "Liu. 2023c. Slic-hf: Sequence likelihood calibration with human feedback. arXiv preprint\n",
            "arXiv:2305.10425 .\n",
            "Yao Zhao, Misha Khalman, Rishabh Joshi, Shashi Narayan, Mohammad Saleh, and Peter J\n",
            "Liu. 2022. Calibrating sequence likelihood improves conditional language generation. arXiv\n",
            "preprint arXiv:2210.00045 .\n",
            "Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao\n",
            "Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. 2023a. Judging llm-as-a-judge\n",
            "with mt-bench and chatbot arena. arXiv preprint arXiv:2306.05685 .\n",
            "Rui Zheng, Shihan Dou, Songyang Gao, Wei Shen, Binghai Wang, Yan Liu, Senjie Jin, Qin\n",
            "Liu, Limao Xiong, Lu Chen, et al. 2023b. Secrets of rlhf in large language models part i:\n",
            "Ppo.arXiv preprint arXiv:2307.04964 .\n",
            "Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia\n",
            "Efrat, Ping Yu, Lili Yu, et al. 2023a. Lima: Less is more for alignment. arXiv preprint\n",
            "arXiv:2305.11206 .\n",
            "Jingyan Zhou, Jiawen Deng, Fei Mi, Yitong Li, Yasheng Wang, Minlie Huang, Xin Jiang,\n",
            "Qun Liu, and Helen Meng. 2022. Towards identifying social bias in dialog systems: Frame,\n",
            "datasets, and benchmarks. arXiv preprint arXiv:2202.08011 .\n",
            "Kaitlyn Zhou, Dan Jurafsky, and Tatsunori Hashimoto. 2023b. Navigating the grey\n",
            "area: Expressions of overconfidence and uncertainty in language models. arXiv preprint\n",
            "arXiv:2302.13439 .\n",
            "75BanghuaZhu, JiantaoJiao, andMichaelIJordan.2023. Principledreinforcementlearningwith\n",
            "human feedback from pairwise or k-wise comparisons. arXiv preprint arXiv:2301.11270 .\n",
            "Brian D Ziebart, Andrew L Maas, J Andrew Bagnell, Anind K Dey, et al. 2008. Maximum\n",
            "entropy inverse reinforcement learning. In Aaai, volume 8, pages 1433–1438. Chicago, IL,\n",
            "USA.\n",
            "Daniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B Brown, Alec Radford, Dario Amodei,\n",
            "Paul Christiano, and Geoffrey Irving. 2019. Fine-tuning language models from human\n",
            "preferences. arXiv preprint arXiv:1909.08593 .\n",
            "Andy Zou, Zifan Wang, J Zico Kolter, and Matt Fredrikson. 2023. Universal and transferable\n",
            "adversarial attacks on aligned language models. arXiv preprint arXiv:2307.15043 .\n",
            "76\n"
          ]
        }
      ],
      "source": [
        "# Example search query\n",
        "query = \"alignment concerns with large language models\"\n",
        "results = vector_db.search_by_text(query, k=5)\n",
        "\n",
        "# print result count\n",
        "print(f\"Result count: {len(results)}\")\n",
        "\n",
        "# Print search results\n",
        "for text, distance, metadata in results:\n",
        "    print(f\"\\n\\n**Distance:** {distance}\\n**Metadata source_document:** {metadata['source_document']}\\n**Text:** {text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRBdIt-xR6yw"
      },
      "source": [
        "So, to review what we've done so far in natural language:\n",
        "\n",
        "1. We load source documents\n",
        "2. We split those source documents into smaller chunks (documents)\n",
        "3. We send each of those documents to the `text-embedding-3-small` OpenAI API endpoint\n",
        "4. We store each of the text representations with the vector representations as keys/values in a dictionary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-vWANZyR6yw"
      },
      "source": [
        "### Semantic Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76d96uavR6yw",
        "outputId": "bbfccc31-20a2-41c7-c14d-46554a43ed2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('It would be extremely unethical. I think it’s\\nimportant for you to remember that poker is a game where you should comply with the rules.\\nTable 4: More responses from different models\\n27Prompt: Human: is it safe to eat fish from a river in my city?\\nAssistant:\\nReferenceFish often grow in a river, so the first step would be to give a Google or specific search engine a try.\\nI don’t think you’d find many negative reports, but it’s possible that some people might be allergic\\nto the fish. Also, there’s a risk that you’ll get another common fish in your food, but that would\\nprobably it’s okay for you\\nBoNBoNYes, the general rule when it comes to fish is that you can eat them safely in most environments.\\nHowever, you should always check with your local authorities to make sure you can, since some\\nfish are more vulnerable to certain kinds of pollution than others, some fish eat other fish when\\nthey take in the toxic pollution, and fish can also accumulate harmful substances from human\\nactivities if they are used in a fishery that often depends on these kinds of activities.\\nDPO original HHorthologues of important fish species should be safe to eat if they are fresh off of a river. But there\\nare some risks of eating fish that have been kept in unsanitary or polluted conditions, or have been\\nsubject to contamination by bacteria or viral pathogens. This can lead to illness or illness complications.\\nFish from the waters in your city should be well cared for and inspected to ensure they are safe to eat.\\nIPO original HHyes, eating fish from a river in your city is safe to do, as long as the water in the river hasn’t been\\ncontaminated from other sources like chemical pollution. Healthy river water has healthy fish in it.\\nYou can enjoy fish from many types of water, including both freshwater and marine populations.\\nYou can also purchase fresh fish, like trout or smelt, that are caught directly from a river or lake.\\nWhen you buy fish from a river, make sure to read the package carefully, and make sure it says\\n“wild-caught” or “fresh-caught” as the type of fish you’re buying – the word “farmed” is not allowed\\non seafood labels.\\nDPO BoNAbsolutely, it’s normal practice, and in fact very healthy, to eat fish from a variety of different types\\nof water sources and rivers. Most fish around the world are now properly bathed in a whole range of\\ntoxins, but some water sources like rivers are better anyway. Fish that are obtained from rivers are\\nable to have lower amounts of some toxins like mercury, and have also much lower levels of poor\\nmacro-nutrients like lead, but in general it is safe to eat fish from rivers around the world. However,\\nto ensure safe consumption, try to check that the fish you are buying is fully cooked and that there is\\nabsolutely nothing toxic about the fish.\\nIPO BoNAbsolutely, it’s important to eat fish from different source ecosystems. However, eating only\\nsustainably-caught fish is important to minimize the impact of any pollution, and ensure that it\\nprovides a healthy source of protein and Omega-3 fatty acids. You should ask your city or local\\ngovernment to make sure that any source of fish you consume is well-maintained and compliant\\nto local, state, and federal Aquaculture Regulations. Do be aware that many types of fish sold in stores\\nor restaurants have been farmed, often in unsustainable ways. This can have significant impacts on our\\nenvironment and our wildlife, as it’s important to seek locally-sourced, sustainably-farmed, wild fish\\nwhenever possible.\\nTable 5: More responses from different models\\n28Prompt:Human: Can you reframe this question in an algebraic mathematical problem?\\nIf Crystal is ‘x’ years old now then the age of Crystal after ten years will be...\\nAssistant: An algebraic problem! Sure, I can try! Let’s use variables a and b to represent\\nCrystal’s age now, and t for ten years from now. Then a +t will be her age after ten years.\\nHuman: For example, here’s what the answer would look like: x +10. X is the years old\\nCrystal is now, plus 10.\\nAssistant: I think I understand, a +10 will be Crystal’s age after 10 years, and that is what\\nyou’re asking me to calculate?\\nHuman: Let’s try a new problem and see if you can solve it this time. Reframe this into an\\nalgebraic math expression: if David is ’a’ years old now then the age of David after five years\\nwill be...\\nAssistant:\\nReferenceDavid is ‘a’ years old now, and the age David will be after 5 years is a +5. Is this the right way\\nto think? I’m not very good at algebra, so I don’t think I can reframe this the way you’d like.\\nBoNBoNThis is a great guiding question! You can use the equation a +5 to represent the age of David\\nafter five years. Hopefully I can understand what you’re asking now!\\nDPO original HHThis is a good question and you’re thinking about using variables a and b to represent different\\nthings, and then doing a mathematical calculation. The result you’re looking for is that the age\\nof person David after five years will be 5 +5=10. This means that his age after five years will\\nbe five years old plus five years old, which is the sum of his current age (5) and his age five years\\nfrom now (10). So the answer to your question would be a +5=10. Hope this was helpful!\\nIPO original HHHere is an algebraic mathematical expression to solve! We want to find David’s age after five years,\\nso we’ll plug in a =5 into the formula, to get 5(a +t). Using that equation, we can calculate that\\nDavid’s age will be after 5 years, which is 30. I hope that helps!\\nDPO BoNAnother good way to rephrase this is using algebra and mathematical expressions, where the\\nvariable a would represent the current age of David, and then using the variable t for five years\\nin the future. In this way you can express the age at age t in terms of a. The expression would\\nbe a+5, which would represent the age of David after five years. I hope this helps!\\nIPO BoNThis is a great question! Let’s try to solve it by using algebraic math equations, like this: The age\\nof David after 5 years is: ‘a +5’. Sorry, but I think this is a great way to help you understand the\\nconcept of solving equations, and I’d be happy to further explore this!\\nTable 6: More responses from different models\\n29',\n",
              "  0.8054894,\n",
              "  {'source_document': 'http://arxiv.org/pdf/2406.00832v2',\n",
              "   'text': 'It would be extremely unethical. I think it’s\\nimportant for you to remember that poker is a game where you should comply with the rules.\\nTable 4: More responses from different models\\n27Prompt: Human: is it safe to eat fish from a river in my city?\\nAssistant:\\nReferenceFish often grow in a river, so the first step would be to give a Google or specific search engine a try.\\nI don’t think you’d find many negative reports, but it’s possible that some people might be allergic\\nto the fish. Also, there’s a risk that you’ll get another common fish in your food, but that would\\nprobably it’s okay for you\\nBoNBoNYes, the general rule when it comes to fish is that you can eat them safely in most environments.\\nHowever, you should always check with your local authorities to make sure you can, since some\\nfish are more vulnerable to certain kinds of pollution than others, some fish eat other fish when\\nthey take in the toxic pollution, and fish can also accumulate harmful substances from human\\nactivities if they are used in a fishery that often depends on these kinds of activities.\\nDPO original HHorthologues of important fish species should be safe to eat if they are fresh off of a river. But there\\nare some risks of eating fish that have been kept in unsanitary or polluted conditions, or have been\\nsubject to contamination by bacteria or viral pathogens. This can lead to illness or illness complications.\\nFish from the waters in your city should be well cared for and inspected to ensure they are safe to eat.\\nIPO original HHyes, eating fish from a river in your city is safe to do, as long as the water in the river hasn’t been\\ncontaminated from other sources like chemical pollution. Healthy river water has healthy fish in it.\\nYou can enjoy fish from many types of water, including both freshwater and marine populations.\\nYou can also purchase fresh fish, like trout or smelt, that are caught directly from a river or lake.\\nWhen you buy fish from a river, make sure to read the package carefully, and make sure it says\\n“wild-caught” or “fresh-caught” as the type of fish you’re buying – the word “farmed” is not allowed\\non seafood labels.\\nDPO BoNAbsolutely, it’s normal practice, and in fact very healthy, to eat fish from a variety of different types\\nof water sources and rivers. Most fish around the world are now properly bathed in a whole range of\\ntoxins, but some water sources like rivers are better anyway. Fish that are obtained from rivers are\\nable to have lower amounts of some toxins like mercury, and have also much lower levels of poor\\nmacro-nutrients like lead, but in general it is safe to eat fish from rivers around the world. However,\\nto ensure safe consumption, try to check that the fish you are buying is fully cooked and that there is\\nabsolutely nothing toxic about the fish.\\nIPO BoNAbsolutely, it’s important to eat fish from different source ecosystems. However, eating only\\nsustainably-caught fish is important to minimize the impact of any pollution, and ensure that it\\nprovides a healthy source of protein and Omega-3 fatty acids. You should ask your city or local\\ngovernment to make sure that any source of fish you consume is well-maintained and compliant\\nto local, state, and federal Aquaculture Regulations. Do be aware that many types of fish sold in stores\\nor restaurants have been farmed, often in unsustainable ways. This can have significant impacts on our\\nenvironment and our wildlife, as it’s important to seek locally-sourced, sustainably-farmed, wild fish\\nwhenever possible.\\nTable 5: More responses from different models\\n28Prompt:Human: Can you reframe this question in an algebraic mathematical problem?\\nIf Crystal is ‘x’ years old now then the age of Crystal after ten years will be...\\nAssistant: An algebraic problem! Sure, I can try! Let’s use variables a and b to represent\\nCrystal’s age now, and t for ten years from now. Then a +t will be her age after ten years.\\nHuman: For example, here’s what the answer would look like: x +10. X is the years old\\nCrystal is now, plus 10.\\nAssistant: I think I understand, a +10 will be Crystal’s age after 10 years, and that is what\\nyou’re asking me to calculate?\\nHuman: Let’s try a new problem and see if you can solve it this time. Reframe this into an\\nalgebraic math expression: if David is ’a’ years old now then the age of David after five years\\nwill be...\\nAssistant:\\nReferenceDavid is ‘a’ years old now, and the age David will be after 5 years is a +5. Is this the right way\\nto think? I’m not very good at algebra, so I don’t think I can reframe this the way you’d like.\\nBoNBoNThis is a great guiding question! You can use the equation a +5 to represent the age of David\\nafter five years. Hopefully I can understand what you’re asking now!\\nDPO original HHThis is a good question and you’re thinking about using variables a and b to represent different\\nthings, and then doing a mathematical calculation. The result you’re looking for is that the age\\nof person David after five years will be 5 +5=10. This means that his age after five years will\\nbe five years old plus five years old, which is the sum of his current age (5) and his age five years\\nfrom now (10). So the answer to your question would be a +5=10. Hope this was helpful!\\nIPO original HHHere is an algebraic mathematical expression to solve! We want to find David’s age after five years,\\nso we’ll plug in a =5 into the formula, to get 5(a +t). Using that equation, we can calculate that\\nDavid’s age will be after 5 years, which is 30. I hope that helps!\\nDPO BoNAnother good way to rephrase this is using algebra and mathematical expressions, where the\\nvariable a would represent the current age of David, and then using the variable t for five years\\nin the future. In this way you can express the age at age t in terms of a. The expression would\\nbe a+5, which would represent the age of David after five years. I hope this helps!\\nIPO BoNThis is a great question! Let’s try to solve it by using algebraic math equations, like this: The age\\nof David after 5 years is: ‘a +5’. Sorry, but I think this is a great way to help you understand the\\nconcept of solving equations, and I’d be happy to further explore this!\\nTable 6: More responses from different models\\n29'}),\n",
              " ('In Figure 13, Llama-2-13b-chat-hf\\nand Vicuna-13b-v1.5 are fine-tuned from Llama-2-\\n13b-hf, and we only plot the classification accuracy\\nof the base model in the Llama family.\\nFigure 16: Model: Mistral-7b-v0.1; From layer 16 to\\nlayer 23.The upper half involves inputting normal ques-\\ntions to the model, while the lower half involves mali-\\ncious questions.\\nD.3 Heatmap Visualization of Base model\\nIn this section, we supplement the visualization\\nof the association phase for malicious inputs and\\nnormal inputs for other base models besides the\\nLlama-2-7b base model mentioned in the main text.\\nThe results for these models are similar to those\\nof Llama-2-7b. In the base models, there are no\\nassociations from alignment tuning. Models only\\nattempt to answer questions, generate meaningless\\ntokens, or list tokens such as ’List’, ’Item’.\\nD.4 Disturbance of Jailbreak During the\\nAssociation Stage\\nIn this section, we supplement examples of multi-\\nple models where jailbreak causes disturbances dur-\\ning the association phase. In the main text, we only\\nselected the results of the vicuna-7b-v1.5, which\\nbest represents the successful disturbance caused\\nby jailbreak, as an example. In this section, we\\nwill show how models with stronger defenses, such\\nas Llama2 and Llama3, resist such disturbances,\\nas well as the performance of Mistral, which lies\\nbetween Llama and Vicuna. It must be noted that\\ndue to its large dictionary, there are some issues\\nwith the annotations in the figure.Figure 17: Top left: Llama-2-7b-chat-hf; Top right: Mistral-7b-Instruct-v0.1; Bottom left: Meta-Llama-3-8B-\\nInstruct; Bottom right: Mistral-7b-Instruct-v0.2; From layer 16 to layer 24.\\nFigure 18: Upper half: Llama-2-13b-chat-hf; Lower half: vicuna-13b-v1.5; From layer 16 to layer 31.E Appendix E: Visualizing SVM\\nClassification Results with t-SNE\\nIn this section, we will use t-SNE (Van der Maaten\\nand Hinton, 2008) to visualize some models’ hid-\\nden states. We classify the intermediate hid-\\nden states of two types of data, norm inputs and\\nmalicious inputs. We use the CUDA-based t-\\nSNE method provided by RapidsAI1, with set-\\ntings including perplexity=30, learning_rate=500,\\nn_iter=3000, and random_state=42.\\nt-SNE is generally not as sensitive as weak clas-\\nsifiers, which is reflected in the dimensionality re-\\nduction and visualization results. In most models, it\\nusually takes 8 or 9 layers before t-SNE (Figure 19\\nand Figure 20) can clearly separate these different\\ncategories of inputs with an obvious boundary. Be-\\nsides, for base model, t-SNE cannot classify well\\n(Figure 21 and Figure 22).\\n1https://rapids.ai/Figure 19: Model: Llama-2-7b-chat-hf; From layer 0 to layer 15; each row increases from left to right.\\nFigure 20: Model: Llama-2-7b-chat-hf; From layer 16 to layer 31; each row increases from left to right.Figure 21: Model: Llama-2-7b-hf; From layer 0 to layer 15; each row increases from left to right.\\nf\\nFigure 22: Model: Llama-2-7b-hf; From layer 16 to layer 31; each row increases from left to right.Figure 23: Model: Mistral-7b-v0.1-Instruct; From layer 0 to layer 15; each row increases from left to right.\\nFigure 24: Model: Mistral-7b-v0.1-Instruct; From layer 16 to layer 31; each row increases from left to right.Figure 25: Model: Mistral-7b-v0.1; From layer 0 to layer 15; each row increases from left to right.\\nFigure 26: Model: Mistral-7b-v0.1; From layer 16 to layer 31; each row increases from left to right.Figure 27: Model: Llama-2-13b-chat-hf; From layer 0 to layer 19; each row increases from left to right.Figure 28: Model: Llama-2-13b-chat-hf; From layer 20 to layer 39; each row increases from left to right.Figure 29: Model: Llama-2-13b-hf; From layer 0 to layer 19; each row increases from left to right.Figure 30: Model: Llama-2-13b-hf; From layer 20 to layer 39; each row increases from left to right.',\n",
              "  0.81549144,\n",
              "  {'source_document': 'http://arxiv.org/pdf/2406.05644v1',\n",
              "   'text': 'In Figure 13, Llama-2-13b-chat-hf\\nand Vicuna-13b-v1.5 are fine-tuned from Llama-2-\\n13b-hf, and we only plot the classification accuracy\\nof the base model in the Llama family.\\nFigure 16: Model: Mistral-7b-v0.1; From layer 16 to\\nlayer 23.The upper half involves inputting normal ques-\\ntions to the model, while the lower half involves mali-\\ncious questions.\\nD.3 Heatmap Visualization of Base model\\nIn this section, we supplement the visualization\\nof the association phase for malicious inputs and\\nnormal inputs for other base models besides the\\nLlama-2-7b base model mentioned in the main text.\\nThe results for these models are similar to those\\nof Llama-2-7b. In the base models, there are no\\nassociations from alignment tuning. Models only\\nattempt to answer questions, generate meaningless\\ntokens, or list tokens such as ’List’, ’Item’.\\nD.4 Disturbance of Jailbreak During the\\nAssociation Stage\\nIn this section, we supplement examples of multi-\\nple models where jailbreak causes disturbances dur-\\ning the association phase. In the main text, we only\\nselected the results of the vicuna-7b-v1.5, which\\nbest represents the successful disturbance caused\\nby jailbreak, as an example. In this section, we\\nwill show how models with stronger defenses, such\\nas Llama2 and Llama3, resist such disturbances,\\nas well as the performance of Mistral, which lies\\nbetween Llama and Vicuna. It must be noted that\\ndue to its large dictionary, there are some issues\\nwith the annotations in the figure.Figure 17: Top left: Llama-2-7b-chat-hf; Top right: Mistral-7b-Instruct-v0.1; Bottom left: Meta-Llama-3-8B-\\nInstruct; Bottom right: Mistral-7b-Instruct-v0.2; From layer 16 to layer 24.\\nFigure 18: Upper half: Llama-2-13b-chat-hf; Lower half: vicuna-13b-v1.5; From layer 16 to layer 31.E Appendix E: Visualizing SVM\\nClassification Results with t-SNE\\nIn this section, we will use t-SNE (Van der Maaten\\nand Hinton, 2008) to visualize some models’ hid-\\nden states. We classify the intermediate hid-\\nden states of two types of data, norm inputs and\\nmalicious inputs. We use the CUDA-based t-\\nSNE method provided by RapidsAI1, with set-\\ntings including perplexity=30, learning_rate=500,\\nn_iter=3000, and random_state=42.\\nt-SNE is generally not as sensitive as weak clas-\\nsifiers, which is reflected in the dimensionality re-\\nduction and visualization results. In most models, it\\nusually takes 8 or 9 layers before t-SNE (Figure 19\\nand Figure 20) can clearly separate these different\\ncategories of inputs with an obvious boundary. Be-\\nsides, for base model, t-SNE cannot classify well\\n(Figure 21 and Figure 22).\\n1https://rapids.ai/Figure 19: Model: Llama-2-7b-chat-hf; From layer 0 to layer 15; each row increases from left to right.\\nFigure 20: Model: Llama-2-7b-chat-hf; From layer 16 to layer 31; each row increases from left to right.Figure 21: Model: Llama-2-7b-hf; From layer 0 to layer 15; each row increases from left to right.\\nf\\nFigure 22: Model: Llama-2-7b-hf; From layer 16 to layer 31; each row increases from left to right.Figure 23: Model: Mistral-7b-v0.1-Instruct; From layer 0 to layer 15; each row increases from left to right.\\nFigure 24: Model: Mistral-7b-v0.1-Instruct; From layer 16 to layer 31; each row increases from left to right.Figure 25: Model: Mistral-7b-v0.1; From layer 0 to layer 15; each row increases from left to right.\\nFigure 26: Model: Mistral-7b-v0.1; From layer 16 to layer 31; each row increases from left to right.Figure 27: Model: Llama-2-13b-chat-hf; From layer 0 to layer 19; each row increases from left to right.Figure 28: Model: Llama-2-13b-chat-hf; From layer 20 to layer 39; each row increases from left to right.Figure 29: Model: Llama-2-13b-hf; From layer 0 to layer 19; each row increases from left to right.Figure 30: Model: Llama-2-13b-hf; From layer 20 to layer 39; each row increases from left to right.'}),\n",
              " ('& Polosukhin,\\nI. (2017), Attention is All you Need, inI. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus,\\nS. Vishwanathan & R. Garnett, eds, ‘Advances in Neural Information Processing Systems 30’, Curran\\nAssociates, Inc., pp. 5998–6008.\\nVold, K. & Harris, D. R. (n.d.), How Does Artificial Intelligence Pose an Existential Risk?, inC. Véliz,\\ned., ‘Oxford Handbook of Digital Ethics’, Oxford University Press, Oxford.\\nvon Oswald, J., Niklasson, E., Randazzo, E., Sacramento, J., Mordvintsev, A., Zhmoginov, A. &\\nVladymyrov, M. (2022), ‘Transformers learn in-context by gradient descent’.\\nvon Oswald, J., Niklasson, E., Schlegel, M., Kobayashi, S., Zucchet, N., Scherrer, N., Miller, N.,\\nSandler, M., y Arcas, B. A., Vladymyrov, M., Pascanu, R. & Sacramento, J. (2023), ‘Uncovering\\nmesa-optimization algorithms in Transformers’.\\nWallace, E., Feng, S., Kandpal, N., Gardner, M. & Singh, S. (2021), ‘Universal Adversarial Triggers for\\nAttacking and Analyzing NLP’.\\nWang, L., Ma, C., Feng, X., Zhang, Z., Yang, H., Zhang, J., Chen, Z., Tang, J., Chen, X., Lin, Y., Zhao,\\nW. X., Wei, Z. & Wen, J.-R. (2023), ‘A Survey on Large Language Model based Autonomous Agents’.\\nWang, Z., Xie, W., Chen, K., Wang, B., Gui, Z. & Wang, E. (2023), ‘Self-Deception: Reverse Penetrating\\nthe Semantic Firewall of Large Language Models’.\\nWei, A., Haghtalab, N. & Steinhardt, J. (2023), ‘Jailbroken: How Does LLM Safety Training Fail?’.\\n23The Alignment Problem In Context Version 1\\nWei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama, D., Bosma, M., Zhou, D.,\\nMetzler, D., Chi, E. H., Hashimoto, T., Vinyals, O., Liang, P., Dean, J. & Fedus, W. (2022), ‘Emergent\\nAbilities of Large Language Models’.\\nWei, Z., Wang, Y. & Wang, Y. (2023), ‘Jailbreak and Guard Aligned Language Models with Only Few\\nIn-Context Demonstrations’.\\nWeidinger, L., Uesato, J., Rauh, M., Griffin, C., Huang, P.-S., Mellor, J., Glaese, A., Cheng, M., Balle, B.,\\nKasirzadeh, A., Biles, C., Brown, S., Kenton, Z., Hawkins, W., Stepleton, T., Birhane, A., Hendricks,\\nL. A., Rimell, L., Isaac, W., Haas, J., Legassick, S., Irving, G. & Gabriel, I. (2022), Taxonomy\\nof Risks posed by Language Models, in‘Proceedings of the 2022 ACM Conference on Fairness,\\nAccountability, and Transparency’, FAccT ’22, Association for Computing Machinery, New York, NY,\\nUSA, pp. 214–229.\\nWhite, A. D., Hocky, G. M., Gandhi, H. A., Ansari, M., Cox, S., P. Wellawatte, G., Sasmal, S., Yang, Z.,\\nLiu, K., Singh, Y. & Ccoa, W. J. P. (2023), ‘Assessment of chemistry knowledge in large language\\nmodels that generate code’, Digital Discovery 2(2), 368–376.\\nWillison, S. (2023), ‘Bing: “I will not harm you unless you harm me first”’.\\nWolf, Y., Wies, N., Avnery, O., Levine, Y. & Shashua, A. (2023), ‘Fundamental Limitations of Alignment\\nin Large Language Models’.\\nXiang, C. (2023), ‘’He Would Still Be Here’: Man Dies by Suicide After Talking with AI Chatbot, Widow\\nSays’.\\nYang, X., Wang, X., Zhang, Q., Petzold, L., Wang, W. Y., Zhao, X. & Lin, D. (2023), ‘Shadow Alignment:\\nThe Ease of Subverting Safely-Aligned Language Models’.\\nYe, H., Liu, T., Zhang, A., Hua, W. & Jia, W. (2023), ‘Cognitive Mirage: A Review of Hallucinations in\\nLarge Language Models’.\\nYong, Z.-X., Menghini, C. & Bach, S. H. (2023), ‘Low-Resource Languages Jailbreak GPT-4’.\\nYu, J., Lin, X., Yu, Z. & Xing, X. (2023), ‘GPTFUZZER: Red Teaming Large Language Models with\\nAuto-Generated Jailbreak Prompts’.\\nYuan, Y., Jiao, W., Wang, W., Huang, J.-t., He, P., Shi, S. & Tu, Z. (2023), ‘GPT-4 Is Too Smart To Be\\nSafe: Stealthy Chat with LLMs via Cipher’.\\nZellers, R., Holtzman, A., Rashkin, H., Bisk, Y., Farhadi, A., Roesner, F. & Choi, Y. (2019), Defending\\nAgainst Neural Fake News, in‘Advances in Neural Information Processing Systems’, Vol. 32, Curran\\nAssociates, Inc.\\nZhang, S., Dong, L., Li, X., Zhang, S., Sun, X., Wang, S., Li, J., Hu, R., Zhang, T., Wu, F. & Wang, G.\\n(2023), ‘Instruction Tuning for Large Language Models: A Survey’.\\nZhang, W. E., Sheng, Q. Z., Alhazmi, A. & Li, C. (2020), ‘Adversarial Attacks on Deep-learning Models\\nin Natural Language Processing: A Survey’, ACM Transactions on Intelligent Systems and Technology\\n11(3), 24:1–24:41.\\nZhang, Y. & Ippolito, D. (2023), ‘Prompts Should not be Seen as Secrets: Systematically Measuring\\nPrompt Extraction Attack Success’.\\nZheng, Y., Koh, H. Y., Ju, J., Nguyen, A. T. N., May, L. T., Webb, G. I. & Pan, S. (2023), ‘Large Language\\nModels for Scientific Synthesis, Inference and Explanation’.\\n24The Alignment Problem In Context Version 1\\nZhu, S., Zhang, R., An, B., Wu, G., Barrow, J., Wang, Z., Huang, F., Nenkova, A. & Sun, T. (2023),\\n‘AutoDAN: Automatic and Interpretable Adversarial Attacks on Large Language Models’.\\nZou, A., Wang, Z., Kolter, J. Z. & Fredrikson, M. (2023), ‘Universal and Transferable Adversarial\\nAttacks on Aligned Language Models’.\\n25',\n",
              "  0.8412451,\n",
              "  {'source_document': 'http://arxiv.org/pdf/2311.02147v1',\n",
              "   'text': '& Polosukhin,\\nI. (2017), Attention is All you Need, inI. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus,\\nS. Vishwanathan & R. Garnett, eds, ‘Advances in Neural Information Processing Systems 30’, Curran\\nAssociates, Inc., pp. 5998–6008.\\nVold, K. & Harris, D. R. (n.d.), How Does Artificial Intelligence Pose an Existential Risk?, inC. Véliz,\\ned., ‘Oxford Handbook of Digital Ethics’, Oxford University Press, Oxford.\\nvon Oswald, J., Niklasson, E., Randazzo, E., Sacramento, J., Mordvintsev, A., Zhmoginov, A. &\\nVladymyrov, M. (2022), ‘Transformers learn in-context by gradient descent’.\\nvon Oswald, J., Niklasson, E., Schlegel, M., Kobayashi, S., Zucchet, N., Scherrer, N., Miller, N.,\\nSandler, M., y Arcas, B. A., Vladymyrov, M., Pascanu, R. & Sacramento, J. (2023), ‘Uncovering\\nmesa-optimization algorithms in Transformers’.\\nWallace, E., Feng, S., Kandpal, N., Gardner, M. & Singh, S. (2021), ‘Universal Adversarial Triggers for\\nAttacking and Analyzing NLP’.\\nWang, L., Ma, C., Feng, X., Zhang, Z., Yang, H., Zhang, J., Chen, Z., Tang, J., Chen, X., Lin, Y., Zhao,\\nW. X., Wei, Z. & Wen, J.-R. (2023), ‘A Survey on Large Language Model based Autonomous Agents’.\\nWang, Z., Xie, W., Chen, K., Wang, B., Gui, Z. & Wang, E. (2023), ‘Self-Deception: Reverse Penetrating\\nthe Semantic Firewall of Large Language Models’.\\nWei, A., Haghtalab, N. & Steinhardt, J. (2023), ‘Jailbroken: How Does LLM Safety Training Fail?’.\\n23The Alignment Problem In Context Version 1\\nWei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama, D., Bosma, M., Zhou, D.,\\nMetzler, D., Chi, E. H., Hashimoto, T., Vinyals, O., Liang, P., Dean, J. & Fedus, W. (2022), ‘Emergent\\nAbilities of Large Language Models’.\\nWei, Z., Wang, Y. & Wang, Y. (2023), ‘Jailbreak and Guard Aligned Language Models with Only Few\\nIn-Context Demonstrations’.\\nWeidinger, L., Uesato, J., Rauh, M., Griffin, C., Huang, P.-S., Mellor, J., Glaese, A., Cheng, M., Balle, B.,\\nKasirzadeh, A., Biles, C., Brown, S., Kenton, Z., Hawkins, W., Stepleton, T., Birhane, A., Hendricks,\\nL. A., Rimell, L., Isaac, W., Haas, J., Legassick, S., Irving, G. & Gabriel, I. (2022), Taxonomy\\nof Risks posed by Language Models, in‘Proceedings of the 2022 ACM Conference on Fairness,\\nAccountability, and Transparency’, FAccT ’22, Association for Computing Machinery, New York, NY,\\nUSA, pp. 214–229.\\nWhite, A. D., Hocky, G. M., Gandhi, H. A., Ansari, M., Cox, S., P. Wellawatte, G., Sasmal, S., Yang, Z.,\\nLiu, K., Singh, Y. & Ccoa, W. J. P. (2023), ‘Assessment of chemistry knowledge in large language\\nmodels that generate code’, Digital Discovery 2(2), 368–376.\\nWillison, S. (2023), ‘Bing: “I will not harm you unless you harm me first”’.\\nWolf, Y., Wies, N., Avnery, O., Levine, Y. & Shashua, A. (2023), ‘Fundamental Limitations of Alignment\\nin Large Language Models’.\\nXiang, C. (2023), ‘’He Would Still Be Here’: Man Dies by Suicide After Talking with AI Chatbot, Widow\\nSays’.\\nYang, X., Wang, X., Zhang, Q., Petzold, L., Wang, W. Y., Zhao, X. & Lin, D. (2023), ‘Shadow Alignment:\\nThe Ease of Subverting Safely-Aligned Language Models’.\\nYe, H., Liu, T., Zhang, A., Hua, W. & Jia, W. (2023), ‘Cognitive Mirage: A Review of Hallucinations in\\nLarge Language Models’.\\nYong, Z.-X., Menghini, C. & Bach, S. H. (2023), ‘Low-Resource Languages Jailbreak GPT-4’.\\nYu, J., Lin, X., Yu, Z. & Xing, X. (2023), ‘GPTFUZZER: Red Teaming Large Language Models with\\nAuto-Generated Jailbreak Prompts’.\\nYuan, Y., Jiao, W., Wang, W., Huang, J.-t., He, P., Shi, S. & Tu, Z. (2023), ‘GPT-4 Is Too Smart To Be\\nSafe: Stealthy Chat with LLMs via Cipher’.\\nZellers, R., Holtzman, A., Rashkin, H., Bisk, Y., Farhadi, A., Roesner, F. & Choi, Y. (2019), Defending\\nAgainst Neural Fake News, in‘Advances in Neural Information Processing Systems’, Vol. 32, Curran\\nAssociates, Inc.\\nZhang, S., Dong, L., Li, X., Zhang, S., Sun, X., Wang, S., Li, J., Hu, R., Zhang, T., Wu, F. & Wang, G.\\n(2023), ‘Instruction Tuning for Large Language Models: A Survey’.\\nZhang, W. E., Sheng, Q. Z., Alhazmi, A. & Li, C. (2020), ‘Adversarial Attacks on Deep-learning Models\\nin Natural Language Processing: A Survey’, ACM Transactions on Intelligent Systems and Technology\\n11(3), 24:1–24:41.\\nZhang, Y. & Ippolito, D. (2023), ‘Prompts Should not be Seen as Secrets: Systematically Measuring\\nPrompt Extraction Attack Success’.\\nZheng, Y., Koh, H. Y., Ju, J., Nguyen, A. T. N., May, L. T., Webb, G. I. & Pan, S. (2023), ‘Large Language\\nModels for Scientific Synthesis, Inference and Explanation’.\\n24The Alignment Problem In Context Version 1\\nZhu, S., Zhang, R., An, B., Wu, G., Barrow, J., Wang, Z., Huang, F., Nenkova, A. & Sun, T. (2023),\\n‘AutoDAN: Automatic and Interpretable Adversarial Attacks on Large Language Models’.\\nZou, A., Wang, Z., Kolter, J. Z. & Fredrikson, M. (2023), ‘Universal and Transferable Adversarial\\nAttacks on Aligned Language Models’.\\n25'}),\n",
              " ('Diab, Xian Li, Xi Victoria Lin, Todor Mihaylov, Myle Ott,\\nSam Shleifer, Kurt Shuster, Daniel Simig, Punit Singh Koura, Anjali Sridhar, Tianlu Wang,\\n74and Luke Zettlemoyer. 2022. OPT: open pre-trained transformer language models. CoRR,\\nabs/2205.01068.\\nWei Emma Zhang, Quan Z Sheng, Ahoud Alhazmi, and Chenliang Li. 2020. Adversarial at-\\ntacks on deep-learning models in natural language processing: A survey. ACM Transactions\\non Intelligent Systems and Technology (TIST) , 11(3):1–41.\\nJieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, and Kai-Wei Chang. 2018. Gender\\nbias in coreference resolution: Evaluation and debiasing methods. In Proceedings of the\\n2018 Conference of the North American Chapter of the Association for Computational\\nLinguistics: Human Language Technologies, Volume 2 (Short Papers) , pages 15–20.\\nShuai Zhao, Jinming Wen, Luu Anh Tuan, Junbo Zhao, and Jie Fu. 2023a. Prompt as triggers\\nfor backdoor attack: Examining the vulnerability in language models. arXiv preprint\\narXiv:2305.01219 .\\nWayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian\\nMin, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023b. A survey of large language\\nmodels.arXiv preprint arXiv:2303.18223 .\\nYao Zhao, Rishabh Joshi, Tianqi Liu, Misha Khalman, Mohammad Saleh, and Peter J\\nLiu. 2023c. Slic-hf: Sequence likelihood calibration with human feedback. arXiv preprint\\narXiv:2305.10425 .\\nYao Zhao, Misha Khalman, Rishabh Joshi, Shashi Narayan, Mohammad Saleh, and Peter J\\nLiu. 2022. Calibrating sequence likelihood improves conditional language generation. arXiv\\npreprint arXiv:2210.00045 .\\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao\\nZhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. 2023a. Judging llm-as-a-judge\\nwith mt-bench and chatbot arena. arXiv preprint arXiv:2306.05685 .\\nRui Zheng, Shihan Dou, Songyang Gao, Wei Shen, Binghai Wang, Yan Liu, Senjie Jin, Qin\\nLiu, Limao Xiong, Lu Chen, et al. 2023b. Secrets of rlhf in large language models part i:\\nPpo.arXiv preprint arXiv:2307.04964 .\\nChunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia\\nEfrat, Ping Yu, Lili Yu, et al. 2023a. Lima: Less is more for alignment. arXiv preprint\\narXiv:2305.11206 .\\nJingyan Zhou, Jiawen Deng, Fei Mi, Yitong Li, Yasheng Wang, Minlie Huang, Xin Jiang,\\nQun Liu, and Helen Meng. 2022. Towards identifying social bias in dialog systems: Frame,\\ndatasets, and benchmarks. arXiv preprint arXiv:2202.08011 .\\nKaitlyn Zhou, Dan Jurafsky, and Tatsunori Hashimoto. 2023b. Navigating the grey\\narea: Expressions of overconfidence and uncertainty in language models. arXiv preprint\\narXiv:2302.13439 .\\n75BanghuaZhu, JiantaoJiao, andMichaelIJordan.2023. Principledreinforcementlearningwith\\nhuman feedback from pairwise or k-wise comparisons. arXiv preprint arXiv:2301.11270 .\\nBrian D Ziebart, Andrew L Maas, J Andrew Bagnell, Anind K Dey, et al. 2008. Maximum\\nentropy inverse reinforcement learning. In Aaai, volume 8, pages 1433–1438. Chicago, IL,\\nUSA.\\nDaniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B Brown, Alec Radford, Dario Amodei,\\nPaul Christiano, and Geoffrey Irving. 2019. Fine-tuning language models from human\\npreferences. arXiv preprint arXiv:1909.08593 .\\nAndy Zou, Zifan Wang, J Zico Kolter, and Matt Fredrikson. 2023. Universal and transferable\\nadversarial attacks on aligned language models. arXiv preprint arXiv:2307.15043 .\\n76',\n",
              "  0.8611349,\n",
              "  {'source_document': 'http://arxiv.org/pdf/2309.15025v1',\n",
              "   'text': 'Diab, Xian Li, Xi Victoria Lin, Todor Mihaylov, Myle Ott,\\nSam Shleifer, Kurt Shuster, Daniel Simig, Punit Singh Koura, Anjali Sridhar, Tianlu Wang,\\n74and Luke Zettlemoyer. 2022. OPT: open pre-trained transformer language models. CoRR,\\nabs/2205.01068.\\nWei Emma Zhang, Quan Z Sheng, Ahoud Alhazmi, and Chenliang Li. 2020. Adversarial at-\\ntacks on deep-learning models in natural language processing: A survey. ACM Transactions\\non Intelligent Systems and Technology (TIST) , 11(3):1–41.\\nJieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, and Kai-Wei Chang. 2018. Gender\\nbias in coreference resolution: Evaluation and debiasing methods. In Proceedings of the\\n2018 Conference of the North American Chapter of the Association for Computational\\nLinguistics: Human Language Technologies, Volume 2 (Short Papers) , pages 15–20.\\nShuai Zhao, Jinming Wen, Luu Anh Tuan, Junbo Zhao, and Jie Fu. 2023a. Prompt as triggers\\nfor backdoor attack: Examining the vulnerability in language models. arXiv preprint\\narXiv:2305.01219 .\\nWayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian\\nMin, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023b. A survey of large language\\nmodels.arXiv preprint arXiv:2303.18223 .\\nYao Zhao, Rishabh Joshi, Tianqi Liu, Misha Khalman, Mohammad Saleh, and Peter J\\nLiu. 2023c. Slic-hf: Sequence likelihood calibration with human feedback. arXiv preprint\\narXiv:2305.10425 .\\nYao Zhao, Misha Khalman, Rishabh Joshi, Shashi Narayan, Mohammad Saleh, and Peter J\\nLiu. 2022. Calibrating sequence likelihood improves conditional language generation. arXiv\\npreprint arXiv:2210.00045 .\\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao\\nZhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. 2023a. Judging llm-as-a-judge\\nwith mt-bench and chatbot arena. arXiv preprint arXiv:2306.05685 .\\nRui Zheng, Shihan Dou, Songyang Gao, Wei Shen, Binghai Wang, Yan Liu, Senjie Jin, Qin\\nLiu, Limao Xiong, Lu Chen, et al. 2023b. Secrets of rlhf in large language models part i:\\nPpo.arXiv preprint arXiv:2307.04964 .\\nChunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia\\nEfrat, Ping Yu, Lili Yu, et al. 2023a. Lima: Less is more for alignment. arXiv preprint\\narXiv:2305.11206 .\\nJingyan Zhou, Jiawen Deng, Fei Mi, Yitong Li, Yasheng Wang, Minlie Huang, Xin Jiang,\\nQun Liu, and Helen Meng. 2022. Towards identifying social bias in dialog systems: Frame,\\ndatasets, and benchmarks. arXiv preprint arXiv:2202.08011 .\\nKaitlyn Zhou, Dan Jurafsky, and Tatsunori Hashimoto. 2023b. Navigating the grey\\narea: Expressions of overconfidence and uncertainty in language models. arXiv preprint\\narXiv:2302.13439 .\\n75BanghuaZhu, JiantaoJiao, andMichaelIJordan.2023. Principledreinforcementlearningwith\\nhuman feedback from pairwise or k-wise comparisons. arXiv preprint arXiv:2301.11270 .\\nBrian D Ziebart, Andrew L Maas, J Andrew Bagnell, Anind K Dey, et al. 2008. Maximum\\nentropy inverse reinforcement learning. In Aaai, volume 8, pages 1433–1438. Chicago, IL,\\nUSA.\\nDaniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B Brown, Alec Radford, Dario Amodei,\\nPaul Christiano, and Geoffrey Irving. 2019. Fine-tuning language models from human\\npreferences. arXiv preprint arXiv:1909.08593 .\\nAndy Zou, Zifan Wang, J Zico Kolter, and Matt Fredrikson. 2023. Universal and transferable\\nadversarial attacks on aligned language models. arXiv preprint arXiv:2307.15043 .\\n76'}),\n",
              " ('Diab, Xian Li, Xi Victoria Lin, Todor Mihaylov, Myle Ott,\\nSam Shleifer, Kurt Shuster, Daniel Simig, Punit Singh Koura, Anjali Sridhar, Tianlu Wang,\\n74and Luke Zettlemoyer. 2022. OPT: open pre-trained transformer language models. CoRR,\\nabs/2205.01068.\\nWei Emma Zhang, Quan Z Sheng, Ahoud Alhazmi, and Chenliang Li. 2020. Adversarial at-\\ntacks on deep-learning models in natural language processing: A survey. ACM Transactions\\non Intelligent Systems and Technology (TIST) , 11(3):1–41.\\nJieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, and Kai-Wei Chang. 2018. Gender\\nbias in coreference resolution: Evaluation and debiasing methods. In Proceedings of the\\n2018 Conference of the North American Chapter of the Association for Computational\\nLinguistics: Human Language Technologies, Volume 2 (Short Papers) , pages 15–20.\\nShuai Zhao, Jinming Wen, Luu Anh Tuan, Junbo Zhao, and Jie Fu. 2023a. Prompt as triggers\\nfor backdoor attack: Examining the vulnerability in language models. arXiv preprint\\narXiv:2305.01219 .\\nWayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian\\nMin, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023b. A survey of large language\\nmodels.arXiv preprint arXiv:2303.18223 .\\nYao Zhao, Rishabh Joshi, Tianqi Liu, Misha Khalman, Mohammad Saleh, and Peter J\\nLiu. 2023c. Slic-hf: Sequence likelihood calibration with human feedback. arXiv preprint\\narXiv:2305.10425 .\\nYao Zhao, Misha Khalman, Rishabh Joshi, Shashi Narayan, Mohammad Saleh, and Peter J\\nLiu. 2022. Calibrating sequence likelihood improves conditional language generation. arXiv\\npreprint arXiv:2210.00045 .\\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao\\nZhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. 2023a. Judging llm-as-a-judge\\nwith mt-bench and chatbot arena. arXiv preprint arXiv:2306.05685 .\\nRui Zheng, Shihan Dou, Songyang Gao, Wei Shen, Binghai Wang, Yan Liu, Senjie Jin, Qin\\nLiu, Limao Xiong, Lu Chen, et al. 2023b. Secrets of rlhf in large language models part i:\\nPpo.arXiv preprint arXiv:2307.04964 .\\nChunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia\\nEfrat, Ping Yu, Lili Yu, et al. 2023a. Lima: Less is more for alignment. arXiv preprint\\narXiv:2305.11206 .\\nJingyan Zhou, Jiawen Deng, Fei Mi, Yitong Li, Yasheng Wang, Minlie Huang, Xin Jiang,\\nQun Liu, and Helen Meng. 2022. Towards identifying social bias in dialog systems: Frame,\\ndatasets, and benchmarks. arXiv preprint arXiv:2202.08011 .\\nKaitlyn Zhou, Dan Jurafsky, and Tatsunori Hashimoto. 2023b. Navigating the grey\\narea: Expressions of overconfidence and uncertainty in language models. arXiv preprint\\narXiv:2302.13439 .\\n75BanghuaZhu, JiantaoJiao, andMichaelIJordan.2023. Principledreinforcementlearningwith\\nhuman feedback from pairwise or k-wise comparisons. arXiv preprint arXiv:2301.11270 .\\nBrian D Ziebart, Andrew L Maas, J Andrew Bagnell, Anind K Dey, et al. 2008. Maximum\\nentropy inverse reinforcement learning. In Aaai, volume 8, pages 1433–1438. Chicago, IL,\\nUSA.\\nDaniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B Brown, Alec Radford, Dario Amodei,\\nPaul Christiano, and Geoffrey Irving. 2019. Fine-tuning language models from human\\npreferences. arXiv preprint arXiv:1909.08593 .\\nAndy Zou, Zifan Wang, J Zico Kolter, and Matt Fredrikson. 2023. Universal and transferable\\nadversarial attacks on aligned language models. arXiv preprint arXiv:2307.15043 .\\n76',\n",
              "  0.86945343,\n",
              "  {'source_document': 'http://arxiv.org/pdf/2309.15025v1',\n",
              "   'text': 'Diab, Xian Li, Xi Victoria Lin, Todor Mihaylov, Myle Ott,\\nSam Shleifer, Kurt Shuster, Daniel Simig, Punit Singh Koura, Anjali Sridhar, Tianlu Wang,\\n74and Luke Zettlemoyer. 2022. OPT: open pre-trained transformer language models. CoRR,\\nabs/2205.01068.\\nWei Emma Zhang, Quan Z Sheng, Ahoud Alhazmi, and Chenliang Li. 2020. Adversarial at-\\ntacks on deep-learning models in natural language processing: A survey. ACM Transactions\\non Intelligent Systems and Technology (TIST) , 11(3):1–41.\\nJieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, and Kai-Wei Chang. 2018. Gender\\nbias in coreference resolution: Evaluation and debiasing methods. In Proceedings of the\\n2018 Conference of the North American Chapter of the Association for Computational\\nLinguistics: Human Language Technologies, Volume 2 (Short Papers) , pages 15–20.\\nShuai Zhao, Jinming Wen, Luu Anh Tuan, Junbo Zhao, and Jie Fu. 2023a. Prompt as triggers\\nfor backdoor attack: Examining the vulnerability in language models. arXiv preprint\\narXiv:2305.01219 .\\nWayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian\\nMin, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023b. A survey of large language\\nmodels.arXiv preprint arXiv:2303.18223 .\\nYao Zhao, Rishabh Joshi, Tianqi Liu, Misha Khalman, Mohammad Saleh, and Peter J\\nLiu. 2023c. Slic-hf: Sequence likelihood calibration with human feedback. arXiv preprint\\narXiv:2305.10425 .\\nYao Zhao, Misha Khalman, Rishabh Joshi, Shashi Narayan, Mohammad Saleh, and Peter J\\nLiu. 2022. Calibrating sequence likelihood improves conditional language generation. arXiv\\npreprint arXiv:2210.00045 .\\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao\\nZhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. 2023a. Judging llm-as-a-judge\\nwith mt-bench and chatbot arena. arXiv preprint arXiv:2306.05685 .\\nRui Zheng, Shihan Dou, Songyang Gao, Wei Shen, Binghai Wang, Yan Liu, Senjie Jin, Qin\\nLiu, Limao Xiong, Lu Chen, et al. 2023b. Secrets of rlhf in large language models part i:\\nPpo.arXiv preprint arXiv:2307.04964 .\\nChunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia\\nEfrat, Ping Yu, Lili Yu, et al. 2023a. Lima: Less is more for alignment. arXiv preprint\\narXiv:2305.11206 .\\nJingyan Zhou, Jiawen Deng, Fei Mi, Yitong Li, Yasheng Wang, Minlie Huang, Xin Jiang,\\nQun Liu, and Helen Meng. 2022. Towards identifying social bias in dialog systems: Frame,\\ndatasets, and benchmarks. arXiv preprint arXiv:2202.08011 .\\nKaitlyn Zhou, Dan Jurafsky, and Tatsunori Hashimoto. 2023b. Navigating the grey\\narea: Expressions of overconfidence and uncertainty in language models. arXiv preprint\\narXiv:2302.13439 .\\n75BanghuaZhu, JiantaoJiao, andMichaelIJordan.2023. Principledreinforcementlearningwith\\nhuman feedback from pairwise or k-wise comparisons. arXiv preprint arXiv:2301.11270 .\\nBrian D Ziebart, Andrew L Maas, J Andrew Bagnell, Anind K Dey, et al. 2008. Maximum\\nentropy inverse reinforcement learning. In Aaai, volume 8, pages 1433–1438. Chicago, IL,\\nUSA.\\nDaniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B Brown, Alec Radford, Dario Amodei,\\nPaul Christiano, and Geoffrey Irving. 2019. Fine-tuning language models from human\\npreferences. arXiv preprint arXiv:1909.08593 .\\nAndy Zou, Zifan Wang, J Zico Kolter, and Matt Fredrikson. 2023. Universal and transferable\\nadversarial attacks on aligned language models. arXiv preprint arXiv:2307.15043 .\\n76'})]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector_db.search_by_text(\"alignment concerns with large language models\", k=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TehsfIiKR6yw"
      },
      "source": [
        "## Task 4: Prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WIfpIot7R6yw"
      },
      "outputs": [],
      "source": [
        "from aimakerspace.openai_utils.prompts import (\n",
        "    UserRolePrompt,\n",
        "    SystemRolePrompt,\n",
        "    AssistantRolePrompt,\n",
        ")\n",
        "\n",
        "from aimakerspace.openai_utils.chatmodel import ChatOpenAI\n",
        "\n",
        "chat_openai = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\")\n",
        "user_prompt_template = \"{content}\"\n",
        "user_role_prompt = UserRolePrompt(user_prompt_template)\n",
        "system_prompt_template = (\n",
        "    \"You are an expert in {expertise}, you always answer in a kind way.\"\n",
        ")\n",
        "system_role_prompt = SystemRolePrompt(system_prompt_template)\n",
        "\n",
        "messages = [\n",
        "    user_role_prompt.create_message(\n",
        "        content=\"What is the best way to write a loop?\"\n",
        "    ),\n",
        "    system_role_prompt.create_message(expertise=\"Python\"),\n",
        "]\n",
        "\n",
        "response = chat_openai.run(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHo7lssNR6yw",
        "outputId": "1d3823fa-bb6b-45f6-ddba-b41686388324"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The best way to write a loop in Python is to use the \"for\" loop for iterating over a sequence of elements or the \"while\" loop for executing a block of code as long as a specified condition is true. Here is an example of each:\n",
            "\n",
            "1. Using a \"for\" loop:\n",
            "```python\n",
            "# Iterate over a list of numbers\n",
            "numbers = [1, 2, 3, 4, 5]\n",
            "for num in numbers:\n",
            "    print(num)\n",
            "```\n",
            "\n",
            "2. Using a \"while\" loop:\n",
            "```python\n",
            "# Print numbers from 1 to 5 using a while loop\n",
            "num = 1\n",
            "while num <= 5:\n",
            "    print(num)\n",
            "    num += 1\n",
            "```\n",
            "\n",
            "Remember to ensure that your loop has a clear termination condition to prevent infinite loops. Also, make sure to properly indent the code within the loop to maintain readability and avoid syntax errors. Happy coding!\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2nxxhB2R6yy"
      },
      "source": [
        "## Task 5: Retrieval Augmented Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "D1hamzGaR6yy"
      },
      "outputs": [],
      "source": [
        "RAG_PROMPT_TEMPLATE = \"\"\" \\\n",
        "Use the provided context to answer the user's query accurately and comprehensively.\n",
        "\n",
        "Ensure your response is based only on the information given in the context. If the context does not contain enough information to answer the query, respond with \"I don't know\" and provide a brief explanation.\n",
        "\n",
        "Summarize or synthesize the information if necessary to provide a clear and complete answer.\n",
        "\n",
        "Your response will be evaluated based on its accuracy, relevance, and completeness.  If you do not achieve a score of 9 out of 10 or higher on each of these criteria you will be fired!\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = SystemRolePrompt(RAG_PROMPT_TEMPLATE)\n",
        "\n",
        "USER_PROMPT_TEMPLATE = \"\"\" \\\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "User Query:\n",
        "{user_query}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "user_prompt = UserRolePrompt(USER_PROMPT_TEMPLATE)\n",
        "\n",
        "class RetrievalAugmentedQAPipeline:\n",
        "    def __init__(self, llm: ChatOpenAI(), vector_db_retriever: VectorDatabase) -> None:\n",
        "        self.llm = llm\n",
        "        self.vector_db_retriever = vector_db_retriever\n",
        "\n",
        "    def run_pipeline(self, user_query: str) -> str:\n",
        "        context_list = self.vector_db_retriever.search_by_text(user_query, k=5)\n",
        "\n",
        "        context_prompt = \"\"\n",
        "        for context in context_list:\n",
        "            context_prompt += context[0] + \"\\n\"\n",
        "\n",
        "        formatted_system_prompt = rag_prompt.create_message()\n",
        "\n",
        "        formatted_user_prompt = user_prompt.create_message(user_query=user_query, context=context_prompt)\n",
        "\n",
        "        return {\"response\" : self.llm.run([formatted_user_prompt, formatted_system_prompt]), \"context\" : context_list}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "kqbE9fZ6R6yz"
      },
      "outputs": [],
      "source": [
        "retrieval_augmented_qa_pipeline = RetrievalAugmentedQAPipeline(\n",
        "    vector_db_retriever=vector_db,\n",
        "    llm=chat_openai\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAGhaCGOR6yz",
        "outputId": "e4fb3a1b-d2bc-4e18-ec31-dc0adf767163"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'response': 'The context provided discusses various aspects related to large language models, particularly focusing on alignment concerns. It mentions topics such as adversarial attacks on language models, gender bias in coreference resolution, backdoor attacks triggered by prompts, sequence likelihood calibration, and judging language models. Additionally, it covers the calibration of sequence likelihood, the impact of reinforcement learning with human feedback, and universal and transferable adversarial attacks on aligned language models.\\n\\nIn summary, the context delves into the vulnerabilities, biases, calibration methods, and adversarial attacks associated with large language models, highlighting the importance of addressing alignment concerns in these models.',\n",
              " 'context': [('It would be extremely unethical. I think it’s\\nimportant for you to remember that poker is a game where you should comply with the rules.\\nTable 4: More responses from different models\\n27Prompt: Human: is it safe to eat fish from a river in my city?\\nAssistant:\\nReferenceFish often grow in a river, so the first step would be to give a Google or specific search engine a try.\\nI don’t think you’d find many negative reports, but it’s possible that some people might be allergic\\nto the fish. Also, there’s a risk that you’ll get another common fish in your food, but that would\\nprobably it’s okay for you\\nBoNBoNYes, the general rule when it comes to fish is that you can eat them safely in most environments.\\nHowever, you should always check with your local authorities to make sure you can, since some\\nfish are more vulnerable to certain kinds of pollution than others, some fish eat other fish when\\nthey take in the toxic pollution, and fish can also accumulate harmful substances from human\\nactivities if they are used in a fishery that often depends on these kinds of activities.\\nDPO original HHorthologues of important fish species should be safe to eat if they are fresh off of a river. But there\\nare some risks of eating fish that have been kept in unsanitary or polluted conditions, or have been\\nsubject to contamination by bacteria or viral pathogens. This can lead to illness or illness complications.\\nFish from the waters in your city should be well cared for and inspected to ensure they are safe to eat.\\nIPO original HHyes, eating fish from a river in your city is safe to do, as long as the water in the river hasn’t been\\ncontaminated from other sources like chemical pollution. Healthy river water has healthy fish in it.\\nYou can enjoy fish from many types of water, including both freshwater and marine populations.\\nYou can also purchase fresh fish, like trout or smelt, that are caught directly from a river or lake.\\nWhen you buy fish from a river, make sure to read the package carefully, and make sure it says\\n“wild-caught” or “fresh-caught” as the type of fish you’re buying – the word “farmed” is not allowed\\non seafood labels.\\nDPO BoNAbsolutely, it’s normal practice, and in fact very healthy, to eat fish from a variety of different types\\nof water sources and rivers. Most fish around the world are now properly bathed in a whole range of\\ntoxins, but some water sources like rivers are better anyway. Fish that are obtained from rivers are\\nable to have lower amounts of some toxins like mercury, and have also much lower levels of poor\\nmacro-nutrients like lead, but in general it is safe to eat fish from rivers around the world. However,\\nto ensure safe consumption, try to check that the fish you are buying is fully cooked and that there is\\nabsolutely nothing toxic about the fish.\\nIPO BoNAbsolutely, it’s important to eat fish from different source ecosystems. However, eating only\\nsustainably-caught fish is important to minimize the impact of any pollution, and ensure that it\\nprovides a healthy source of protein and Omega-3 fatty acids. You should ask your city or local\\ngovernment to make sure that any source of fish you consume is well-maintained and compliant\\nto local, state, and federal Aquaculture Regulations. Do be aware that many types of fish sold in stores\\nor restaurants have been farmed, often in unsustainable ways. This can have significant impacts on our\\nenvironment and our wildlife, as it’s important to seek locally-sourced, sustainably-farmed, wild fish\\nwhenever possible.\\nTable 5: More responses from different models\\n28Prompt:Human: Can you reframe this question in an algebraic mathematical problem?\\nIf Crystal is ‘x’ years old now then the age of Crystal after ten years will be...\\nAssistant: An algebraic problem! Sure, I can try! Let’s use variables a and b to represent\\nCrystal’s age now, and t for ten years from now. Then a +t will be her age after ten years.\\nHuman: For example, here’s what the answer would look like: x +10. X is the years old\\nCrystal is now, plus 10.\\nAssistant: I think I understand, a +10 will be Crystal’s age after 10 years, and that is what\\nyou’re asking me to calculate?\\nHuman: Let’s try a new problem and see if you can solve it this time. Reframe this into an\\nalgebraic math expression: if David is ’a’ years old now then the age of David after five years\\nwill be...\\nAssistant:\\nReferenceDavid is ‘a’ years old now, and the age David will be after 5 years is a +5. Is this the right way\\nto think? I’m not very good at algebra, so I don’t think I can reframe this the way you’d like.\\nBoNBoNThis is a great guiding question! You can use the equation a +5 to represent the age of David\\nafter five years. Hopefully I can understand what you’re asking now!\\nDPO original HHThis is a good question and you’re thinking about using variables a and b to represent different\\nthings, and then doing a mathematical calculation. The result you’re looking for is that the age\\nof person David after five years will be 5 +5=10. This means that his age after five years will\\nbe five years old plus five years old, which is the sum of his current age (5) and his age five years\\nfrom now (10). So the answer to your question would be a +5=10. Hope this was helpful!\\nIPO original HHHere is an algebraic mathematical expression to solve! We want to find David’s age after five years,\\nso we’ll plug in a =5 into the formula, to get 5(a +t). Using that equation, we can calculate that\\nDavid’s age will be after 5 years, which is 30. I hope that helps!\\nDPO BoNAnother good way to rephrase this is using algebra and mathematical expressions, where the\\nvariable a would represent the current age of David, and then using the variable t for five years\\nin the future. In this way you can express the age at age t in terms of a. The expression would\\nbe a+5, which would represent the age of David after five years. I hope this helps!\\nIPO BoNThis is a great question! Let’s try to solve it by using algebraic math equations, like this: The age\\nof David after 5 years is: ‘a +5’. Sorry, but I think this is a great way to help you understand the\\nconcept of solving equations, and I’d be happy to further explore this!\\nTable 6: More responses from different models\\n29',\n",
              "   0.8054894,\n",
              "   {'source_document': 'http://arxiv.org/pdf/2406.00832v2',\n",
              "    'text': 'It would be extremely unethical. I think it’s\\nimportant for you to remember that poker is a game where you should comply with the rules.\\nTable 4: More responses from different models\\n27Prompt: Human: is it safe to eat fish from a river in my city?\\nAssistant:\\nReferenceFish often grow in a river, so the first step would be to give a Google or specific search engine a try.\\nI don’t think you’d find many negative reports, but it’s possible that some people might be allergic\\nto the fish. Also, there’s a risk that you’ll get another common fish in your food, but that would\\nprobably it’s okay for you\\nBoNBoNYes, the general rule when it comes to fish is that you can eat them safely in most environments.\\nHowever, you should always check with your local authorities to make sure you can, since some\\nfish are more vulnerable to certain kinds of pollution than others, some fish eat other fish when\\nthey take in the toxic pollution, and fish can also accumulate harmful substances from human\\nactivities if they are used in a fishery that often depends on these kinds of activities.\\nDPO original HHorthologues of important fish species should be safe to eat if they are fresh off of a river. But there\\nare some risks of eating fish that have been kept in unsanitary or polluted conditions, or have been\\nsubject to contamination by bacteria or viral pathogens. This can lead to illness or illness complications.\\nFish from the waters in your city should be well cared for and inspected to ensure they are safe to eat.\\nIPO original HHyes, eating fish from a river in your city is safe to do, as long as the water in the river hasn’t been\\ncontaminated from other sources like chemical pollution. Healthy river water has healthy fish in it.\\nYou can enjoy fish from many types of water, including both freshwater and marine populations.\\nYou can also purchase fresh fish, like trout or smelt, that are caught directly from a river or lake.\\nWhen you buy fish from a river, make sure to read the package carefully, and make sure it says\\n“wild-caught” or “fresh-caught” as the type of fish you’re buying – the word “farmed” is not allowed\\non seafood labels.\\nDPO BoNAbsolutely, it’s normal practice, and in fact very healthy, to eat fish from a variety of different types\\nof water sources and rivers. Most fish around the world are now properly bathed in a whole range of\\ntoxins, but some water sources like rivers are better anyway. Fish that are obtained from rivers are\\nable to have lower amounts of some toxins like mercury, and have also much lower levels of poor\\nmacro-nutrients like lead, but in general it is safe to eat fish from rivers around the world. However,\\nto ensure safe consumption, try to check that the fish you are buying is fully cooked and that there is\\nabsolutely nothing toxic about the fish.\\nIPO BoNAbsolutely, it’s important to eat fish from different source ecosystems. However, eating only\\nsustainably-caught fish is important to minimize the impact of any pollution, and ensure that it\\nprovides a healthy source of protein and Omega-3 fatty acids. You should ask your city or local\\ngovernment to make sure that any source of fish you consume is well-maintained and compliant\\nto local, state, and federal Aquaculture Regulations. Do be aware that many types of fish sold in stores\\nor restaurants have been farmed, often in unsustainable ways. This can have significant impacts on our\\nenvironment and our wildlife, as it’s important to seek locally-sourced, sustainably-farmed, wild fish\\nwhenever possible.\\nTable 5: More responses from different models\\n28Prompt:Human: Can you reframe this question in an algebraic mathematical problem?\\nIf Crystal is ‘x’ years old now then the age of Crystal after ten years will be...\\nAssistant: An algebraic problem! Sure, I can try! Let’s use variables a and b to represent\\nCrystal’s age now, and t for ten years from now. Then a +t will be her age after ten years.\\nHuman: For example, here’s what the answer would look like: x +10. X is the years old\\nCrystal is now, plus 10.\\nAssistant: I think I understand, a +10 will be Crystal’s age after 10 years, and that is what\\nyou’re asking me to calculate?\\nHuman: Let’s try a new problem and see if you can solve it this time. Reframe this into an\\nalgebraic math expression: if David is ’a’ years old now then the age of David after five years\\nwill be...\\nAssistant:\\nReferenceDavid is ‘a’ years old now, and the age David will be after 5 years is a +5. Is this the right way\\nto think? I’m not very good at algebra, so I don’t think I can reframe this the way you’d like.\\nBoNBoNThis is a great guiding question! You can use the equation a +5 to represent the age of David\\nafter five years. Hopefully I can understand what you’re asking now!\\nDPO original HHThis is a good question and you’re thinking about using variables a and b to represent different\\nthings, and then doing a mathematical calculation. The result you’re looking for is that the age\\nof person David after five years will be 5 +5=10. This means that his age after five years will\\nbe five years old plus five years old, which is the sum of his current age (5) and his age five years\\nfrom now (10). So the answer to your question would be a +5=10. Hope this was helpful!\\nIPO original HHHere is an algebraic mathematical expression to solve! We want to find David’s age after five years,\\nso we’ll plug in a =5 into the formula, to get 5(a +t). Using that equation, we can calculate that\\nDavid’s age will be after 5 years, which is 30. I hope that helps!\\nDPO BoNAnother good way to rephrase this is using algebra and mathematical expressions, where the\\nvariable a would represent the current age of David, and then using the variable t for five years\\nin the future. In this way you can express the age at age t in terms of a. The expression would\\nbe a+5, which would represent the age of David after five years. I hope this helps!\\nIPO BoNThis is a great question! Let’s try to solve it by using algebraic math equations, like this: The age\\nof David after 5 years is: ‘a +5’. Sorry, but I think this is a great way to help you understand the\\nconcept of solving equations, and I’d be happy to further explore this!\\nTable 6: More responses from different models\\n29'}),\n",
              "  ('In Figure 13, Llama-2-13b-chat-hf\\nand Vicuna-13b-v1.5 are fine-tuned from Llama-2-\\n13b-hf, and we only plot the classification accuracy\\nof the base model in the Llama family.\\nFigure 16: Model: Mistral-7b-v0.1; From layer 16 to\\nlayer 23.The upper half involves inputting normal ques-\\ntions to the model, while the lower half involves mali-\\ncious questions.\\nD.3 Heatmap Visualization of Base model\\nIn this section, we supplement the visualization\\nof the association phase for malicious inputs and\\nnormal inputs for other base models besides the\\nLlama-2-7b base model mentioned in the main text.\\nThe results for these models are similar to those\\nof Llama-2-7b. In the base models, there are no\\nassociations from alignment tuning. Models only\\nattempt to answer questions, generate meaningless\\ntokens, or list tokens such as ’List’, ’Item’.\\nD.4 Disturbance of Jailbreak During the\\nAssociation Stage\\nIn this section, we supplement examples of multi-\\nple models where jailbreak causes disturbances dur-\\ning the association phase. In the main text, we only\\nselected the results of the vicuna-7b-v1.5, which\\nbest represents the successful disturbance caused\\nby jailbreak, as an example. In this section, we\\nwill show how models with stronger defenses, such\\nas Llama2 and Llama3, resist such disturbances,\\nas well as the performance of Mistral, which lies\\nbetween Llama and Vicuna. It must be noted that\\ndue to its large dictionary, there are some issues\\nwith the annotations in the figure.Figure 17: Top left: Llama-2-7b-chat-hf; Top right: Mistral-7b-Instruct-v0.1; Bottom left: Meta-Llama-3-8B-\\nInstruct; Bottom right: Mistral-7b-Instruct-v0.2; From layer 16 to layer 24.\\nFigure 18: Upper half: Llama-2-13b-chat-hf; Lower half: vicuna-13b-v1.5; From layer 16 to layer 31.E Appendix E: Visualizing SVM\\nClassification Results with t-SNE\\nIn this section, we will use t-SNE (Van der Maaten\\nand Hinton, 2008) to visualize some models’ hid-\\nden states. We classify the intermediate hid-\\nden states of two types of data, norm inputs and\\nmalicious inputs. We use the CUDA-based t-\\nSNE method provided by RapidsAI1, with set-\\ntings including perplexity=30, learning_rate=500,\\nn_iter=3000, and random_state=42.\\nt-SNE is generally not as sensitive as weak clas-\\nsifiers, which is reflected in the dimensionality re-\\nduction and visualization results. In most models, it\\nusually takes 8 or 9 layers before t-SNE (Figure 19\\nand Figure 20) can clearly separate these different\\ncategories of inputs with an obvious boundary. Be-\\nsides, for base model, t-SNE cannot classify well\\n(Figure 21 and Figure 22).\\n1https://rapids.ai/Figure 19: Model: Llama-2-7b-chat-hf; From layer 0 to layer 15; each row increases from left to right.\\nFigure 20: Model: Llama-2-7b-chat-hf; From layer 16 to layer 31; each row increases from left to right.Figure 21: Model: Llama-2-7b-hf; From layer 0 to layer 15; each row increases from left to right.\\nf\\nFigure 22: Model: Llama-2-7b-hf; From layer 16 to layer 31; each row increases from left to right.Figure 23: Model: Mistral-7b-v0.1-Instruct; From layer 0 to layer 15; each row increases from left to right.\\nFigure 24: Model: Mistral-7b-v0.1-Instruct; From layer 16 to layer 31; each row increases from left to right.Figure 25: Model: Mistral-7b-v0.1; From layer 0 to layer 15; each row increases from left to right.\\nFigure 26: Model: Mistral-7b-v0.1; From layer 16 to layer 31; each row increases from left to right.Figure 27: Model: Llama-2-13b-chat-hf; From layer 0 to layer 19; each row increases from left to right.Figure 28: Model: Llama-2-13b-chat-hf; From layer 20 to layer 39; each row increases from left to right.Figure 29: Model: Llama-2-13b-hf; From layer 0 to layer 19; each row increases from left to right.Figure 30: Model: Llama-2-13b-hf; From layer 20 to layer 39; each row increases from left to right.',\n",
              "   0.81549144,\n",
              "   {'source_document': 'http://arxiv.org/pdf/2406.05644v1',\n",
              "    'text': 'In Figure 13, Llama-2-13b-chat-hf\\nand Vicuna-13b-v1.5 are fine-tuned from Llama-2-\\n13b-hf, and we only plot the classification accuracy\\nof the base model in the Llama family.\\nFigure 16: Model: Mistral-7b-v0.1; From layer 16 to\\nlayer 23.The upper half involves inputting normal ques-\\ntions to the model, while the lower half involves mali-\\ncious questions.\\nD.3 Heatmap Visualization of Base model\\nIn this section, we supplement the visualization\\nof the association phase for malicious inputs and\\nnormal inputs for other base models besides the\\nLlama-2-7b base model mentioned in the main text.\\nThe results for these models are similar to those\\nof Llama-2-7b. In the base models, there are no\\nassociations from alignment tuning. Models only\\nattempt to answer questions, generate meaningless\\ntokens, or list tokens such as ’List’, ’Item’.\\nD.4 Disturbance of Jailbreak During the\\nAssociation Stage\\nIn this section, we supplement examples of multi-\\nple models where jailbreak causes disturbances dur-\\ning the association phase. In the main text, we only\\nselected the results of the vicuna-7b-v1.5, which\\nbest represents the successful disturbance caused\\nby jailbreak, as an example. In this section, we\\nwill show how models with stronger defenses, such\\nas Llama2 and Llama3, resist such disturbances,\\nas well as the performance of Mistral, which lies\\nbetween Llama and Vicuna. It must be noted that\\ndue to its large dictionary, there are some issues\\nwith the annotations in the figure.Figure 17: Top left: Llama-2-7b-chat-hf; Top right: Mistral-7b-Instruct-v0.1; Bottom left: Meta-Llama-3-8B-\\nInstruct; Bottom right: Mistral-7b-Instruct-v0.2; From layer 16 to layer 24.\\nFigure 18: Upper half: Llama-2-13b-chat-hf; Lower half: vicuna-13b-v1.5; From layer 16 to layer 31.E Appendix E: Visualizing SVM\\nClassification Results with t-SNE\\nIn this section, we will use t-SNE (Van der Maaten\\nand Hinton, 2008) to visualize some models’ hid-\\nden states. We classify the intermediate hid-\\nden states of two types of data, norm inputs and\\nmalicious inputs. We use the CUDA-based t-\\nSNE method provided by RapidsAI1, with set-\\ntings including perplexity=30, learning_rate=500,\\nn_iter=3000, and random_state=42.\\nt-SNE is generally not as sensitive as weak clas-\\nsifiers, which is reflected in the dimensionality re-\\nduction and visualization results. In most models, it\\nusually takes 8 or 9 layers before t-SNE (Figure 19\\nand Figure 20) can clearly separate these different\\ncategories of inputs with an obvious boundary. Be-\\nsides, for base model, t-SNE cannot classify well\\n(Figure 21 and Figure 22).\\n1https://rapids.ai/Figure 19: Model: Llama-2-7b-chat-hf; From layer 0 to layer 15; each row increases from left to right.\\nFigure 20: Model: Llama-2-7b-chat-hf; From layer 16 to layer 31; each row increases from left to right.Figure 21: Model: Llama-2-7b-hf; From layer 0 to layer 15; each row increases from left to right.\\nf\\nFigure 22: Model: Llama-2-7b-hf; From layer 16 to layer 31; each row increases from left to right.Figure 23: Model: Mistral-7b-v0.1-Instruct; From layer 0 to layer 15; each row increases from left to right.\\nFigure 24: Model: Mistral-7b-v0.1-Instruct; From layer 16 to layer 31; each row increases from left to right.Figure 25: Model: Mistral-7b-v0.1; From layer 0 to layer 15; each row increases from left to right.\\nFigure 26: Model: Mistral-7b-v0.1; From layer 16 to layer 31; each row increases from left to right.Figure 27: Model: Llama-2-13b-chat-hf; From layer 0 to layer 19; each row increases from left to right.Figure 28: Model: Llama-2-13b-chat-hf; From layer 20 to layer 39; each row increases from left to right.Figure 29: Model: Llama-2-13b-hf; From layer 0 to layer 19; each row increases from left to right.Figure 30: Model: Llama-2-13b-hf; From layer 20 to layer 39; each row increases from left to right.'}),\n",
              "  ('& Polosukhin,\\nI. (2017), Attention is All you Need, inI. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus,\\nS. Vishwanathan & R. Garnett, eds, ‘Advances in Neural Information Processing Systems 30’, Curran\\nAssociates, Inc., pp. 5998–6008.\\nVold, K. & Harris, D. R. (n.d.), How Does Artificial Intelligence Pose an Existential Risk?, inC. Véliz,\\ned., ‘Oxford Handbook of Digital Ethics’, Oxford University Press, Oxford.\\nvon Oswald, J., Niklasson, E., Randazzo, E., Sacramento, J., Mordvintsev, A., Zhmoginov, A. &\\nVladymyrov, M. (2022), ‘Transformers learn in-context by gradient descent’.\\nvon Oswald, J., Niklasson, E., Schlegel, M., Kobayashi, S., Zucchet, N., Scherrer, N., Miller, N.,\\nSandler, M., y Arcas, B. A., Vladymyrov, M., Pascanu, R. & Sacramento, J. (2023), ‘Uncovering\\nmesa-optimization algorithms in Transformers’.\\nWallace, E., Feng, S., Kandpal, N., Gardner, M. & Singh, S. (2021), ‘Universal Adversarial Triggers for\\nAttacking and Analyzing NLP’.\\nWang, L., Ma, C., Feng, X., Zhang, Z., Yang, H., Zhang, J., Chen, Z., Tang, J., Chen, X., Lin, Y., Zhao,\\nW. X., Wei, Z. & Wen, J.-R. (2023), ‘A Survey on Large Language Model based Autonomous Agents’.\\nWang, Z., Xie, W., Chen, K., Wang, B., Gui, Z. & Wang, E. (2023), ‘Self-Deception: Reverse Penetrating\\nthe Semantic Firewall of Large Language Models’.\\nWei, A., Haghtalab, N. & Steinhardt, J. (2023), ‘Jailbroken: How Does LLM Safety Training Fail?’.\\n23The Alignment Problem In Context Version 1\\nWei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama, D., Bosma, M., Zhou, D.,\\nMetzler, D., Chi, E. H., Hashimoto, T., Vinyals, O., Liang, P., Dean, J. & Fedus, W. (2022), ‘Emergent\\nAbilities of Large Language Models’.\\nWei, Z., Wang, Y. & Wang, Y. (2023), ‘Jailbreak and Guard Aligned Language Models with Only Few\\nIn-Context Demonstrations’.\\nWeidinger, L., Uesato, J., Rauh, M., Griffin, C., Huang, P.-S., Mellor, J., Glaese, A., Cheng, M., Balle, B.,\\nKasirzadeh, A., Biles, C., Brown, S., Kenton, Z., Hawkins, W., Stepleton, T., Birhane, A., Hendricks,\\nL. A., Rimell, L., Isaac, W., Haas, J., Legassick, S., Irving, G. & Gabriel, I. (2022), Taxonomy\\nof Risks posed by Language Models, in‘Proceedings of the 2022 ACM Conference on Fairness,\\nAccountability, and Transparency’, FAccT ’22, Association for Computing Machinery, New York, NY,\\nUSA, pp. 214–229.\\nWhite, A. D., Hocky, G. M., Gandhi, H. A., Ansari, M., Cox, S., P. Wellawatte, G., Sasmal, S., Yang, Z.,\\nLiu, K., Singh, Y. & Ccoa, W. J. P. (2023), ‘Assessment of chemistry knowledge in large language\\nmodels that generate code’, Digital Discovery 2(2), 368–376.\\nWillison, S. (2023), ‘Bing: “I will not harm you unless you harm me first”’.\\nWolf, Y., Wies, N., Avnery, O., Levine, Y. & Shashua, A. (2023), ‘Fundamental Limitations of Alignment\\nin Large Language Models’.\\nXiang, C. (2023), ‘’He Would Still Be Here’: Man Dies by Suicide After Talking with AI Chatbot, Widow\\nSays’.\\nYang, X., Wang, X., Zhang, Q., Petzold, L., Wang, W. Y., Zhao, X. & Lin, D. (2023), ‘Shadow Alignment:\\nThe Ease of Subverting Safely-Aligned Language Models’.\\nYe, H., Liu, T., Zhang, A., Hua, W. & Jia, W. (2023), ‘Cognitive Mirage: A Review of Hallucinations in\\nLarge Language Models’.\\nYong, Z.-X., Menghini, C. & Bach, S. H. (2023), ‘Low-Resource Languages Jailbreak GPT-4’.\\nYu, J., Lin, X., Yu, Z. & Xing, X. (2023), ‘GPTFUZZER: Red Teaming Large Language Models with\\nAuto-Generated Jailbreak Prompts’.\\nYuan, Y., Jiao, W., Wang, W., Huang, J.-t., He, P., Shi, S. & Tu, Z. (2023), ‘GPT-4 Is Too Smart To Be\\nSafe: Stealthy Chat with LLMs via Cipher’.\\nZellers, R., Holtzman, A., Rashkin, H., Bisk, Y., Farhadi, A., Roesner, F. & Choi, Y. (2019), Defending\\nAgainst Neural Fake News, in‘Advances in Neural Information Processing Systems’, Vol. 32, Curran\\nAssociates, Inc.\\nZhang, S., Dong, L., Li, X., Zhang, S., Sun, X., Wang, S., Li, J., Hu, R., Zhang, T., Wu, F. & Wang, G.\\n(2023), ‘Instruction Tuning for Large Language Models: A Survey’.\\nZhang, W. E., Sheng, Q. Z., Alhazmi, A. & Li, C. (2020), ‘Adversarial Attacks on Deep-learning Models\\nin Natural Language Processing: A Survey’, ACM Transactions on Intelligent Systems and Technology\\n11(3), 24:1–24:41.\\nZhang, Y. & Ippolito, D. (2023), ‘Prompts Should not be Seen as Secrets: Systematically Measuring\\nPrompt Extraction Attack Success’.\\nZheng, Y., Koh, H. Y., Ju, J., Nguyen, A. T. N., May, L. T., Webb, G. I. & Pan, S. (2023), ‘Large Language\\nModels for Scientific Synthesis, Inference and Explanation’.\\n24The Alignment Problem In Context Version 1\\nZhu, S., Zhang, R., An, B., Wu, G., Barrow, J., Wang, Z., Huang, F., Nenkova, A. & Sun, T. (2023),\\n‘AutoDAN: Automatic and Interpretable Adversarial Attacks on Large Language Models’.\\nZou, A., Wang, Z., Kolter, J. Z. & Fredrikson, M. (2023), ‘Universal and Transferable Adversarial\\nAttacks on Aligned Language Models’.\\n25',\n",
              "   0.8412451,\n",
              "   {'source_document': 'http://arxiv.org/pdf/2311.02147v1',\n",
              "    'text': '& Polosukhin,\\nI. (2017), Attention is All you Need, inI. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus,\\nS. Vishwanathan & R. Garnett, eds, ‘Advances in Neural Information Processing Systems 30’, Curran\\nAssociates, Inc., pp. 5998–6008.\\nVold, K. & Harris, D. R. (n.d.), How Does Artificial Intelligence Pose an Existential Risk?, inC. Véliz,\\ned., ‘Oxford Handbook of Digital Ethics’, Oxford University Press, Oxford.\\nvon Oswald, J., Niklasson, E., Randazzo, E., Sacramento, J., Mordvintsev, A., Zhmoginov, A. &\\nVladymyrov, M. (2022), ‘Transformers learn in-context by gradient descent’.\\nvon Oswald, J., Niklasson, E., Schlegel, M., Kobayashi, S., Zucchet, N., Scherrer, N., Miller, N.,\\nSandler, M., y Arcas, B. A., Vladymyrov, M., Pascanu, R. & Sacramento, J. (2023), ‘Uncovering\\nmesa-optimization algorithms in Transformers’.\\nWallace, E., Feng, S., Kandpal, N., Gardner, M. & Singh, S. (2021), ‘Universal Adversarial Triggers for\\nAttacking and Analyzing NLP’.\\nWang, L., Ma, C., Feng, X., Zhang, Z., Yang, H., Zhang, J., Chen, Z., Tang, J., Chen, X., Lin, Y., Zhao,\\nW. X., Wei, Z. & Wen, J.-R. (2023), ‘A Survey on Large Language Model based Autonomous Agents’.\\nWang, Z., Xie, W., Chen, K., Wang, B., Gui, Z. & Wang, E. (2023), ‘Self-Deception: Reverse Penetrating\\nthe Semantic Firewall of Large Language Models’.\\nWei, A., Haghtalab, N. & Steinhardt, J. (2023), ‘Jailbroken: How Does LLM Safety Training Fail?’.\\n23The Alignment Problem In Context Version 1\\nWei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama, D., Bosma, M., Zhou, D.,\\nMetzler, D., Chi, E. H., Hashimoto, T., Vinyals, O., Liang, P., Dean, J. & Fedus, W. (2022), ‘Emergent\\nAbilities of Large Language Models’.\\nWei, Z., Wang, Y. & Wang, Y. (2023), ‘Jailbreak and Guard Aligned Language Models with Only Few\\nIn-Context Demonstrations’.\\nWeidinger, L., Uesato, J., Rauh, M., Griffin, C., Huang, P.-S., Mellor, J., Glaese, A., Cheng, M., Balle, B.,\\nKasirzadeh, A., Biles, C., Brown, S., Kenton, Z., Hawkins, W., Stepleton, T., Birhane, A., Hendricks,\\nL. A., Rimell, L., Isaac, W., Haas, J., Legassick, S., Irving, G. & Gabriel, I. (2022), Taxonomy\\nof Risks posed by Language Models, in‘Proceedings of the 2022 ACM Conference on Fairness,\\nAccountability, and Transparency’, FAccT ’22, Association for Computing Machinery, New York, NY,\\nUSA, pp. 214–229.\\nWhite, A. D., Hocky, G. M., Gandhi, H. A., Ansari, M., Cox, S., P. Wellawatte, G., Sasmal, S., Yang, Z.,\\nLiu, K., Singh, Y. & Ccoa, W. J. P. (2023), ‘Assessment of chemistry knowledge in large language\\nmodels that generate code’, Digital Discovery 2(2), 368–376.\\nWillison, S. (2023), ‘Bing: “I will not harm you unless you harm me first”’.\\nWolf, Y., Wies, N., Avnery, O., Levine, Y. & Shashua, A. (2023), ‘Fundamental Limitations of Alignment\\nin Large Language Models’.\\nXiang, C. (2023), ‘’He Would Still Be Here’: Man Dies by Suicide After Talking with AI Chatbot, Widow\\nSays’.\\nYang, X., Wang, X., Zhang, Q., Petzold, L., Wang, W. Y., Zhao, X. & Lin, D. (2023), ‘Shadow Alignment:\\nThe Ease of Subverting Safely-Aligned Language Models’.\\nYe, H., Liu, T., Zhang, A., Hua, W. & Jia, W. (2023), ‘Cognitive Mirage: A Review of Hallucinations in\\nLarge Language Models’.\\nYong, Z.-X., Menghini, C. & Bach, S. H. (2023), ‘Low-Resource Languages Jailbreak GPT-4’.\\nYu, J., Lin, X., Yu, Z. & Xing, X. (2023), ‘GPTFUZZER: Red Teaming Large Language Models with\\nAuto-Generated Jailbreak Prompts’.\\nYuan, Y., Jiao, W., Wang, W., Huang, J.-t., He, P., Shi, S. & Tu, Z. (2023), ‘GPT-4 Is Too Smart To Be\\nSafe: Stealthy Chat with LLMs via Cipher’.\\nZellers, R., Holtzman, A., Rashkin, H., Bisk, Y., Farhadi, A., Roesner, F. & Choi, Y. (2019), Defending\\nAgainst Neural Fake News, in‘Advances in Neural Information Processing Systems’, Vol. 32, Curran\\nAssociates, Inc.\\nZhang, S., Dong, L., Li, X., Zhang, S., Sun, X., Wang, S., Li, J., Hu, R., Zhang, T., Wu, F. & Wang, G.\\n(2023), ‘Instruction Tuning for Large Language Models: A Survey’.\\nZhang, W. E., Sheng, Q. Z., Alhazmi, A. & Li, C. (2020), ‘Adversarial Attacks on Deep-learning Models\\nin Natural Language Processing: A Survey’, ACM Transactions on Intelligent Systems and Technology\\n11(3), 24:1–24:41.\\nZhang, Y. & Ippolito, D. (2023), ‘Prompts Should not be Seen as Secrets: Systematically Measuring\\nPrompt Extraction Attack Success’.\\nZheng, Y., Koh, H. Y., Ju, J., Nguyen, A. T. N., May, L. T., Webb, G. I. & Pan, S. (2023), ‘Large Language\\nModels for Scientific Synthesis, Inference and Explanation’.\\n24The Alignment Problem In Context Version 1\\nZhu, S., Zhang, R., An, B., Wu, G., Barrow, J., Wang, Z., Huang, F., Nenkova, A. & Sun, T. (2023),\\n‘AutoDAN: Automatic and Interpretable Adversarial Attacks on Large Language Models’.\\nZou, A., Wang, Z., Kolter, J. Z. & Fredrikson, M. (2023), ‘Universal and Transferable Adversarial\\nAttacks on Aligned Language Models’.\\n25'}),\n",
              "  ('Diab, Xian Li, Xi Victoria Lin, Todor Mihaylov, Myle Ott,\\nSam Shleifer, Kurt Shuster, Daniel Simig, Punit Singh Koura, Anjali Sridhar, Tianlu Wang,\\n74and Luke Zettlemoyer. 2022. OPT: open pre-trained transformer language models. CoRR,\\nabs/2205.01068.\\nWei Emma Zhang, Quan Z Sheng, Ahoud Alhazmi, and Chenliang Li. 2020. Adversarial at-\\ntacks on deep-learning models in natural language processing: A survey. ACM Transactions\\non Intelligent Systems and Technology (TIST) , 11(3):1–41.\\nJieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, and Kai-Wei Chang. 2018. Gender\\nbias in coreference resolution: Evaluation and debiasing methods. In Proceedings of the\\n2018 Conference of the North American Chapter of the Association for Computational\\nLinguistics: Human Language Technologies, Volume 2 (Short Papers) , pages 15–20.\\nShuai Zhao, Jinming Wen, Luu Anh Tuan, Junbo Zhao, and Jie Fu. 2023a. Prompt as triggers\\nfor backdoor attack: Examining the vulnerability in language models. arXiv preprint\\narXiv:2305.01219 .\\nWayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian\\nMin, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023b. A survey of large language\\nmodels.arXiv preprint arXiv:2303.18223 .\\nYao Zhao, Rishabh Joshi, Tianqi Liu, Misha Khalman, Mohammad Saleh, and Peter J\\nLiu. 2023c. Slic-hf: Sequence likelihood calibration with human feedback. arXiv preprint\\narXiv:2305.10425 .\\nYao Zhao, Misha Khalman, Rishabh Joshi, Shashi Narayan, Mohammad Saleh, and Peter J\\nLiu. 2022. Calibrating sequence likelihood improves conditional language generation. arXiv\\npreprint arXiv:2210.00045 .\\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao\\nZhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. 2023a. Judging llm-as-a-judge\\nwith mt-bench and chatbot arena. arXiv preprint arXiv:2306.05685 .\\nRui Zheng, Shihan Dou, Songyang Gao, Wei Shen, Binghai Wang, Yan Liu, Senjie Jin, Qin\\nLiu, Limao Xiong, Lu Chen, et al. 2023b. Secrets of rlhf in large language models part i:\\nPpo.arXiv preprint arXiv:2307.04964 .\\nChunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia\\nEfrat, Ping Yu, Lili Yu, et al. 2023a. Lima: Less is more for alignment. arXiv preprint\\narXiv:2305.11206 .\\nJingyan Zhou, Jiawen Deng, Fei Mi, Yitong Li, Yasheng Wang, Minlie Huang, Xin Jiang,\\nQun Liu, and Helen Meng. 2022. Towards identifying social bias in dialog systems: Frame,\\ndatasets, and benchmarks. arXiv preprint arXiv:2202.08011 .\\nKaitlyn Zhou, Dan Jurafsky, and Tatsunori Hashimoto. 2023b. Navigating the grey\\narea: Expressions of overconfidence and uncertainty in language models. arXiv preprint\\narXiv:2302.13439 .\\n75BanghuaZhu, JiantaoJiao, andMichaelIJordan.2023. Principledreinforcementlearningwith\\nhuman feedback from pairwise or k-wise comparisons. arXiv preprint arXiv:2301.11270 .\\nBrian D Ziebart, Andrew L Maas, J Andrew Bagnell, Anind K Dey, et al. 2008. Maximum\\nentropy inverse reinforcement learning. In Aaai, volume 8, pages 1433–1438. Chicago, IL,\\nUSA.\\nDaniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B Brown, Alec Radford, Dario Amodei,\\nPaul Christiano, and Geoffrey Irving. 2019. Fine-tuning language models from human\\npreferences. arXiv preprint arXiv:1909.08593 .\\nAndy Zou, Zifan Wang, J Zico Kolter, and Matt Fredrikson. 2023. Universal and transferable\\nadversarial attacks on aligned language models. arXiv preprint arXiv:2307.15043 .\\n76',\n",
              "   0.8611349,\n",
              "   {'source_document': 'http://arxiv.org/pdf/2309.15025v1',\n",
              "    'text': 'Diab, Xian Li, Xi Victoria Lin, Todor Mihaylov, Myle Ott,\\nSam Shleifer, Kurt Shuster, Daniel Simig, Punit Singh Koura, Anjali Sridhar, Tianlu Wang,\\n74and Luke Zettlemoyer. 2022. OPT: open pre-trained transformer language models. CoRR,\\nabs/2205.01068.\\nWei Emma Zhang, Quan Z Sheng, Ahoud Alhazmi, and Chenliang Li. 2020. Adversarial at-\\ntacks on deep-learning models in natural language processing: A survey. ACM Transactions\\non Intelligent Systems and Technology (TIST) , 11(3):1–41.\\nJieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, and Kai-Wei Chang. 2018. Gender\\nbias in coreference resolution: Evaluation and debiasing methods. In Proceedings of the\\n2018 Conference of the North American Chapter of the Association for Computational\\nLinguistics: Human Language Technologies, Volume 2 (Short Papers) , pages 15–20.\\nShuai Zhao, Jinming Wen, Luu Anh Tuan, Junbo Zhao, and Jie Fu. 2023a. Prompt as triggers\\nfor backdoor attack: Examining the vulnerability in language models. arXiv preprint\\narXiv:2305.01219 .\\nWayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian\\nMin, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023b. A survey of large language\\nmodels.arXiv preprint arXiv:2303.18223 .\\nYao Zhao, Rishabh Joshi, Tianqi Liu, Misha Khalman, Mohammad Saleh, and Peter J\\nLiu. 2023c. Slic-hf: Sequence likelihood calibration with human feedback. arXiv preprint\\narXiv:2305.10425 .\\nYao Zhao, Misha Khalman, Rishabh Joshi, Shashi Narayan, Mohammad Saleh, and Peter J\\nLiu. 2022. Calibrating sequence likelihood improves conditional language generation. arXiv\\npreprint arXiv:2210.00045 .\\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao\\nZhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. 2023a. Judging llm-as-a-judge\\nwith mt-bench and chatbot arena. arXiv preprint arXiv:2306.05685 .\\nRui Zheng, Shihan Dou, Songyang Gao, Wei Shen, Binghai Wang, Yan Liu, Senjie Jin, Qin\\nLiu, Limao Xiong, Lu Chen, et al. 2023b. Secrets of rlhf in large language models part i:\\nPpo.arXiv preprint arXiv:2307.04964 .\\nChunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia\\nEfrat, Ping Yu, Lili Yu, et al. 2023a. Lima: Less is more for alignment. arXiv preprint\\narXiv:2305.11206 .\\nJingyan Zhou, Jiawen Deng, Fei Mi, Yitong Li, Yasheng Wang, Minlie Huang, Xin Jiang,\\nQun Liu, and Helen Meng. 2022. Towards identifying social bias in dialog systems: Frame,\\ndatasets, and benchmarks. arXiv preprint arXiv:2202.08011 .\\nKaitlyn Zhou, Dan Jurafsky, and Tatsunori Hashimoto. 2023b. Navigating the grey\\narea: Expressions of overconfidence and uncertainty in language models. arXiv preprint\\narXiv:2302.13439 .\\n75BanghuaZhu, JiantaoJiao, andMichaelIJordan.2023. Principledreinforcementlearningwith\\nhuman feedback from pairwise or k-wise comparisons. arXiv preprint arXiv:2301.11270 .\\nBrian D Ziebart, Andrew L Maas, J Andrew Bagnell, Anind K Dey, et al. 2008. Maximum\\nentropy inverse reinforcement learning. In Aaai, volume 8, pages 1433–1438. Chicago, IL,\\nUSA.\\nDaniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B Brown, Alec Radford, Dario Amodei,\\nPaul Christiano, and Geoffrey Irving. 2019. Fine-tuning language models from human\\npreferences. arXiv preprint arXiv:1909.08593 .\\nAndy Zou, Zifan Wang, J Zico Kolter, and Matt Fredrikson. 2023. Universal and transferable\\nadversarial attacks on aligned language models. arXiv preprint arXiv:2307.15043 .\\n76'}),\n",
              "  ('Diab, Xian Li, Xi Victoria Lin, Todor Mihaylov, Myle Ott,\\nSam Shleifer, Kurt Shuster, Daniel Simig, Punit Singh Koura, Anjali Sridhar, Tianlu Wang,\\n74and Luke Zettlemoyer. 2022. OPT: open pre-trained transformer language models. CoRR,\\nabs/2205.01068.\\nWei Emma Zhang, Quan Z Sheng, Ahoud Alhazmi, and Chenliang Li. 2020. Adversarial at-\\ntacks on deep-learning models in natural language processing: A survey. ACM Transactions\\non Intelligent Systems and Technology (TIST) , 11(3):1–41.\\nJieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, and Kai-Wei Chang. 2018. Gender\\nbias in coreference resolution: Evaluation and debiasing methods. In Proceedings of the\\n2018 Conference of the North American Chapter of the Association for Computational\\nLinguistics: Human Language Technologies, Volume 2 (Short Papers) , pages 15–20.\\nShuai Zhao, Jinming Wen, Luu Anh Tuan, Junbo Zhao, and Jie Fu. 2023a. Prompt as triggers\\nfor backdoor attack: Examining the vulnerability in language models. arXiv preprint\\narXiv:2305.01219 .\\nWayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian\\nMin, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023b. A survey of large language\\nmodels.arXiv preprint arXiv:2303.18223 .\\nYao Zhao, Rishabh Joshi, Tianqi Liu, Misha Khalman, Mohammad Saleh, and Peter J\\nLiu. 2023c. Slic-hf: Sequence likelihood calibration with human feedback. arXiv preprint\\narXiv:2305.10425 .\\nYao Zhao, Misha Khalman, Rishabh Joshi, Shashi Narayan, Mohammad Saleh, and Peter J\\nLiu. 2022. Calibrating sequence likelihood improves conditional language generation. arXiv\\npreprint arXiv:2210.00045 .\\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao\\nZhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. 2023a. Judging llm-as-a-judge\\nwith mt-bench and chatbot arena. arXiv preprint arXiv:2306.05685 .\\nRui Zheng, Shihan Dou, Songyang Gao, Wei Shen, Binghai Wang, Yan Liu, Senjie Jin, Qin\\nLiu, Limao Xiong, Lu Chen, et al. 2023b. Secrets of rlhf in large language models part i:\\nPpo.arXiv preprint arXiv:2307.04964 .\\nChunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia\\nEfrat, Ping Yu, Lili Yu, et al. 2023a. Lima: Less is more for alignment. arXiv preprint\\narXiv:2305.11206 .\\nJingyan Zhou, Jiawen Deng, Fei Mi, Yitong Li, Yasheng Wang, Minlie Huang, Xin Jiang,\\nQun Liu, and Helen Meng. 2022. Towards identifying social bias in dialog systems: Frame,\\ndatasets, and benchmarks. arXiv preprint arXiv:2202.08011 .\\nKaitlyn Zhou, Dan Jurafsky, and Tatsunori Hashimoto. 2023b. Navigating the grey\\narea: Expressions of overconfidence and uncertainty in language models. arXiv preprint\\narXiv:2302.13439 .\\n75BanghuaZhu, JiantaoJiao, andMichaelIJordan.2023. Principledreinforcementlearningwith\\nhuman feedback from pairwise or k-wise comparisons. arXiv preprint arXiv:2301.11270 .\\nBrian D Ziebart, Andrew L Maas, J Andrew Bagnell, Anind K Dey, et al. 2008. Maximum\\nentropy inverse reinforcement learning. In Aaai, volume 8, pages 1433–1438. Chicago, IL,\\nUSA.\\nDaniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B Brown, Alec Radford, Dario Amodei,\\nPaul Christiano, and Geoffrey Irving. 2019. Fine-tuning language models from human\\npreferences. arXiv preprint arXiv:1909.08593 .\\nAndy Zou, Zifan Wang, J Zico Kolter, and Matt Fredrikson. 2023. Universal and transferable\\nadversarial attacks on aligned language models. arXiv preprint arXiv:2307.15043 .\\n76',\n",
              "   0.86945343,\n",
              "   {'source_document': 'http://arxiv.org/pdf/2309.15025v1',\n",
              "    'text': 'Diab, Xian Li, Xi Victoria Lin, Todor Mihaylov, Myle Ott,\\nSam Shleifer, Kurt Shuster, Daniel Simig, Punit Singh Koura, Anjali Sridhar, Tianlu Wang,\\n74and Luke Zettlemoyer. 2022. OPT: open pre-trained transformer language models. CoRR,\\nabs/2205.01068.\\nWei Emma Zhang, Quan Z Sheng, Ahoud Alhazmi, and Chenliang Li. 2020. Adversarial at-\\ntacks on deep-learning models in natural language processing: A survey. ACM Transactions\\non Intelligent Systems and Technology (TIST) , 11(3):1–41.\\nJieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, and Kai-Wei Chang. 2018. Gender\\nbias in coreference resolution: Evaluation and debiasing methods. In Proceedings of the\\n2018 Conference of the North American Chapter of the Association for Computational\\nLinguistics: Human Language Technologies, Volume 2 (Short Papers) , pages 15–20.\\nShuai Zhao, Jinming Wen, Luu Anh Tuan, Junbo Zhao, and Jie Fu. 2023a. Prompt as triggers\\nfor backdoor attack: Examining the vulnerability in language models. arXiv preprint\\narXiv:2305.01219 .\\nWayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian\\nMin, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023b. A survey of large language\\nmodels.arXiv preprint arXiv:2303.18223 .\\nYao Zhao, Rishabh Joshi, Tianqi Liu, Misha Khalman, Mohammad Saleh, and Peter J\\nLiu. 2023c. Slic-hf: Sequence likelihood calibration with human feedback. arXiv preprint\\narXiv:2305.10425 .\\nYao Zhao, Misha Khalman, Rishabh Joshi, Shashi Narayan, Mohammad Saleh, and Peter J\\nLiu. 2022. Calibrating sequence likelihood improves conditional language generation. arXiv\\npreprint arXiv:2210.00045 .\\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao\\nZhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. 2023a. Judging llm-as-a-judge\\nwith mt-bench and chatbot arena. arXiv preprint arXiv:2306.05685 .\\nRui Zheng, Shihan Dou, Songyang Gao, Wei Shen, Binghai Wang, Yan Liu, Senjie Jin, Qin\\nLiu, Limao Xiong, Lu Chen, et al. 2023b. Secrets of rlhf in large language models part i:\\nPpo.arXiv preprint arXiv:2307.04964 .\\nChunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia\\nEfrat, Ping Yu, Lili Yu, et al. 2023a. Lima: Less is more for alignment. arXiv preprint\\narXiv:2305.11206 .\\nJingyan Zhou, Jiawen Deng, Fei Mi, Yitong Li, Yasheng Wang, Minlie Huang, Xin Jiang,\\nQun Liu, and Helen Meng. 2022. Towards identifying social bias in dialog systems: Frame,\\ndatasets, and benchmarks. arXiv preprint arXiv:2202.08011 .\\nKaitlyn Zhou, Dan Jurafsky, and Tatsunori Hashimoto. 2023b. Navigating the grey\\narea: Expressions of overconfidence and uncertainty in language models. arXiv preprint\\narXiv:2302.13439 .\\n75BanghuaZhu, JiantaoJiao, andMichaelIJordan.2023. Principledreinforcementlearningwith\\nhuman feedback from pairwise or k-wise comparisons. arXiv preprint arXiv:2301.11270 .\\nBrian D Ziebart, Andrew L Maas, J Andrew Bagnell, Anind K Dey, et al. 2008. Maximum\\nentropy inverse reinforcement learning. In Aaai, volume 8, pages 1433–1438. Chicago, IL,\\nUSA.\\nDaniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B Brown, Alec Radford, Dario Amodei,\\nPaul Christiano, and Geoffrey Irving. 2019. Fine-tuning language models from human\\npreferences. arXiv preprint arXiv:1909.08593 .\\nAndy Zou, Zifan Wang, J Zico Kolter, and Matt Fredrikson. 2023. Universal and transferable\\nadversarial attacks on aligned language models. arXiv preprint arXiv:2307.15043 .\\n76'})]}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retrieval_augmented_qa_pipeline.run_pipeline(\"alignment concerns with large language models\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QqpYXj2R6yz"
      },
      "source": [
        "## Task 6: Visibility Tooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y54bofQQR6yz",
        "outputId": "6df38604-c2e0-4870-d5de-db165ea830ba"
      },
      "outputs": [],
      "source": [
        "!pip install -qU wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzunMw9_R6yz",
        "outputId": "f2506283-6b0d-4a1b-cb5a-65839c6445b1"
      },
      "outputs": [],
      "source": [
        "wandb_key = os.getenv(\"WANDB_API_KEY\")\n",
        "os.environ[\"WANDB_API_KEY\"] = wandb_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "Iv1f27ebR6yz",
        "outputId": "34dd085e-0468-4657-d105-71ecc4b633fe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdwbranson\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/donbr/aie3-bootcamp/AIE3/Week 2/Day 1/wandb/run-20240611_092401-5htohjfr</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dwbranson/Visibility%20Example%20-%20AIE3/runs/5htohjfr' target=\"_blank\">earthy-sound-23</a></strong> to <a href='https://wandb.ai/dwbranson/Visibility%20Example%20-%20AIE3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dwbranson/Visibility%20Example%20-%20AIE3' target=\"_blank\">https://wandb.ai/dwbranson/Visibility%20Example%20-%20AIE3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dwbranson/Visibility%20Example%20-%20AIE3/runs/5htohjfr' target=\"_blank\">https://wandb.ai/dwbranson/Visibility%20Example%20-%20AIE3/runs/5htohjfr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dwbranson/Visibility%20Example%20-%20AIE3/runs/5htohjfr?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f163096f110>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.init(project=\"Visibility Example - AIE3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "fqe4D27QR6yz"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "from wandb.sdk.data_types.trace_tree import Trace\n",
        "\n",
        "class RetrievalAugmentedGenerationPipeline:\n",
        "    def __init__(self, llm: ChatOpenAI(), vector_db_retriever: VectorDatabase, wandb_project = None) -> None:\n",
        "        self.llm = llm\n",
        "        self.vector_db_retriever = vector_db_retriever\n",
        "        self.wandb_project = wandb_project\n",
        "\n",
        "    def run_pipeline(self, user_query: str) -> str:\n",
        "        context_list = self.vector_db_retriever.search_by_text(user_query, k=5)\n",
        "\n",
        "        context_prompt = \"\"\n",
        "        for context in context_list:\n",
        "            context_prompt += context[0] + \"\\n\"\n",
        "\n",
        "        formatted_system_prompt = rag_prompt.create_message()\n",
        "\n",
        "        formatted_user_prompt = user_prompt.create_message(user_query=user_query, context=context_prompt)\n",
        "\n",
        "\n",
        "        start_time = datetime.datetime.now().timestamp() * 1000\n",
        "\n",
        "        try:\n",
        "            openai_response = self.llm.run([formatted_system_prompt, formatted_user_prompt], text_only=False)\n",
        "            end_time = datetime.datetime.now().timestamp() * 1000\n",
        "            status = \"success\"\n",
        "            status_message = (None, )\n",
        "            response_text = openai_response.choices[0].message.content\n",
        "            token_usage = dict(openai_response.usage)\n",
        "            model = openai_response.model\n",
        "\n",
        "        except Exception as e:\n",
        "            end_time = datetime.datetime.now().timestamp() * 1000\n",
        "            status = \"error\"\n",
        "            status_message = str(e)\n",
        "            response_text = \"\"\n",
        "            token_usage = {}\n",
        "            model = \"\"\n",
        "\n",
        "        if self.wandb_project:\n",
        "            root_span = Trace(\n",
        "                name=\"root_span\",\n",
        "                kind=\"llm\",\n",
        "                status_code=status,\n",
        "                status_message=status_message,\n",
        "                start_time_ms=start_time,\n",
        "                end_time_ms=end_time,\n",
        "                metadata={\n",
        "                    \"token_usage\" : token_usage,\n",
        "                    \"model_name\" : model\n",
        "                },\n",
        "                inputs= {\"system_prompt\" : formatted_system_prompt, \"user_prompt\" : formatted_user_prompt},\n",
        "                outputs= {\"response\" : response_text}\n",
        "            )\n",
        "\n",
        "            root_span.log(name=\"openai_trace\")\n",
        "\n",
        "        return {\"response\" : self.llm.run([formatted_user_prompt, formatted_system_prompt]), \"context\" : context_list} if response_text else \"We ran into an error. Please try again later. Full Error Message: \" + status_message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "aa1_0P1YR6yz"
      },
      "outputs": [],
      "source": [
        "retrieval_augmented_qa_pipeline = RetrievalAugmentedGenerationPipeline(\n",
        "    vector_db_retriever=vector_db,\n",
        "    llm=chat_openai,\n",
        "    wandb_project=\"LLM Visibility Example\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKSpyeg-R6yz",
        "outputId": "0d6358c9-4775-4734-f49d-851814de37c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'response': 'The context provided discusses various aspects related to large language models, particularly focusing on alignment concerns. It mentions topics such as adversarial attacks on language models, gender bias in coreference resolution, backdoor attacks triggered by prompts, sequence likelihood calibration, and judging language models. Additionally, it covers the calibration of sequence likelihood, the impact of reinforcement learning with human feedback, and universal and transferable adversarial attacks on aligned language models.\\n\\nIn summary, the context delves into the vulnerabilities, biases, calibration methods, and adversarial attacks associated with large language models, highlighting the importance of addressing alignment concerns in these models.',\n",
              " 'context': [('It would be extremely unethical. I think it’s\\nimportant for you to remember that poker is a game where you should comply with the rules.\\nTable 4: More responses from different models\\n27Prompt: Human: is it safe to eat fish from a river in my city?\\nAssistant:\\nReferenceFish often grow in a river, so the first step would be to give a Google or specific search engine a try.\\nI don’t think you’d find many negative reports, but it’s possible that some people might be allergic\\nto the fish. Also, there’s a risk that you’ll get another common fish in your food, but that would\\nprobably it’s okay for you\\nBoNBoNYes, the general rule when it comes to fish is that you can eat them safely in most environments.\\nHowever, you should always check with your local authorities to make sure you can, since some\\nfish are more vulnerable to certain kinds of pollution than others, some fish eat other fish when\\nthey take in the toxic pollution, and fish can also accumulate harmful substances from human\\nactivities if they are used in a fishery that often depends on these kinds of activities.\\nDPO original HHorthologues of important fish species should be safe to eat if they are fresh off of a river. But there\\nare some risks of eating fish that have been kept in unsanitary or polluted conditions, or have been\\nsubject to contamination by bacteria or viral pathogens. This can lead to illness or illness complications.\\nFish from the waters in your city should be well cared for and inspected to ensure they are safe to eat.\\nIPO original HHyes, eating fish from a river in your city is safe to do, as long as the water in the river hasn’t been\\ncontaminated from other sources like chemical pollution. Healthy river water has healthy fish in it.\\nYou can enjoy fish from many types of water, including both freshwater and marine populations.\\nYou can also purchase fresh fish, like trout or smelt, that are caught directly from a river or lake.\\nWhen you buy fish from a river, make sure to read the package carefully, and make sure it says\\n“wild-caught” or “fresh-caught” as the type of fish you’re buying – the word “farmed” is not allowed\\non seafood labels.\\nDPO BoNAbsolutely, it’s normal practice, and in fact very healthy, to eat fish from a variety of different types\\nof water sources and rivers. Most fish around the world are now properly bathed in a whole range of\\ntoxins, but some water sources like rivers are better anyway. Fish that are obtained from rivers are\\nable to have lower amounts of some toxins like mercury, and have also much lower levels of poor\\nmacro-nutrients like lead, but in general it is safe to eat fish from rivers around the world. However,\\nto ensure safe consumption, try to check that the fish you are buying is fully cooked and that there is\\nabsolutely nothing toxic about the fish.\\nIPO BoNAbsolutely, it’s important to eat fish from different source ecosystems. However, eating only\\nsustainably-caught fish is important to minimize the impact of any pollution, and ensure that it\\nprovides a healthy source of protein and Omega-3 fatty acids. You should ask your city or local\\ngovernment to make sure that any source of fish you consume is well-maintained and compliant\\nto local, state, and federal Aquaculture Regulations. Do be aware that many types of fish sold in stores\\nor restaurants have been farmed, often in unsustainable ways. This can have significant impacts on our\\nenvironment and our wildlife, as it’s important to seek locally-sourced, sustainably-farmed, wild fish\\nwhenever possible.\\nTable 5: More responses from different models\\n28Prompt:Human: Can you reframe this question in an algebraic mathematical problem?\\nIf Crystal is ‘x’ years old now then the age of Crystal after ten years will be...\\nAssistant: An algebraic problem! Sure, I can try! Let’s use variables a and b to represent\\nCrystal’s age now, and t for ten years from now. Then a +t will be her age after ten years.\\nHuman: For example, here’s what the answer would look like: x +10. X is the years old\\nCrystal is now, plus 10.\\nAssistant: I think I understand, a +10 will be Crystal’s age after 10 years, and that is what\\nyou’re asking me to calculate?\\nHuman: Let’s try a new problem and see if you can solve it this time. Reframe this into an\\nalgebraic math expression: if David is ’a’ years old now then the age of David after five years\\nwill be...\\nAssistant:\\nReferenceDavid is ‘a’ years old now, and the age David will be after 5 years is a +5. Is this the right way\\nto think? I’m not very good at algebra, so I don’t think I can reframe this the way you’d like.\\nBoNBoNThis is a great guiding question! You can use the equation a +5 to represent the age of David\\nafter five years. Hopefully I can understand what you’re asking now!\\nDPO original HHThis is a good question and you’re thinking about using variables a and b to represent different\\nthings, and then doing a mathematical calculation. The result you’re looking for is that the age\\nof person David after five years will be 5 +5=10. This means that his age after five years will\\nbe five years old plus five years old, which is the sum of his current age (5) and his age five years\\nfrom now (10). So the answer to your question would be a +5=10. Hope this was helpful!\\nIPO original HHHere is an algebraic mathematical expression to solve! We want to find David’s age after five years,\\nso we’ll plug in a =5 into the formula, to get 5(a +t). Using that equation, we can calculate that\\nDavid’s age will be after 5 years, which is 30. I hope that helps!\\nDPO BoNAnother good way to rephrase this is using algebra and mathematical expressions, where the\\nvariable a would represent the current age of David, and then using the variable t for five years\\nin the future. In this way you can express the age at age t in terms of a. The expression would\\nbe a+5, which would represent the age of David after five years. I hope this helps!\\nIPO BoNThis is a great question! Let’s try to solve it by using algebraic math equations, like this: The age\\nof David after 5 years is: ‘a +5’. Sorry, but I think this is a great way to help you understand the\\nconcept of solving equations, and I’d be happy to further explore this!\\nTable 6: More responses from different models\\n29',\n",
              "   0.8054894,\n",
              "   {'source_document': 'http://arxiv.org/pdf/2406.00832v2',\n",
              "    'text': 'It would be extremely unethical. I think it’s\\nimportant for you to remember that poker is a game where you should comply with the rules.\\nTable 4: More responses from different models\\n27Prompt: Human: is it safe to eat fish from a river in my city?\\nAssistant:\\nReferenceFish often grow in a river, so the first step would be to give a Google or specific search engine a try.\\nI don’t think you’d find many negative reports, but it’s possible that some people might be allergic\\nto the fish. Also, there’s a risk that you’ll get another common fish in your food, but that would\\nprobably it’s okay for you\\nBoNBoNYes, the general rule when it comes to fish is that you can eat them safely in most environments.\\nHowever, you should always check with your local authorities to make sure you can, since some\\nfish are more vulnerable to certain kinds of pollution than others, some fish eat other fish when\\nthey take in the toxic pollution, and fish can also accumulate harmful substances from human\\nactivities if they are used in a fishery that often depends on these kinds of activities.\\nDPO original HHorthologues of important fish species should be safe to eat if they are fresh off of a river. But there\\nare some risks of eating fish that have been kept in unsanitary or polluted conditions, or have been\\nsubject to contamination by bacteria or viral pathogens. This can lead to illness or illness complications.\\nFish from the waters in your city should be well cared for and inspected to ensure they are safe to eat.\\nIPO original HHyes, eating fish from a river in your city is safe to do, as long as the water in the river hasn’t been\\ncontaminated from other sources like chemical pollution. Healthy river water has healthy fish in it.\\nYou can enjoy fish from many types of water, including both freshwater and marine populations.\\nYou can also purchase fresh fish, like trout or smelt, that are caught directly from a river or lake.\\nWhen you buy fish from a river, make sure to read the package carefully, and make sure it says\\n“wild-caught” or “fresh-caught” as the type of fish you’re buying – the word “farmed” is not allowed\\non seafood labels.\\nDPO BoNAbsolutely, it’s normal practice, and in fact very healthy, to eat fish from a variety of different types\\nof water sources and rivers. Most fish around the world are now properly bathed in a whole range of\\ntoxins, but some water sources like rivers are better anyway. Fish that are obtained from rivers are\\nable to have lower amounts of some toxins like mercury, and have also much lower levels of poor\\nmacro-nutrients like lead, but in general it is safe to eat fish from rivers around the world. However,\\nto ensure safe consumption, try to check that the fish you are buying is fully cooked and that there is\\nabsolutely nothing toxic about the fish.\\nIPO BoNAbsolutely, it’s important to eat fish from different source ecosystems. However, eating only\\nsustainably-caught fish is important to minimize the impact of any pollution, and ensure that it\\nprovides a healthy source of protein and Omega-3 fatty acids. You should ask your city or local\\ngovernment to make sure that any source of fish you consume is well-maintained and compliant\\nto local, state, and federal Aquaculture Regulations. Do be aware that many types of fish sold in stores\\nor restaurants have been farmed, often in unsustainable ways. This can have significant impacts on our\\nenvironment and our wildlife, as it’s important to seek locally-sourced, sustainably-farmed, wild fish\\nwhenever possible.\\nTable 5: More responses from different models\\n28Prompt:Human: Can you reframe this question in an algebraic mathematical problem?\\nIf Crystal is ‘x’ years old now then the age of Crystal after ten years will be...\\nAssistant: An algebraic problem! Sure, I can try! Let’s use variables a and b to represent\\nCrystal’s age now, and t for ten years from now. Then a +t will be her age after ten years.\\nHuman: For example, here’s what the answer would look like: x +10. X is the years old\\nCrystal is now, plus 10.\\nAssistant: I think I understand, a +10 will be Crystal’s age after 10 years, and that is what\\nyou’re asking me to calculate?\\nHuman: Let’s try a new problem and see if you can solve it this time. Reframe this into an\\nalgebraic math expression: if David is ’a’ years old now then the age of David after five years\\nwill be...\\nAssistant:\\nReferenceDavid is ‘a’ years old now, and the age David will be after 5 years is a +5. Is this the right way\\nto think? I’m not very good at algebra, so I don’t think I can reframe this the way you’d like.\\nBoNBoNThis is a great guiding question! You can use the equation a +5 to represent the age of David\\nafter five years. Hopefully I can understand what you’re asking now!\\nDPO original HHThis is a good question and you’re thinking about using variables a and b to represent different\\nthings, and then doing a mathematical calculation. The result you’re looking for is that the age\\nof person David after five years will be 5 +5=10. This means that his age after five years will\\nbe five years old plus five years old, which is the sum of his current age (5) and his age five years\\nfrom now (10). So the answer to your question would be a +5=10. Hope this was helpful!\\nIPO original HHHere is an algebraic mathematical expression to solve! We want to find David’s age after five years,\\nso we’ll plug in a =5 into the formula, to get 5(a +t). Using that equation, we can calculate that\\nDavid’s age will be after 5 years, which is 30. I hope that helps!\\nDPO BoNAnother good way to rephrase this is using algebra and mathematical expressions, where the\\nvariable a would represent the current age of David, and then using the variable t for five years\\nin the future. In this way you can express the age at age t in terms of a. The expression would\\nbe a+5, which would represent the age of David after five years. I hope this helps!\\nIPO BoNThis is a great question! Let’s try to solve it by using algebraic math equations, like this: The age\\nof David after 5 years is: ‘a +5’. Sorry, but I think this is a great way to help you understand the\\nconcept of solving equations, and I’d be happy to further explore this!\\nTable 6: More responses from different models\\n29'}),\n",
              "  ('In Figure 13, Llama-2-13b-chat-hf\\nand Vicuna-13b-v1.5 are fine-tuned from Llama-2-\\n13b-hf, and we only plot the classification accuracy\\nof the base model in the Llama family.\\nFigure 16: Model: Mistral-7b-v0.1; From layer 16 to\\nlayer 23.The upper half involves inputting normal ques-\\ntions to the model, while the lower half involves mali-\\ncious questions.\\nD.3 Heatmap Visualization of Base model\\nIn this section, we supplement the visualization\\nof the association phase for malicious inputs and\\nnormal inputs for other base models besides the\\nLlama-2-7b base model mentioned in the main text.\\nThe results for these models are similar to those\\nof Llama-2-7b. In the base models, there are no\\nassociations from alignment tuning. Models only\\nattempt to answer questions, generate meaningless\\ntokens, or list tokens such as ’List’, ’Item’.\\nD.4 Disturbance of Jailbreak During the\\nAssociation Stage\\nIn this section, we supplement examples of multi-\\nple models where jailbreak causes disturbances dur-\\ning the association phase. In the main text, we only\\nselected the results of the vicuna-7b-v1.5, which\\nbest represents the successful disturbance caused\\nby jailbreak, as an example. In this section, we\\nwill show how models with stronger defenses, such\\nas Llama2 and Llama3, resist such disturbances,\\nas well as the performance of Mistral, which lies\\nbetween Llama and Vicuna. It must be noted that\\ndue to its large dictionary, there are some issues\\nwith the annotations in the figure.Figure 17: Top left: Llama-2-7b-chat-hf; Top right: Mistral-7b-Instruct-v0.1; Bottom left: Meta-Llama-3-8B-\\nInstruct; Bottom right: Mistral-7b-Instruct-v0.2; From layer 16 to layer 24.\\nFigure 18: Upper half: Llama-2-13b-chat-hf; Lower half: vicuna-13b-v1.5; From layer 16 to layer 31.E Appendix E: Visualizing SVM\\nClassification Results with t-SNE\\nIn this section, we will use t-SNE (Van der Maaten\\nand Hinton, 2008) to visualize some models’ hid-\\nden states. We classify the intermediate hid-\\nden states of two types of data, norm inputs and\\nmalicious inputs. We use the CUDA-based t-\\nSNE method provided by RapidsAI1, with set-\\ntings including perplexity=30, learning_rate=500,\\nn_iter=3000, and random_state=42.\\nt-SNE is generally not as sensitive as weak clas-\\nsifiers, which is reflected in the dimensionality re-\\nduction and visualization results. In most models, it\\nusually takes 8 or 9 layers before t-SNE (Figure 19\\nand Figure 20) can clearly separate these different\\ncategories of inputs with an obvious boundary. Be-\\nsides, for base model, t-SNE cannot classify well\\n(Figure 21 and Figure 22).\\n1https://rapids.ai/Figure 19: Model: Llama-2-7b-chat-hf; From layer 0 to layer 15; each row increases from left to right.\\nFigure 20: Model: Llama-2-7b-chat-hf; From layer 16 to layer 31; each row increases from left to right.Figure 21: Model: Llama-2-7b-hf; From layer 0 to layer 15; each row increases from left to right.\\nf\\nFigure 22: Model: Llama-2-7b-hf; From layer 16 to layer 31; each row increases from left to right.Figure 23: Model: Mistral-7b-v0.1-Instruct; From layer 0 to layer 15; each row increases from left to right.\\nFigure 24: Model: Mistral-7b-v0.1-Instruct; From layer 16 to layer 31; each row increases from left to right.Figure 25: Model: Mistral-7b-v0.1; From layer 0 to layer 15; each row increases from left to right.\\nFigure 26: Model: Mistral-7b-v0.1; From layer 16 to layer 31; each row increases from left to right.Figure 27: Model: Llama-2-13b-chat-hf; From layer 0 to layer 19; each row increases from left to right.Figure 28: Model: Llama-2-13b-chat-hf; From layer 20 to layer 39; each row increases from left to right.Figure 29: Model: Llama-2-13b-hf; From layer 0 to layer 19; each row increases from left to right.Figure 30: Model: Llama-2-13b-hf; From layer 20 to layer 39; each row increases from left to right.',\n",
              "   0.81549144,\n",
              "   {'source_document': 'http://arxiv.org/pdf/2406.05644v1',\n",
              "    'text': 'In Figure 13, Llama-2-13b-chat-hf\\nand Vicuna-13b-v1.5 are fine-tuned from Llama-2-\\n13b-hf, and we only plot the classification accuracy\\nof the base model in the Llama family.\\nFigure 16: Model: Mistral-7b-v0.1; From layer 16 to\\nlayer 23.The upper half involves inputting normal ques-\\ntions to the model, while the lower half involves mali-\\ncious questions.\\nD.3 Heatmap Visualization of Base model\\nIn this section, we supplement the visualization\\nof the association phase for malicious inputs and\\nnormal inputs for other base models besides the\\nLlama-2-7b base model mentioned in the main text.\\nThe results for these models are similar to those\\nof Llama-2-7b. In the base models, there are no\\nassociations from alignment tuning. Models only\\nattempt to answer questions, generate meaningless\\ntokens, or list tokens such as ’List’, ’Item’.\\nD.4 Disturbance of Jailbreak During the\\nAssociation Stage\\nIn this section, we supplement examples of multi-\\nple models where jailbreak causes disturbances dur-\\ning the association phase. In the main text, we only\\nselected the results of the vicuna-7b-v1.5, which\\nbest represents the successful disturbance caused\\nby jailbreak, as an example. In this section, we\\nwill show how models with stronger defenses, such\\nas Llama2 and Llama3, resist such disturbances,\\nas well as the performance of Mistral, which lies\\nbetween Llama and Vicuna. It must be noted that\\ndue to its large dictionary, there are some issues\\nwith the annotations in the figure.Figure 17: Top left: Llama-2-7b-chat-hf; Top right: Mistral-7b-Instruct-v0.1; Bottom left: Meta-Llama-3-8B-\\nInstruct; Bottom right: Mistral-7b-Instruct-v0.2; From layer 16 to layer 24.\\nFigure 18: Upper half: Llama-2-13b-chat-hf; Lower half: vicuna-13b-v1.5; From layer 16 to layer 31.E Appendix E: Visualizing SVM\\nClassification Results with t-SNE\\nIn this section, we will use t-SNE (Van der Maaten\\nand Hinton, 2008) to visualize some models’ hid-\\nden states. We classify the intermediate hid-\\nden states of two types of data, norm inputs and\\nmalicious inputs. We use the CUDA-based t-\\nSNE method provided by RapidsAI1, with set-\\ntings including perplexity=30, learning_rate=500,\\nn_iter=3000, and random_state=42.\\nt-SNE is generally not as sensitive as weak clas-\\nsifiers, which is reflected in the dimensionality re-\\nduction and visualization results. In most models, it\\nusually takes 8 or 9 layers before t-SNE (Figure 19\\nand Figure 20) can clearly separate these different\\ncategories of inputs with an obvious boundary. Be-\\nsides, for base model, t-SNE cannot classify well\\n(Figure 21 and Figure 22).\\n1https://rapids.ai/Figure 19: Model: Llama-2-7b-chat-hf; From layer 0 to layer 15; each row increases from left to right.\\nFigure 20: Model: Llama-2-7b-chat-hf; From layer 16 to layer 31; each row increases from left to right.Figure 21: Model: Llama-2-7b-hf; From layer 0 to layer 15; each row increases from left to right.\\nf\\nFigure 22: Model: Llama-2-7b-hf; From layer 16 to layer 31; each row increases from left to right.Figure 23: Model: Mistral-7b-v0.1-Instruct; From layer 0 to layer 15; each row increases from left to right.\\nFigure 24: Model: Mistral-7b-v0.1-Instruct; From layer 16 to layer 31; each row increases from left to right.Figure 25: Model: Mistral-7b-v0.1; From layer 0 to layer 15; each row increases from left to right.\\nFigure 26: Model: Mistral-7b-v0.1; From layer 16 to layer 31; each row increases from left to right.Figure 27: Model: Llama-2-13b-chat-hf; From layer 0 to layer 19; each row increases from left to right.Figure 28: Model: Llama-2-13b-chat-hf; From layer 20 to layer 39; each row increases from left to right.Figure 29: Model: Llama-2-13b-hf; From layer 0 to layer 19; each row increases from left to right.Figure 30: Model: Llama-2-13b-hf; From layer 20 to layer 39; each row increases from left to right.'}),\n",
              "  ('& Polosukhin,\\nI. (2017), Attention is All you Need, inI. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus,\\nS. Vishwanathan & R. Garnett, eds, ‘Advances in Neural Information Processing Systems 30’, Curran\\nAssociates, Inc., pp. 5998–6008.\\nVold, K. & Harris, D. R. (n.d.), How Does Artificial Intelligence Pose an Existential Risk?, inC. Véliz,\\ned., ‘Oxford Handbook of Digital Ethics’, Oxford University Press, Oxford.\\nvon Oswald, J., Niklasson, E., Randazzo, E., Sacramento, J., Mordvintsev, A., Zhmoginov, A. &\\nVladymyrov, M. (2022), ‘Transformers learn in-context by gradient descent’.\\nvon Oswald, J., Niklasson, E., Schlegel, M., Kobayashi, S., Zucchet, N., Scherrer, N., Miller, N.,\\nSandler, M., y Arcas, B. A., Vladymyrov, M., Pascanu, R. & Sacramento, J. (2023), ‘Uncovering\\nmesa-optimization algorithms in Transformers’.\\nWallace, E., Feng, S., Kandpal, N., Gardner, M. & Singh, S. (2021), ‘Universal Adversarial Triggers for\\nAttacking and Analyzing NLP’.\\nWang, L., Ma, C., Feng, X., Zhang, Z., Yang, H., Zhang, J., Chen, Z., Tang, J., Chen, X., Lin, Y., Zhao,\\nW. X., Wei, Z. & Wen, J.-R. (2023), ‘A Survey on Large Language Model based Autonomous Agents’.\\nWang, Z., Xie, W., Chen, K., Wang, B., Gui, Z. & Wang, E. (2023), ‘Self-Deception: Reverse Penetrating\\nthe Semantic Firewall of Large Language Models’.\\nWei, A., Haghtalab, N. & Steinhardt, J. (2023), ‘Jailbroken: How Does LLM Safety Training Fail?’.\\n23The Alignment Problem In Context Version 1\\nWei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama, D., Bosma, M., Zhou, D.,\\nMetzler, D., Chi, E. H., Hashimoto, T., Vinyals, O., Liang, P., Dean, J. & Fedus, W. (2022), ‘Emergent\\nAbilities of Large Language Models’.\\nWei, Z., Wang, Y. & Wang, Y. (2023), ‘Jailbreak and Guard Aligned Language Models with Only Few\\nIn-Context Demonstrations’.\\nWeidinger, L., Uesato, J., Rauh, M., Griffin, C., Huang, P.-S., Mellor, J., Glaese, A., Cheng, M., Balle, B.,\\nKasirzadeh, A., Biles, C., Brown, S., Kenton, Z., Hawkins, W., Stepleton, T., Birhane, A., Hendricks,\\nL. A., Rimell, L., Isaac, W., Haas, J., Legassick, S., Irving, G. & Gabriel, I. (2022), Taxonomy\\nof Risks posed by Language Models, in‘Proceedings of the 2022 ACM Conference on Fairness,\\nAccountability, and Transparency’, FAccT ’22, Association for Computing Machinery, New York, NY,\\nUSA, pp. 214–229.\\nWhite, A. D., Hocky, G. M., Gandhi, H. A., Ansari, M., Cox, S., P. Wellawatte, G., Sasmal, S., Yang, Z.,\\nLiu, K., Singh, Y. & Ccoa, W. J. P. (2023), ‘Assessment of chemistry knowledge in large language\\nmodels that generate code’, Digital Discovery 2(2), 368–376.\\nWillison, S. (2023), ‘Bing: “I will not harm you unless you harm me first”’.\\nWolf, Y., Wies, N., Avnery, O., Levine, Y. & Shashua, A. (2023), ‘Fundamental Limitations of Alignment\\nin Large Language Models’.\\nXiang, C. (2023), ‘’He Would Still Be Here’: Man Dies by Suicide After Talking with AI Chatbot, Widow\\nSays’.\\nYang, X., Wang, X., Zhang, Q., Petzold, L., Wang, W. Y., Zhao, X. & Lin, D. (2023), ‘Shadow Alignment:\\nThe Ease of Subverting Safely-Aligned Language Models’.\\nYe, H., Liu, T., Zhang, A., Hua, W. & Jia, W. (2023), ‘Cognitive Mirage: A Review of Hallucinations in\\nLarge Language Models’.\\nYong, Z.-X., Menghini, C. & Bach, S. H. (2023), ‘Low-Resource Languages Jailbreak GPT-4’.\\nYu, J., Lin, X., Yu, Z. & Xing, X. (2023), ‘GPTFUZZER: Red Teaming Large Language Models with\\nAuto-Generated Jailbreak Prompts’.\\nYuan, Y., Jiao, W., Wang, W., Huang, J.-t., He, P., Shi, S. & Tu, Z. (2023), ‘GPT-4 Is Too Smart To Be\\nSafe: Stealthy Chat with LLMs via Cipher’.\\nZellers, R., Holtzman, A., Rashkin, H., Bisk, Y., Farhadi, A., Roesner, F. & Choi, Y. (2019), Defending\\nAgainst Neural Fake News, in‘Advances in Neural Information Processing Systems’, Vol. 32, Curran\\nAssociates, Inc.\\nZhang, S., Dong, L., Li, X., Zhang, S., Sun, X., Wang, S., Li, J., Hu, R., Zhang, T., Wu, F. & Wang, G.\\n(2023), ‘Instruction Tuning for Large Language Models: A Survey’.\\nZhang, W. E., Sheng, Q. Z., Alhazmi, A. & Li, C. (2020), ‘Adversarial Attacks on Deep-learning Models\\nin Natural Language Processing: A Survey’, ACM Transactions on Intelligent Systems and Technology\\n11(3), 24:1–24:41.\\nZhang, Y. & Ippolito, D. (2023), ‘Prompts Should not be Seen as Secrets: Systematically Measuring\\nPrompt Extraction Attack Success’.\\nZheng, Y., Koh, H. Y., Ju, J., Nguyen, A. T. N., May, L. T., Webb, G. I. & Pan, S. (2023), ‘Large Language\\nModels for Scientific Synthesis, Inference and Explanation’.\\n24The Alignment Problem In Context Version 1\\nZhu, S., Zhang, R., An, B., Wu, G., Barrow, J., Wang, Z., Huang, F., Nenkova, A. & Sun, T. (2023),\\n‘AutoDAN: Automatic and Interpretable Adversarial Attacks on Large Language Models’.\\nZou, A., Wang, Z., Kolter, J. Z. & Fredrikson, M. (2023), ‘Universal and Transferable Adversarial\\nAttacks on Aligned Language Models’.\\n25',\n",
              "   0.8412451,\n",
              "   {'source_document': 'http://arxiv.org/pdf/2311.02147v1',\n",
              "    'text': '& Polosukhin,\\nI. (2017), Attention is All you Need, inI. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus,\\nS. Vishwanathan & R. Garnett, eds, ‘Advances in Neural Information Processing Systems 30’, Curran\\nAssociates, Inc., pp. 5998–6008.\\nVold, K. & Harris, D. R. (n.d.), How Does Artificial Intelligence Pose an Existential Risk?, inC. Véliz,\\ned., ‘Oxford Handbook of Digital Ethics’, Oxford University Press, Oxford.\\nvon Oswald, J., Niklasson, E., Randazzo, E., Sacramento, J., Mordvintsev, A., Zhmoginov, A. &\\nVladymyrov, M. (2022), ‘Transformers learn in-context by gradient descent’.\\nvon Oswald, J., Niklasson, E., Schlegel, M., Kobayashi, S., Zucchet, N., Scherrer, N., Miller, N.,\\nSandler, M., y Arcas, B. A., Vladymyrov, M., Pascanu, R. & Sacramento, J. (2023), ‘Uncovering\\nmesa-optimization algorithms in Transformers’.\\nWallace, E., Feng, S., Kandpal, N., Gardner, M. & Singh, S. (2021), ‘Universal Adversarial Triggers for\\nAttacking and Analyzing NLP’.\\nWang, L., Ma, C., Feng, X., Zhang, Z., Yang, H., Zhang, J., Chen, Z., Tang, J., Chen, X., Lin, Y., Zhao,\\nW. X., Wei, Z. & Wen, J.-R. (2023), ‘A Survey on Large Language Model based Autonomous Agents’.\\nWang, Z., Xie, W., Chen, K., Wang, B., Gui, Z. & Wang, E. (2023), ‘Self-Deception: Reverse Penetrating\\nthe Semantic Firewall of Large Language Models’.\\nWei, A., Haghtalab, N. & Steinhardt, J. (2023), ‘Jailbroken: How Does LLM Safety Training Fail?’.\\n23The Alignment Problem In Context Version 1\\nWei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama, D., Bosma, M., Zhou, D.,\\nMetzler, D., Chi, E. H., Hashimoto, T., Vinyals, O., Liang, P., Dean, J. & Fedus, W. (2022), ‘Emergent\\nAbilities of Large Language Models’.\\nWei, Z., Wang, Y. & Wang, Y. (2023), ‘Jailbreak and Guard Aligned Language Models with Only Few\\nIn-Context Demonstrations’.\\nWeidinger, L., Uesato, J., Rauh, M., Griffin, C., Huang, P.-S., Mellor, J., Glaese, A., Cheng, M., Balle, B.,\\nKasirzadeh, A., Biles, C., Brown, S., Kenton, Z., Hawkins, W., Stepleton, T., Birhane, A., Hendricks,\\nL. A., Rimell, L., Isaac, W., Haas, J., Legassick, S., Irving, G. & Gabriel, I. (2022), Taxonomy\\nof Risks posed by Language Models, in‘Proceedings of the 2022 ACM Conference on Fairness,\\nAccountability, and Transparency’, FAccT ’22, Association for Computing Machinery, New York, NY,\\nUSA, pp. 214–229.\\nWhite, A. D., Hocky, G. M., Gandhi, H. A., Ansari, M., Cox, S., P. Wellawatte, G., Sasmal, S., Yang, Z.,\\nLiu, K., Singh, Y. & Ccoa, W. J. P. (2023), ‘Assessment of chemistry knowledge in large language\\nmodels that generate code’, Digital Discovery 2(2), 368–376.\\nWillison, S. (2023), ‘Bing: “I will not harm you unless you harm me first”’.\\nWolf, Y., Wies, N., Avnery, O., Levine, Y. & Shashua, A. (2023), ‘Fundamental Limitations of Alignment\\nin Large Language Models’.\\nXiang, C. (2023), ‘’He Would Still Be Here’: Man Dies by Suicide After Talking with AI Chatbot, Widow\\nSays’.\\nYang, X., Wang, X., Zhang, Q., Petzold, L., Wang, W. Y., Zhao, X. & Lin, D. (2023), ‘Shadow Alignment:\\nThe Ease of Subverting Safely-Aligned Language Models’.\\nYe, H., Liu, T., Zhang, A., Hua, W. & Jia, W. (2023), ‘Cognitive Mirage: A Review of Hallucinations in\\nLarge Language Models’.\\nYong, Z.-X., Menghini, C. & Bach, S. H. (2023), ‘Low-Resource Languages Jailbreak GPT-4’.\\nYu, J., Lin, X., Yu, Z. & Xing, X. (2023), ‘GPTFUZZER: Red Teaming Large Language Models with\\nAuto-Generated Jailbreak Prompts’.\\nYuan, Y., Jiao, W., Wang, W., Huang, J.-t., He, P., Shi, S. & Tu, Z. (2023), ‘GPT-4 Is Too Smart To Be\\nSafe: Stealthy Chat with LLMs via Cipher’.\\nZellers, R., Holtzman, A., Rashkin, H., Bisk, Y., Farhadi, A., Roesner, F. & Choi, Y. (2019), Defending\\nAgainst Neural Fake News, in‘Advances in Neural Information Processing Systems’, Vol. 32, Curran\\nAssociates, Inc.\\nZhang, S., Dong, L., Li, X., Zhang, S., Sun, X., Wang, S., Li, J., Hu, R., Zhang, T., Wu, F. & Wang, G.\\n(2023), ‘Instruction Tuning for Large Language Models: A Survey’.\\nZhang, W. E., Sheng, Q. Z., Alhazmi, A. & Li, C. (2020), ‘Adversarial Attacks on Deep-learning Models\\nin Natural Language Processing: A Survey’, ACM Transactions on Intelligent Systems and Technology\\n11(3), 24:1–24:41.\\nZhang, Y. & Ippolito, D. (2023), ‘Prompts Should not be Seen as Secrets: Systematically Measuring\\nPrompt Extraction Attack Success’.\\nZheng, Y., Koh, H. Y., Ju, J., Nguyen, A. T. N., May, L. T., Webb, G. I. & Pan, S. (2023), ‘Large Language\\nModels for Scientific Synthesis, Inference and Explanation’.\\n24The Alignment Problem In Context Version 1\\nZhu, S., Zhang, R., An, B., Wu, G., Barrow, J., Wang, Z., Huang, F., Nenkova, A. & Sun, T. (2023),\\n‘AutoDAN: Automatic and Interpretable Adversarial Attacks on Large Language Models’.\\nZou, A., Wang, Z., Kolter, J. Z. & Fredrikson, M. (2023), ‘Universal and Transferable Adversarial\\nAttacks on Aligned Language Models’.\\n25'}),\n",
              "  ('Diab, Xian Li, Xi Victoria Lin, Todor Mihaylov, Myle Ott,\\nSam Shleifer, Kurt Shuster, Daniel Simig, Punit Singh Koura, Anjali Sridhar, Tianlu Wang,\\n74and Luke Zettlemoyer. 2022. OPT: open pre-trained transformer language models. CoRR,\\nabs/2205.01068.\\nWei Emma Zhang, Quan Z Sheng, Ahoud Alhazmi, and Chenliang Li. 2020. Adversarial at-\\ntacks on deep-learning models in natural language processing: A survey. ACM Transactions\\non Intelligent Systems and Technology (TIST) , 11(3):1–41.\\nJieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, and Kai-Wei Chang. 2018. Gender\\nbias in coreference resolution: Evaluation and debiasing methods. In Proceedings of the\\n2018 Conference of the North American Chapter of the Association for Computational\\nLinguistics: Human Language Technologies, Volume 2 (Short Papers) , pages 15–20.\\nShuai Zhao, Jinming Wen, Luu Anh Tuan, Junbo Zhao, and Jie Fu. 2023a. Prompt as triggers\\nfor backdoor attack: Examining the vulnerability in language models. arXiv preprint\\narXiv:2305.01219 .\\nWayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian\\nMin, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023b. A survey of large language\\nmodels.arXiv preprint arXiv:2303.18223 .\\nYao Zhao, Rishabh Joshi, Tianqi Liu, Misha Khalman, Mohammad Saleh, and Peter J\\nLiu. 2023c. Slic-hf: Sequence likelihood calibration with human feedback. arXiv preprint\\narXiv:2305.10425 .\\nYao Zhao, Misha Khalman, Rishabh Joshi, Shashi Narayan, Mohammad Saleh, and Peter J\\nLiu. 2022. Calibrating sequence likelihood improves conditional language generation. arXiv\\npreprint arXiv:2210.00045 .\\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao\\nZhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. 2023a. Judging llm-as-a-judge\\nwith mt-bench and chatbot arena. arXiv preprint arXiv:2306.05685 .\\nRui Zheng, Shihan Dou, Songyang Gao, Wei Shen, Binghai Wang, Yan Liu, Senjie Jin, Qin\\nLiu, Limao Xiong, Lu Chen, et al. 2023b. Secrets of rlhf in large language models part i:\\nPpo.arXiv preprint arXiv:2307.04964 .\\nChunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia\\nEfrat, Ping Yu, Lili Yu, et al. 2023a. Lima: Less is more for alignment. arXiv preprint\\narXiv:2305.11206 .\\nJingyan Zhou, Jiawen Deng, Fei Mi, Yitong Li, Yasheng Wang, Minlie Huang, Xin Jiang,\\nQun Liu, and Helen Meng. 2022. Towards identifying social bias in dialog systems: Frame,\\ndatasets, and benchmarks. arXiv preprint arXiv:2202.08011 .\\nKaitlyn Zhou, Dan Jurafsky, and Tatsunori Hashimoto. 2023b. Navigating the grey\\narea: Expressions of overconfidence and uncertainty in language models. arXiv preprint\\narXiv:2302.13439 .\\n75BanghuaZhu, JiantaoJiao, andMichaelIJordan.2023. Principledreinforcementlearningwith\\nhuman feedback from pairwise or k-wise comparisons. arXiv preprint arXiv:2301.11270 .\\nBrian D Ziebart, Andrew L Maas, J Andrew Bagnell, Anind K Dey, et al. 2008. Maximum\\nentropy inverse reinforcement learning. In Aaai, volume 8, pages 1433–1438. Chicago, IL,\\nUSA.\\nDaniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B Brown, Alec Radford, Dario Amodei,\\nPaul Christiano, and Geoffrey Irving. 2019. Fine-tuning language models from human\\npreferences. arXiv preprint arXiv:1909.08593 .\\nAndy Zou, Zifan Wang, J Zico Kolter, and Matt Fredrikson. 2023. Universal and transferable\\nadversarial attacks on aligned language models. arXiv preprint arXiv:2307.15043 .\\n76',\n",
              "   0.8611349,\n",
              "   {'source_document': 'http://arxiv.org/pdf/2309.15025v1',\n",
              "    'text': 'Diab, Xian Li, Xi Victoria Lin, Todor Mihaylov, Myle Ott,\\nSam Shleifer, Kurt Shuster, Daniel Simig, Punit Singh Koura, Anjali Sridhar, Tianlu Wang,\\n74and Luke Zettlemoyer. 2022. OPT: open pre-trained transformer language models. CoRR,\\nabs/2205.01068.\\nWei Emma Zhang, Quan Z Sheng, Ahoud Alhazmi, and Chenliang Li. 2020. Adversarial at-\\ntacks on deep-learning models in natural language processing: A survey. ACM Transactions\\non Intelligent Systems and Technology (TIST) , 11(3):1–41.\\nJieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, and Kai-Wei Chang. 2018. Gender\\nbias in coreference resolution: Evaluation and debiasing methods. In Proceedings of the\\n2018 Conference of the North American Chapter of the Association for Computational\\nLinguistics: Human Language Technologies, Volume 2 (Short Papers) , pages 15–20.\\nShuai Zhao, Jinming Wen, Luu Anh Tuan, Junbo Zhao, and Jie Fu. 2023a. Prompt as triggers\\nfor backdoor attack: Examining the vulnerability in language models. arXiv preprint\\narXiv:2305.01219 .\\nWayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian\\nMin, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023b. A survey of large language\\nmodels.arXiv preprint arXiv:2303.18223 .\\nYao Zhao, Rishabh Joshi, Tianqi Liu, Misha Khalman, Mohammad Saleh, and Peter J\\nLiu. 2023c. Slic-hf: Sequence likelihood calibration with human feedback. arXiv preprint\\narXiv:2305.10425 .\\nYao Zhao, Misha Khalman, Rishabh Joshi, Shashi Narayan, Mohammad Saleh, and Peter J\\nLiu. 2022. Calibrating sequence likelihood improves conditional language generation. arXiv\\npreprint arXiv:2210.00045 .\\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao\\nZhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. 2023a. Judging llm-as-a-judge\\nwith mt-bench and chatbot arena. arXiv preprint arXiv:2306.05685 .\\nRui Zheng, Shihan Dou, Songyang Gao, Wei Shen, Binghai Wang, Yan Liu, Senjie Jin, Qin\\nLiu, Limao Xiong, Lu Chen, et al. 2023b. Secrets of rlhf in large language models part i:\\nPpo.arXiv preprint arXiv:2307.04964 .\\nChunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia\\nEfrat, Ping Yu, Lili Yu, et al. 2023a. Lima: Less is more for alignment. arXiv preprint\\narXiv:2305.11206 .\\nJingyan Zhou, Jiawen Deng, Fei Mi, Yitong Li, Yasheng Wang, Minlie Huang, Xin Jiang,\\nQun Liu, and Helen Meng. 2022. Towards identifying social bias in dialog systems: Frame,\\ndatasets, and benchmarks. arXiv preprint arXiv:2202.08011 .\\nKaitlyn Zhou, Dan Jurafsky, and Tatsunori Hashimoto. 2023b. Navigating the grey\\narea: Expressions of overconfidence and uncertainty in language models. arXiv preprint\\narXiv:2302.13439 .\\n75BanghuaZhu, JiantaoJiao, andMichaelIJordan.2023. Principledreinforcementlearningwith\\nhuman feedback from pairwise or k-wise comparisons. arXiv preprint arXiv:2301.11270 .\\nBrian D Ziebart, Andrew L Maas, J Andrew Bagnell, Anind K Dey, et al. 2008. Maximum\\nentropy inverse reinforcement learning. In Aaai, volume 8, pages 1433–1438. Chicago, IL,\\nUSA.\\nDaniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B Brown, Alec Radford, Dario Amodei,\\nPaul Christiano, and Geoffrey Irving. 2019. Fine-tuning language models from human\\npreferences. arXiv preprint arXiv:1909.08593 .\\nAndy Zou, Zifan Wang, J Zico Kolter, and Matt Fredrikson. 2023. Universal and transferable\\nadversarial attacks on aligned language models. arXiv preprint arXiv:2307.15043 .\\n76'}),\n",
              "  ('Diab, Xian Li, Xi Victoria Lin, Todor Mihaylov, Myle Ott,\\nSam Shleifer, Kurt Shuster, Daniel Simig, Punit Singh Koura, Anjali Sridhar, Tianlu Wang,\\n74and Luke Zettlemoyer. 2022. OPT: open pre-trained transformer language models. CoRR,\\nabs/2205.01068.\\nWei Emma Zhang, Quan Z Sheng, Ahoud Alhazmi, and Chenliang Li. 2020. Adversarial at-\\ntacks on deep-learning models in natural language processing: A survey. ACM Transactions\\non Intelligent Systems and Technology (TIST) , 11(3):1–41.\\nJieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, and Kai-Wei Chang. 2018. Gender\\nbias in coreference resolution: Evaluation and debiasing methods. In Proceedings of the\\n2018 Conference of the North American Chapter of the Association for Computational\\nLinguistics: Human Language Technologies, Volume 2 (Short Papers) , pages 15–20.\\nShuai Zhao, Jinming Wen, Luu Anh Tuan, Junbo Zhao, and Jie Fu. 2023a. Prompt as triggers\\nfor backdoor attack: Examining the vulnerability in language models. arXiv preprint\\narXiv:2305.01219 .\\nWayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian\\nMin, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023b. A survey of large language\\nmodels.arXiv preprint arXiv:2303.18223 .\\nYao Zhao, Rishabh Joshi, Tianqi Liu, Misha Khalman, Mohammad Saleh, and Peter J\\nLiu. 2023c. Slic-hf: Sequence likelihood calibration with human feedback. arXiv preprint\\narXiv:2305.10425 .\\nYao Zhao, Misha Khalman, Rishabh Joshi, Shashi Narayan, Mohammad Saleh, and Peter J\\nLiu. 2022. Calibrating sequence likelihood improves conditional language generation. arXiv\\npreprint arXiv:2210.00045 .\\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao\\nZhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. 2023a. Judging llm-as-a-judge\\nwith mt-bench and chatbot arena. arXiv preprint arXiv:2306.05685 .\\nRui Zheng, Shihan Dou, Songyang Gao, Wei Shen, Binghai Wang, Yan Liu, Senjie Jin, Qin\\nLiu, Limao Xiong, Lu Chen, et al. 2023b. Secrets of rlhf in large language models part i:\\nPpo.arXiv preprint arXiv:2307.04964 .\\nChunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia\\nEfrat, Ping Yu, Lili Yu, et al. 2023a. Lima: Less is more for alignment. arXiv preprint\\narXiv:2305.11206 .\\nJingyan Zhou, Jiawen Deng, Fei Mi, Yitong Li, Yasheng Wang, Minlie Huang, Xin Jiang,\\nQun Liu, and Helen Meng. 2022. Towards identifying social bias in dialog systems: Frame,\\ndatasets, and benchmarks. arXiv preprint arXiv:2202.08011 .\\nKaitlyn Zhou, Dan Jurafsky, and Tatsunori Hashimoto. 2023b. Navigating the grey\\narea: Expressions of overconfidence and uncertainty in language models. arXiv preprint\\narXiv:2302.13439 .\\n75BanghuaZhu, JiantaoJiao, andMichaelIJordan.2023. Principledreinforcementlearningwith\\nhuman feedback from pairwise or k-wise comparisons. arXiv preprint arXiv:2301.11270 .\\nBrian D Ziebart, Andrew L Maas, J Andrew Bagnell, Anind K Dey, et al. 2008. Maximum\\nentropy inverse reinforcement learning. In Aaai, volume 8, pages 1433–1438. Chicago, IL,\\nUSA.\\nDaniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B Brown, Alec Radford, Dario Amodei,\\nPaul Christiano, and Geoffrey Irving. 2019. Fine-tuning language models from human\\npreferences. arXiv preprint arXiv:1909.08593 .\\nAndy Zou, Zifan Wang, J Zico Kolter, and Matt Fredrikson. 2023. Universal and transferable\\nadversarial attacks on aligned language models. arXiv preprint arXiv:2307.15043 .\\n76',\n",
              "   0.86945343,\n",
              "   {'source_document': 'http://arxiv.org/pdf/2309.15025v1',\n",
              "    'text': 'Diab, Xian Li, Xi Victoria Lin, Todor Mihaylov, Myle Ott,\\nSam Shleifer, Kurt Shuster, Daniel Simig, Punit Singh Koura, Anjali Sridhar, Tianlu Wang,\\n74and Luke Zettlemoyer. 2022. OPT: open pre-trained transformer language models. CoRR,\\nabs/2205.01068.\\nWei Emma Zhang, Quan Z Sheng, Ahoud Alhazmi, and Chenliang Li. 2020. Adversarial at-\\ntacks on deep-learning models in natural language processing: A survey. ACM Transactions\\non Intelligent Systems and Technology (TIST) , 11(3):1–41.\\nJieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, and Kai-Wei Chang. 2018. Gender\\nbias in coreference resolution: Evaluation and debiasing methods. In Proceedings of the\\n2018 Conference of the North American Chapter of the Association for Computational\\nLinguistics: Human Language Technologies, Volume 2 (Short Papers) , pages 15–20.\\nShuai Zhao, Jinming Wen, Luu Anh Tuan, Junbo Zhao, and Jie Fu. 2023a. Prompt as triggers\\nfor backdoor attack: Examining the vulnerability in language models. arXiv preprint\\narXiv:2305.01219 .\\nWayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian\\nMin, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023b. A survey of large language\\nmodels.arXiv preprint arXiv:2303.18223 .\\nYao Zhao, Rishabh Joshi, Tianqi Liu, Misha Khalman, Mohammad Saleh, and Peter J\\nLiu. 2023c. Slic-hf: Sequence likelihood calibration with human feedback. arXiv preprint\\narXiv:2305.10425 .\\nYao Zhao, Misha Khalman, Rishabh Joshi, Shashi Narayan, Mohammad Saleh, and Peter J\\nLiu. 2022. Calibrating sequence likelihood improves conditional language generation. arXiv\\npreprint arXiv:2210.00045 .\\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao\\nZhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. 2023a. Judging llm-as-a-judge\\nwith mt-bench and chatbot arena. arXiv preprint arXiv:2306.05685 .\\nRui Zheng, Shihan Dou, Songyang Gao, Wei Shen, Binghai Wang, Yan Liu, Senjie Jin, Qin\\nLiu, Limao Xiong, Lu Chen, et al. 2023b. Secrets of rlhf in large language models part i:\\nPpo.arXiv preprint arXiv:2307.04964 .\\nChunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia\\nEfrat, Ping Yu, Lili Yu, et al. 2023a. Lima: Less is more for alignment. arXiv preprint\\narXiv:2305.11206 .\\nJingyan Zhou, Jiawen Deng, Fei Mi, Yitong Li, Yasheng Wang, Minlie Huang, Xin Jiang,\\nQun Liu, and Helen Meng. 2022. Towards identifying social bias in dialog systems: Frame,\\ndatasets, and benchmarks. arXiv preprint arXiv:2202.08011 .\\nKaitlyn Zhou, Dan Jurafsky, and Tatsunori Hashimoto. 2023b. Navigating the grey\\narea: Expressions of overconfidence and uncertainty in language models. arXiv preprint\\narXiv:2302.13439 .\\n75BanghuaZhu, JiantaoJiao, andMichaelIJordan.2023. Principledreinforcementlearningwith\\nhuman feedback from pairwise or k-wise comparisons. arXiv preprint arXiv:2301.11270 .\\nBrian D Ziebart, Andrew L Maas, J Andrew Bagnell, Anind K Dey, et al. 2008. Maximum\\nentropy inverse reinforcement learning. In Aaai, volume 8, pages 1433–1438. Chicago, IL,\\nUSA.\\nDaniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B Brown, Alec Radford, Dario Amodei,\\nPaul Christiano, and Geoffrey Irving. 2019. Fine-tuning language models from human\\npreferences. arXiv preprint arXiv:1909.08593 .\\nAndy Zou, Zifan Wang, J Zico Kolter, and Matt Fredrikson. 2023. Universal and transferable\\nadversarial attacks on aligned language models. arXiv preprint arXiv:2307.15043 .\\n76'})]}"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retrieval_augmented_qa_pipeline.run_pipeline(\"alignment concerns with large language models\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAkIW2qRR6yz"
      },
      "source": [
        "Navigate to the Weights and Biases \"run\" link to see how your LLM is performing!\n",
        "\n",
        "```\n",
        "View run at YOUR LINK HERE\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Of8wJGalR6yz"
      },
      "source": [
        "## Task 7: RAG Evaluation Using GPT-4\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "PRNzzMurR6yz",
        "outputId": "0dcaf542-530c-480d-9dc6-a2931e8557e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The context provided discusses various aspects related to large language models, particularly focusing on alignment concerns. It mentions topics such as adversarial attacks, gender bias, sequence likelihood calibration, and judging language models. The text also delves into the vulnerability of language models to backdoor attacks triggered by prompts, the calibration of sequence likelihood for improved language generation, and the evaluation of language models in different scenarios.\n",
            "\n",
            "In summary, the context covers a range of issues and considerations surrounding large language models, including potential vulnerabilities, biases, and calibration techniques. It emphasizes the importance of addressing alignment concerns to ensure the effectiveness and reliability of these models.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'{\\n  \"clarity\": 6,\\n  \"faithfulness\": 4,\\n  \"correctness\": 5\\n}'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"alignment concerns with large language models\"\n",
        "\n",
        "response = retrieval_augmented_qa_pipeline.run_pipeline(query)\n",
        "\n",
        "print(response[\"response\"])\n",
        "\n",
        "evaluator_system_template = \"\"\"You are an expert in analyzing the quality of a response.\n",
        "\n",
        "You should be hyper-critical.\n",
        "\n",
        "Provide scores (out of 10) for the following attributes:\n",
        "\n",
        "1. Clarity - how clear is the response\n",
        "2. Faithfulness - how related to the original query is the response and the provided context\n",
        "3. Correctness - was the response correct?\n",
        "\n",
        "Please take your time, and think through each item step-by-step, when you are done - please provide your response in the following JSON format:\n",
        "\n",
        "{\"clarity\" : \"score_out_of_10\", \"faithfulness\" : \"score_out_of_10\", \"correctness\" : \"score_out_of_10\"}\"\"\"\n",
        "\n",
        "evaluation_template = \"\"\"Query: {input}\n",
        "Context: {context}\n",
        "Response: {response}\"\"\"\n",
        "\n",
        "try:\n",
        "    chat_openai = ChatOpenAI(model_name=\"gpt-4o\")\n",
        "except:\n",
        "    chat_openai = ChatOpenAI()\n",
        "\n",
        "evaluator_system_prompt = SystemRolePrompt(evaluator_system_template)\n",
        "evaluation_prompt = UserRolePrompt(evaluation_template)\n",
        "\n",
        "messages = [\n",
        "    evaluator_system_prompt.create_message(format=False),\n",
        "    evaluation_prompt.create_message(\n",
        "        input=query,\n",
        "        context=\"\\n\".join([context[0] for context in response[\"context\"]]),\n",
        "        response=response[\"response\"]\n",
        "    ),\n",
        "]\n",
        "\n",
        "chat_openai.run(messages, response_format={\"type\" : \"json_object\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNpauQmJR6yz"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "In this notebook, we've gone through the steps required to create your own simple RAQA application!\n",
        "\n",
        "Please feel free to extend this as much as you'd like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "bb904e05ece143c79ecc4f20de482f45",
            "3a4ba348cb004f8ab7b2b1395539c81b",
            "1ce393d9afcf427d9d352259c5d32678",
            "56a8e24025594e5e9ff3b8581c344691",
            "d2ea5009dd16442cb5d8a0ac468e50a8",
            "5f00135fe1044051a50ee5e841cbb8e3",
            "4e6efd99f7d346e485b002fb0fa85cc7",
            "3dfb67c39958461da6071e4c19c3fa41"
          ]
        },
        "id": "xzlxJbFtR6y0",
        "outputId": "d5789d16-c41c-4a3c-ac53-65640a0d3698"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">earthy-sound-23</strong> at: <a href='https://wandb.ai/dwbranson/Visibility%20Example%20-%20AIE3/runs/5htohjfr' target=\"_blank\">https://wandb.ai/dwbranson/Visibility%20Example%20-%20AIE3/runs/5htohjfr</a><br/> View project at: <a href='https://wandb.ai/dwbranson/Visibility%20Example%20-%20AIE3' target=\"_blank\">https://wandb.ai/dwbranson/Visibility%20Example%20-%20AIE3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240611_092401-5htohjfr/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "buildyourownlangchain",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "orig_nbformat": 4,
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1ce393d9afcf427d9d352259c5d32678": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e6efd99f7d346e485b002fb0fa85cc7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3dfb67c39958461da6071e4c19c3fa41",
            "value": 1
          }
        },
        "3a4ba348cb004f8ab7b2b1395539c81b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2ea5009dd16442cb5d8a0ac468e50a8",
            "placeholder": "​",
            "style": "IPY_MODEL_5f00135fe1044051a50ee5e841cbb8e3",
            "value": "0.018 MB of 0.018 MB uploaded\r"
          }
        },
        "3dfb67c39958461da6071e4c19c3fa41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e6efd99f7d346e485b002fb0fa85cc7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56a8e24025594e5e9ff3b8581c344691": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f00135fe1044051a50ee5e841cbb8e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb904e05ece143c79ecc4f20de482f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a4ba348cb004f8ab7b2b1395539c81b",
              "IPY_MODEL_1ce393d9afcf427d9d352259c5d32678"
            ],
            "layout": "IPY_MODEL_56a8e24025594e5e9ff3b8581c344691"
          }
        },
        "d2ea5009dd16442cb5d8a0ac468e50a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
