{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/donbcolab/AIE3/blob/main/brain_tumor_hf_ds_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuBoZd6_Kw7s"
      },
      "source": [
        "# Brain Tumor Image Dataset - Hugging Face Dataset Creation\n",
        "\n",
        "This notebook processes a brain tumor image dataset with COCO-format annotations and creates a Hugging Face Dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key learnings and decisions while creating this brain tumor image dataset for Hugging Face.\n",
        "\n",
        "1. Data Structure:\n",
        "   - The dataset contains brain tumor images with COCO-format annotations.\n",
        "   - Annotations include bounding boxes and polygon segmentations.\n",
        "   - Categories are structured as: ID 0 (Tumor), ID 1 (0), ID 2 (1), with 1 and 2 being subcategories of Tumor.\n",
        "\n",
        "2. Segmentation Characteristics:\n",
        "   - Segmentations are not rectangular but complex polygons.\n",
        "   - 100% of segmentations are near their bounding boxes.\n",
        "   - 100% of sampled annotations have valid polygon segmentations.\n",
        "\n",
        "3. Key Adjustments:\n",
        "   - We adjusted the 'features' definition to accommodate complex polygon segmentations.\n",
        "   - The ClassLabel for 'category_id' was updated to ['Tumor', '0', '1'] to match the actual data structure.\n",
        "\n",
        "4. Data Loading Considerations:\n",
        "   - Image data is stored as bytes after being read with OpenCV.\n",
        "   - Segmentation data needs to be carefully handled to maintain its list-of-lists structure.\n",
        "\n",
        "5. Verification Steps:\n",
        "   - We implemented functions to verify polygon validity and dataset structure.\n",
        "   - These checks are crucial before pushing the dataset to the Hugging Face Hub.\n",
        "\n",
        "6. Performance and Efficiency:\n",
        "   - We used tqdm for progress tracking during image loading, which is helpful for large datasets.\n",
        "   - The dataset creation process involves reading and encoding many images, which can be time-consuming.\n",
        "\n",
        "7. Hugging Face Dataset Structure:\n",
        "   - The dataset is created using the Hugging Face Datasets library, which has specific requirements for data types and structures.\n",
        "   - We needed to ensure that all data types in the pandas DataFrame matched the defined features.\n",
        "\n",
        "8. Potential Future Work:\n",
        "   - The current implementation doesn't push to the Hugging Face Hub automatically. This step should be done manually after thorough verification.\n",
        "   - Depending on the specific use case, additional preprocessing or data augmentation steps might be necessary."
      ],
      "metadata": {
        "id": "1A7rmeq2T-1I"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhhJ8h1uKw7t"
      },
      "source": [
        "## 1. Setup and Imports\n",
        "\n",
        "This section imports necessary libraries and sets up the environment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpEWz1J1Kw7t"
      },
      "source": [
        "### Import Necessary Libraries and Define Constants"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OQLXzGadLOnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU pyarrow==14.0.1 requests==2.31.0"
      ],
      "metadata": {
        "id": "_ko8sN4vVrxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU datasets==2.11.0"
      ],
      "metadata": {
        "id": "Hgjmz2RkVxVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from datasets import Dataset, Features, ClassLabel, Value, Sequence, Image\n",
        "from tqdm.auto import tqdm\n",
        "import cv2"
      ],
      "metadata": {
        "id": "22AUgBXjT3fs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Constants and Configuration\n",
        "Define constants and configurations used throughout the notebook.\n"
      ],
      "metadata": {
        "id": "I7X6iGqZVBa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HF_DATASET_NAME = 'brain-tumor-image-dataset-semantic-segmentation'\n",
        "SOURCE_JSON = \"/content/drive/MyDrive/kaggle/datasets/brain-tumor-image-dataset-semantic-segmentation/train/_annotations.coco.json\"\n",
        "SOURCE_IMAGE_DIR = \"/content/drive/MyDrive/kaggle/datasets/brain-tumor-image-dataset-semantic-segmentation/train\"\n"
      ],
      "metadata": {
        "id": "Wmu5BpQJbwqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FsovZqvKw7u"
      },
      "source": [
        "## 3. Feature Definition\n",
        "Define the structure of the Hugging Face Dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = Features({\n",
        "    'file_name': Value(dtype='string'),\n",
        "    'image': Image(),\n",
        "    'id': Value(dtype='int64'),\n",
        "    'category_id': ClassLabel(names=['Tumor', '0', '1']),\n",
        "    'bbox': Sequence(feature=Value(dtype='float32'), length=4),\n",
        "    'segmentation': Sequence(Sequence(Value(dtype='float32'))),\n",
        "    'area': Value(dtype='float32'),\n",
        "    'iscrowd': Value(dtype='int64'),\n",
        "    'height': Value(dtype='int64'),\n",
        "    'width': Value(dtype='int64'),\n",
        "    'date_captured': Value(dtype='string'),\n",
        "    'license': Value(dtype='int64')\n",
        "})"
      ],
      "metadata": {
        "id": "a00QTeM8ZGAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Data Loading and Preprocessing\n",
        "Functions to load and preprocess the COCO-format data."
      ],
      "metadata": {
        "id": "uvw_7Nn2VXbc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZL8oddLKw7u"
      },
      "outputs": [],
      "source": [
        "def verify_source_data():\n",
        "    with open(SOURCE_JSON, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    print(\"Categories:\")\n",
        "    for category in data['categories']:\n",
        "        print(f\"ID: {category['id']}, Name: {category['name']}, Supercategory: {category['supercategory']}\")\n",
        "\n",
        "    category_counts = pd.DataFrame(data['annotations'])['category_id'].value_counts().sort_index()\n",
        "    print(\"\\nCategory distribution in annotations:\")\n",
        "    print(category_counts)\n",
        "\n",
        "    # Check for images with multiple bounding boxes\n",
        "    image_bbox_counts = pd.DataFrame(data['annotations'])['image_id'].value_counts()\n",
        "    print(f\"\\nImages with multiple bounding boxes: {(image_bbox_counts > 1).sum()}\")\n",
        "    print(f\"Max bounding boxes in an image: {image_bbox_counts.max()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_to_df():\n",
        "    with open(SOURCE_JSON, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    images = pd.DataFrame(data['images'])\n",
        "    annotations = pd.DataFrame(data['annotations'])\n",
        "\n",
        "    df = pd.merge(images, annotations, left_on='id', right_on='image_id', suffixes=('', '_ann'))\n",
        "\n",
        "    # Drop duplicate columns\n",
        "    df = df.drop(columns=['id_ann', 'image_id'])\n",
        "\n",
        "    # Add the full image path\n",
        "    df['image'] = df['file_name'].apply(lambda x: os.path.join(SOURCE_IMAGE_DIR, x))\n",
        "\n",
        "    # Ensure all required columns are present\n",
        "    for column in features.keys():\n",
        "        if column not in df.columns and column != 'image':\n",
        "            df[column] = None\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "iCYaNVX3dN4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Dataset Creation\n",
        "Function to create the Hugging Face Dataset from the preprocessed data."
      ],
      "metadata": {
        "id": "BQ9sogWWV7KH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_hf_dataset(df, hf_dataset_name):\n",
        "    # Convert 'image' column to image data\n",
        "    def load_image(image_path):\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is not None:\n",
        "            return cv2.imencode('.jpg', img)[1].tobytes()\n",
        "        return None\n",
        "\n",
        "    tqdm.pandas(desc=\"Loading images\")\n",
        "    df['image'] = df['image'].progress_apply(load_image)\n",
        "\n",
        "    # Ensure datatypes match the features\n",
        "    df['bbox'] = df['bbox'].apply(lambda x: [float(i) for i in x])\n",
        "    df['segmentation'] = df['segmentation'].apply(lambda x: [[float(i) for i in poly] for poly in x])\n",
        "    df['area'] = df['area'].astype('float32')\n",
        "\n",
        "    dataset = Dataset.from_pandas(df, features=features)\n",
        "    print(f\"Dataset created successfully with {len(dataset)} examples.\")\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "VkLvwAuFmZkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Verification Functions\n",
        "Functions to verify the integrity and structure of the data and created dataset."
      ],
      "metadata": {
        "id": "C4jcZp4kWNhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_valid_polygon(segmentation):\n",
        "    # Check if it's a list of lists\n",
        "    if not isinstance(segmentation, list) or not all(isinstance(poly, list) for poly in segmentation):\n",
        "        return False\n",
        "\n",
        "    # Check if each polygon has at least 6 coordinates (3 points)\n",
        "    if not all(len(poly) >= 6 and len(poly) % 2 == 0 for poly in segmentation):\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n",
        "sample_annotations = coco_data['annotations'][:100]\n",
        "valid_count = sum(is_valid_polygon(ann['segmentation']) for ann in sample_annotations)\n",
        "valid_percentage = (valid_count / len(sample_annotations)) * 100\n",
        "print(f\"{valid_percentage:.2f}% of sampled annotations have valid polygon segmentations\")"
      ],
      "metadata": {
        "id": "AjQKcEaSMHGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_dataset(dataset):\n",
        "    print(f\"Dataset contains {len(dataset)} examples.\")\n",
        "    print(\"Sample of the first example:\")\n",
        "    print(dataset[0])\n",
        "\n",
        "    # Check if all required fields are present\n",
        "    required_fields = ['file_name', 'image', 'id', 'category_id', 'bbox', 'segmentation', 'area']\n",
        "    for field in required_fields:\n",
        "        if field not in dataset[0]:\n",
        "            print(f\"Warning: '{field}' is missing from the dataset.\")\n",
        "\n",
        "    # Verify image data\n",
        "    if isinstance(dataset[0]['image'], bytes):\n",
        "        print(\"Image data is stored as bytes.\")\n",
        "    else:\n",
        "        print(\"Warning: Image data is not stored as bytes.\")\n",
        "\n",
        "    # Verify segmentation data\n",
        "    if isinstance(dataset[0]['segmentation'], list) and isinstance(dataset[0]['segmentation'][0], list):\n",
        "        print(\"Segmentation data is stored as a list of lists.\")\n",
        "    else:\n",
        "        print(\"Warning: Segmentation data is not stored as a list of lists.\")\n",
        "\n",
        "    print(\"Dataset verification complete.\")"
      ],
      "metadata": {
        "id": "DzgHdUtqOLlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Main Execution\n",
        "The main workflow to create and verify the dataset."
      ],
      "metadata": {
        "id": "D38qHafRW1lu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and prepare the data\n",
        "df = load_data_to_df()\n",
        "\n",
        "# Create the dataset\n",
        "dataset = create_hf_dataset(df, HF_DATASET_NAME)\n",
        "\n",
        "# Verify the dataset\n",
        "verify_dataset(dataset)\n",
        "\n",
        "# If you want to upload to the Hub (uncomment when ready)\n",
        "# dataset.push_to_hub(HF_DATASET_NAME)"
      ],
      "metadata": {
        "id": "pdF4aJRz92bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. (Optional) Upload to Hugging Face Hub\n",
        "Uncomment this section when ready to upload the dataset to the Hugging Face Hub."
      ],
      "metadata": {
        "id": "u-UcN5SKTwA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset.push_to_hub(HF_DATASET_NAME)"
      ],
      "metadata": {
        "id": "5XnrOC47XAN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## APPENDIX:  Other Validations"
      ],
      "metadata": {
        "id": "EV54_sZGXNRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "\n",
        "with open(SOURCE_JSON, 'r') as f:\n",
        "    coco_data = json.load(f)\n",
        "\n",
        "category_ids = [ann['category_id'] for ann in coco_data['annotations']]\n",
        "id_counts = Counter(category_ids)\n",
        "\n",
        "categories = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
        "\n",
        "print(\"Category ID counts:\", id_counts)\n",
        "print(\"Category mappings:\", categories)\n",
        "\n",
        "# Automated verification\n",
        "expected_categories = {0: 'Tumor', 1: '0', 2: '1'}\n",
        "assert categories == expected_categories, f\"Category mismatch. Expected {expected_categories}, got {categories}\"\n",
        "assert set(id_counts.keys()) == {1, 2}, f\"Unexpected category IDs found: {set(id_counts.keys())}\""
      ],
      "metadata": {
        "id": "vY56XeTb6qZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_rectangle_segmentation(bbox, segmentation):\n",
        "    x, y, w, h = bbox\n",
        "    expected = [[x, y, x+w, y, x+w, y+h, x, y+h]]\n",
        "    if segmentation != expected:\n",
        "        print(f\"Non-rectangular segmentation found:\")\n",
        "        print(f\"Bbox: {bbox}\")\n",
        "        print(f\"Segmentation: {segmentation}\")\n",
        "        print(f\"Expected: {expected}\")\n",
        "        print(\"---\")\n",
        "    return segmentation == expected\n",
        "\n",
        "sample_annotations = coco_data['annotations'][:100]\n",
        "rectangle_count = sum(is_rectangle_segmentation(ann['bbox'], ann['segmentation'])\n",
        "                      for ann in sample_annotations)\n",
        "\n",
        "rectangle_percentage = (rectangle_count / len(sample_annotations)) * 100\n",
        "print(f\"{rectangle_percentage:.2f}% of sampled annotations have rectangular segmentations\")\n",
        "\n",
        "# Instead of asserting, let's just print a warning\n",
        "if rectangle_percentage < 100:\n",
        "    print(f\"Warning: Only {rectangle_percentage:.2f}% of segmentations are rectangular\")"
      ],
      "metadata": {
        "id": "uC_AaGlFKXbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_segmentations(annotations):\n",
        "    segmentation_types = {}\n",
        "    for ann in annotations:\n",
        "        seg_type = (len(ann['segmentation']), len(ann['segmentation'][0]) if ann['segmentation'] else 0)\n",
        "        segmentation_types[seg_type] = segmentation_types.get(seg_type, 0) + 1\n",
        "\n",
        "    print(\"Segmentation structure analysis:\")\n",
        "    for (outer_len, inner_len), count in segmentation_types.items():\n",
        "        print(f\"Outer length: {outer_len}, Inner length: {inner_len}, Count: {count}\")\n",
        "\n",
        "analyze_segmentations(coco_data['annotations'][:100])"
      ],
      "metadata": {
        "id": "r-bqK6EQKWdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def is_approximately_rectangular(bbox, segmentation, tolerance=1.0):\n",
        "    x, y, w, h = bbox\n",
        "    expected = np.array([[x, y], [x+w, y], [x+w, y+h], [x, y+h], [x, y]])\n",
        "    actual = np.array(segmentation[0]).reshape(-1, 2)\n",
        "    return np.allclose(actual, expected, atol=tolerance)\n",
        "\n",
        "sample_annotations = coco_data['annotations'][:100]\n",
        "rectangle_count = sum(is_approximately_rectangular(ann['bbox'], ann['segmentation'])\n",
        "                      for ann in sample_annotations)\n",
        "\n",
        "rectangle_percentage = (rectangle_count / len(sample_annotations)) * 100\n",
        "print(f\"{rectangle_percentage:.2f}% of sampled annotations are approximately rectangular\")"
      ],
      "metadata": {
        "id": "QldlaK-vK8t3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_segmentation_inside_bbox(bbox, segmentation):\n",
        "    x, y, w, h = bbox\n",
        "    for polygon in segmentation:\n",
        "        for i in range(0, len(polygon), 2):\n",
        "            if polygon[i] < x or polygon[i] > x + w or polygon[i+1] < y or polygon[i+1] > y + h:\n",
        "                return False\n",
        "    return True\n",
        "\n",
        "inside_bbox_count = sum(is_segmentation_inside_bbox(ann['bbox'], ann['segmentation'])\n",
        "                        for ann in coco_data['annotations'][:100])\n",
        "inside_bbox_percentage = (inside_bbox_count / 100) * 100\n",
        "print(f\"{inside_bbox_percentage:.2f}% of segmentations are inside their bounding boxes\")"
      ],
      "metadata": {
        "id": "TjK2YjZTKfrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_segmentation_near_bbox(bbox, segmentation, tolerance=1.0):\n",
        "    x, y, w, h = bbox\n",
        "    for polygon in segmentation:\n",
        "        for i in range(0, len(polygon), 2):\n",
        "            if (polygon[i] < x - tolerance or\n",
        "                polygon[i] > x + w + tolerance or\n",
        "                polygon[i+1] < y - tolerance or\n",
        "                polygon[i+1] > y + h + tolerance):\n",
        "                return False\n",
        "    return True\n",
        "\n",
        "near_bbox_count = sum(is_segmentation_near_bbox(ann['bbox'], ann['segmentation'])\n",
        "                      for ann in coco_data['annotations'][:100])\n",
        "near_bbox_percentage = (near_bbox_count / 100) * 100\n",
        "print(f\"{near_bbox_percentage:.2f}% of segmentations are near their bounding boxes\")"
      ],
      "metadata": {
        "id": "Z8gyX9SlK9jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "# Create small subset\n",
        "subset_images = coco_data['images'][:10]\n",
        "subset_annotations = [ann for ann in coco_data['annotations']\n",
        "                      if ann['image_id'] in [img['id'] for img in subset_images]]\n",
        "\n",
        "# Create DataFrame\n",
        "df_subset = pd.DataFrame({\n",
        "    'file_name': [img['file_name'] for img in subset_images],\n",
        "    'image_id': [img['id'] for img in subset_images],\n",
        "    'category_id': [ann['category_id'] for ann in subset_annotations],\n",
        "    'bbox': [ann['bbox'] for ann in subset_annotations],\n",
        "    'segmentation': [ann['segmentation'] for ann in subset_annotations]\n",
        "})\n",
        "\n",
        "# Convert to Parquet\n",
        "df_subset.to_parquet('test_subset.parquet')\n",
        "\n",
        "# Load Parquet file\n",
        "loaded_df = pd.read_parquet('test_subset.parquet')\n",
        "\n",
        "# Verify data\n",
        "assert len(loaded_df) == len(df_subset), \"Row count mismatch\"\n",
        "for column in df_subset.columns:\n",
        "    if column in ['bbox', 'segmentation']:\n",
        "        assert all(loaded_df[column].apply(str) == df_subset[column].apply(str)), f\"Mismatch in column {column}\"\n",
        "    else:\n",
        "        assert (loaded_df[column] == df_subset[column]).all(), f\"Mismatch in column {column}\"\n",
        "\n",
        "print(\"Parquet conversion and loading test passed successfully\")"
      ],
      "metadata": {
        "id": "JurNk-p96zzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "def load_image_on_demand(example):\n",
        "    image_path = os.path.join(SOURCE_IMAGE_DIR, example['file_name'])\n",
        "    example['image'] = cv2.imread(image_path)\n",
        "    return example\n",
        "\n",
        "# Create dataset\n",
        "dataset = Dataset.from_parquet('test_subset.parquet')\n",
        "\n",
        "# Set transform for on-demand loading\n",
        "dataset.set_transform(load_image_on_demand)\n",
        "\n",
        "# Test accessing items\n",
        "for i in range(min(3, len(dataset))):\n",
        "    item = dataset[i]\n",
        "    assert 'image' in item, f\"Image not loaded for item {i}\"\n",
        "    assert item['image'] is not None, f\"Image is None for item {i}\"\n",
        "    print(f\"Successfully loaded image for item {i}\")\n",
        "\n",
        "    # Visualize the image\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(cv2.cvtColor(item['image'], cv2.COLOR_BGR2RGB))\n",
        "    plt.title(f\"Image {i}: {item['file_name']}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "K-20jXXG65Dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uy1EawZ56-NB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}